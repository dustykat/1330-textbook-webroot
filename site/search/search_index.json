{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ENGR 1330 Computational Thinking and Data Science A WebBook by Theodore G. Cleveland and Farhang Forghanparast with contributions from : Dinesh Sundaravadivelu Devarajan, Turgut Batuhan Baturalp (Batu), Tanja Karp, Long Nguyen, and Mona Rizvi Introduction This on-line workbook is a collection of lessons and workshop contents for ENGR-1330 sections taught bt the first two authors; students in other sections are welcome to use this as a resource with proper attribution (check with your instructor regarding what they will consider acceptable) suggested citation goes here The entire course content is served here and can be accessed from blackboard.ttu.edu or directly using the public URL. Homeworks and exams must be uploaded to blackboard.ttu.edu to be graded. Solutions are posted after due dates have passed, these links are updated weekly-ish. Document History This document is a living document and is updated frequently, Python is an ever evolving tool and stuff that works today will be constructively broken by the development team (python.org) in their quest for continuous improvement. Generally these changes occur in the packages (libraries, external modules) and primative python is quite stable. Administrator Notes The lead author built this webbook on a Raspberry Pi 4B (4GB) running Ubuntu 20.XX, an Apache Web Server, a JupyterHub (fully encrypted) with iPython extensions, R core, Latex, and MkDocs with extensions. The deployment hardware is an Amazon Web Services Virtual Private Server (Lightsail Instance) in the West Virginia Server Farm (typically the container is run on x86-64 Xeon hardware) Direct access to the notebook directories is on the to-do-list. A backup is maintained at https://github.com/dustykat/1330-textbook-webroot .","title":"Home"},{"location":"#engr-1330-computational-thinking-and-data-science","text":"","title":" ENGR 1330 Computational Thinking and Data Science "},{"location":"#a-webbook","text":"by Theodore G. Cleveland and Farhang Forghanparast with contributions from : Dinesh Sundaravadivelu Devarajan, Turgut Batuhan Baturalp (Batu), Tanja Karp, Long Nguyen, and Mona Rizvi","title":"A WebBook "},{"location":"#introduction","text":"This on-line workbook is a collection of lessons and workshop contents for ENGR-1330 sections taught bt the first two authors; students in other sections are welcome to use this as a resource with proper attribution (check with your instructor regarding what they will consider acceptable) suggested citation goes here The entire course content is served here and can be accessed from blackboard.ttu.edu or directly using the public URL. Homeworks and exams must be uploaded to blackboard.ttu.edu to be graded. Solutions are posted after due dates have passed, these links are updated weekly-ish.","title":"Introduction"},{"location":"#document-history","text":"This document is a living document and is updated frequently, Python is an ever evolving tool and stuff that works today will be constructively broken by the development team (python.org) in their quest for continuous improvement. Generally these changes occur in the packages (libraries, external modules) and primative python is quite stable.","title":"Document History"},{"location":"#administrator-notes","text":"The lead author built this webbook on a Raspberry Pi 4B (4GB) running Ubuntu 20.XX, an Apache Web Server, a JupyterHub (fully encrypted) with iPython extensions, R core, Latex, and MkDocs with extensions. The deployment hardware is an Amazon Web Services Virtual Private Server (Lightsail Instance) in the West Virginia Server Farm (typically the container is run on x86-64 Xeon hardware) Direct access to the notebook directories is on the to-do-list. A backup is maintained at https://github.com/dustykat/1330-textbook-webroot .","title":"Administrator Notes"},{"location":"untitled/","text":"About this document Put something here about the document, authors, copyright (GPL or MIT Open License) On-Line Book Author's Notes Inserting Code Fragments To insert a code fragment such as print('Hello World') simply indent in the source file used to generate the document print('hello world') These fragments can be cut-and-paste into a JupyterLab notebook. Inserting Images If the image is taken from a URL, use the following: ![image-name (a local tag)](url_to_image_source) Such as: ![image-name](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQqn40YbupkMAzY63jYtA6auEmjRfCOvCd0FA&usqp=CAU) Which will render a black swan: If the image is local to the host replace the url with the path to the image. Inserting URL links This is a variation of images, but without the ! , such as [link-name-that-will-display](url_to_link_destimation) For example the code below will link to the black swan search results: [link-to-images-of-black-swans](https://www.google.com/search?q=images+of+black+swan&client=safari&rls=en&sxsrf=ALeKk03oIoQ387TWjJoKzX-D_b7o1to43Q:1613002985584&tbm=isch&source=iu&ictx=1&fir=L2P5MiS1ICLTxM%252CC6BDdJoXT9KcEM%252C_&vet=1&usg=AI4_-kTXrBMpj__xL5IkGCshrXTp04fX3w&sa=X&ved=2ahUKEwiCneivyODuAhVJBs0KHY88CaAQ9QF6BAgUEAE&biw=1447&bih=975#imgrc=i_lxoojURNE3XM) link-to-images-of-black-swans","title":"Exam 3 Solution"},{"location":"untitled/#about-this-document","text":"Put something here about the document, authors, copyright (GPL or MIT Open License)","title":"About this document"},{"location":"untitled/#on-line-book-authors-notes","text":"Inserting Code Fragments To insert a code fragment such as print('Hello World') simply indent in the source file used to generate the document print('hello world') These fragments can be cut-and-paste into a JupyterLab notebook. Inserting Images If the image is taken from a URL, use the following: ![image-name (a local tag)](url_to_image_source) Such as: ![image-name](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQqn40YbupkMAzY63jYtA6auEmjRfCOvCd0FA&usqp=CAU) Which will render a black swan: If the image is local to the host replace the url with the path to the image. Inserting URL links This is a variation of images, but without the ! , such as [link-name-that-will-display](url_to_link_destimation) For example the code below will link to the black swan search results: [link-to-images-of-black-swans](https://www.google.com/search?q=images+of+black+swan&client=safari&rls=en&sxsrf=ALeKk03oIoQ387TWjJoKzX-D_b7o1to43Q:1613002985584&tbm=isch&source=iu&ictx=1&fir=L2P5MiS1ICLTxM%252CC6BDdJoXT9KcEM%252C_&vet=1&usg=AI4_-kTXrBMpj__xL5IkGCshrXTp04fX3w&sa=X&ved=2ahUKEwiCneivyODuAhVJBs0KHY88CaAQ9QF6BAgUEAE&biw=1447&bih=975#imgrc=i_lxoojURNE3XM) link-to-images-of-black-swans","title":"On-Line Book Author's Notes"},{"location":"8-Labs/Lab0/Lab0_Dev/","text":"Laboratory 0: Yes, That's how we count in python! Link to Content Server Welcome to your first Jupyter Notebook . This is a medium that we will be using throughout the semester. Why is this called a notebook? Because you can write stuff in it! Is that it? Nope! you can write and run CODE in this notebook! Plus a bunch of other cool stuff such as making graphs, running tests and simulations, adding images, and prepare documents (such as this one!). How do we get this? There are online services that allow you create, modify, and export Jupyter notebooks. However, to have this on your local machines (computers), you can install Anaconda . Anaconda is a package of different software suits including \"Jupyter Notebook\". You can find videos on how to install Anaconda on your devices on BlackBoard: Go to Anaconda.com Scroll down to the bottom of the page or click on products > individual edition Download the right version for your system: Windows, MacOS, and Linux- This may take a while depending on your connection speed Once the installer file is downloaded, run it and install Anaconda on your machine. Anaconda requires almost 3 GB of free space Install it in a separate folder- Preferably on a drive with lots of free memory! BE PATIENT!- It will take a while. The Environment - Let's have a look around this window! The tabs File Edit View Insert Cell Kernel The Icons Save Insert Cell Below Cut Copy Paste Cells Below Move Up Move Down Run Intruppt Kernel Restart Kernel Cell Type Selector (Dropdown list) The notebook consists of a sequence of cells. A cell is a multiline text input field, and its contents can be executed by using Shift-Enter, or by clicking Run in the menu bar. The execution behavior of a cell is determined by the cell\u2019s type. There are three types of cells: code cells, markdown cells, and raw cells. Every cell starts off being a code cell, but its type can be changed by using a drop-down on the toolbar (which will be \u201cCode\u201d, initially). Code Cells: A code cell allows you to edit and write new code, with full syntax highlighting and tab completion. The programming language you use depends on the kernel. What we will use for this course and the default kernel IPython runs, is Python code. When a code cell is executed, code that it contains is sent to the kernel associated with the notebook. The results that are returned from this computation are then displayed in the notebook as the cell\u2019s output. The output is not limited to text, with many other possible forms of output are also possible, including matplotlib figures and HTML tables. This is known as IPython\u2019s rich display capability. Markdown Cells: You can document the computational process in a literate way, alternating descriptive text with code, using rich text. In IPython this is accomplished by marking up text with the Markdown language. The corresponding cells are called Markdown cells. The Markdown language provides a simple way to perform this text markup, that is, to specify which parts of the text should be emphasized (italics), bold, form lists, etc. In fact, markdown cells allow a variety of cool modifications to be applied: If you want to provide structure for your document, you can use markdown headings. Markdown headings consist of 1 to 5 hash # signs followed by a space and the title of your section. (The markdown heading will be converted to a clickable link for a section of the notebook. It is also used as a hint when exporting to other document formats, like PDF.) Here is how it looks: # title ## major headings ### subheadings #### 4th level subheadings ##### 5th level subheadings These codes are also quite useful: Use triple \" * \" before and after a word (without spacing) to make the word bold and italic B&I: string __ or before and after a word (without spacing) to make the word bold Bold: string or string** _ or * before and after a word (without spacing to make the word italic Italic: string or string Double ~ before and after a word (without spacing to make the word scratched Scratched: ~~string~~ For line breaks use \"br\" in the middle of <> For colors use this code: Text Text Text For indented quoting, use a greater than sign (>) and then a space, then type the text. The text is indented and has a gray horizontal line to the left of it until the next carriage return. here is an example of how it works! For bullets, use the dash sign (- ) with a space after it, or a space, a dash, and a space ( - ), to create a circular bullet. To create a sub bullet, use a tab followed a dash and a space. You can also use an asterisk instead of a dash, and it works the same. For numbered lists, start with 1. followed by a space, then it starts numbering for you. Start each line with some number and a period, then a space. Tab to indent to get subnumbering. first second third ... For horizontal lines: Use three asterisks: *** For graphics, you can attach image files directly to a notebook only in Markdown cells. Drag and drop your images to the Mardown cell to attach it to the notebook. You can also use images from online sources be using this format: ![](put the image address here.image format) Raw Cells: Raw cells provide a place in which you can write output directly. Raw cells are not evaluated by the notebook. Let's meet world's most popular python! What is python? \"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\" - Wikipedia @ https://en.wikipedia.org/wiki/Python_(programming_language) How to have access to it? There are plenty of ways, from online compilers to our beloved Jupyter Notebook on your local machines. Here are a few examples of online compilers: a. https://www.programiz.com/python-programming/online-compiler/ b. https://www.onlinegdb.com/online_python_compiler c. https://www.w3schools.com/python/python_compiler.asp d. https://repl.it/languages/python3 We can do the exact same thing in this notebook. But we need a CODE cell. print(\"Hello World\") Hello World This is the classic \"first program\" of many languages! The script input is quite simple, we instruct the computer to print the literal string \"hello world\" to standard input/output device which is the console. Let's change it and see what happens: print(\"This is my first notebook!\") This is my first notebook! How to save a notebook? As a notebook file (.ipynb): Go to File > Download As > Notebook (.ipynb) As an HTML file (.html): Go to File > Download As > HTML (.html) As a Pdf (.pdf): Go to File > Download As > PDF via LaTex (.pdf) or Save it as an HTML file and then convert that to a pdf via a website such as https://html2pdf.com/ Unless stated otherwise, we want you to submit your weekly lab assignments in PDF and your exam and project deliverables in both PDF and .ipynb formats. This notebook was inspired by several blogposts including: \"Markdown for Jupyter notebooks cheatsheet\" by Inge Halilovic available at *https://medium.com/@ingeh/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed \"Jupyter Notebook: An Introduction\" by Mike Driscoll available at *https://realpython.com/jupyter-notebook-introduction/ Here are some great reads on this topic: - \"Jupyter Notebook Tutorial: The Definitive Guide\" by Karlijn Willems available at https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook - \"Introduction to Jupyter Notebooks\" by Quinn Dombrowski, Tassie Gniady, and David Kloster available at https://programminghistorian.org/en/lessons/jupyter-notebooks - \"12 Things to know about Jupyter Notebook Markdown\" by Dayal Chand Aichara available at *https://medium.com/game-of-data/12-things-to-know-about-jupyter-notebook-markdown-3f6cef811707 Here are some great videos on these topics: - \"Jupyter Notebook Tutorial: Introduction, Setup, and Walkthrough\" by Corey Schafer available at https://www.youtube.com/watch?v=HW29067qVWk - \"Quick introduction to Jupyter Notebook\" by Michael Fudge available at https://www.youtube.com/watch?v=jZ952vChhuI - \"What is Jupyter Notebook?\" by codebasics available at *https://www.youtube.com/watch?v=q_BzsPxwLOE Exercise: Let's see who you are! Similar to the example, use a code cell and print a paragraph about you. You can introduce yourselves and write about interesting things to and about you!","title":"Workshop 0"},{"location":"8-Labs/Lab0/Lab0_Dev/#laboratory-0-yes-thats-how-we-count-in-python","text":"Link to Content Server","title":"Laboratory 0: Yes, That's how we count in python!"},{"location":"8-Labs/Lab0/Lab0_Dev/#welcome-to-your-first-jupyter-notebook-this-is-a-medium-that-we-will-be-using-throughout-the-semester","text":"","title":"Welcome to your first Jupyter Notebook. This is a medium that we will be using throughout the semester."},{"location":"8-Labs/Lab0/Lab0_Dev/#why-is-this-called-a-notebook","text":"","title":"Why is this called a notebook?"},{"location":"8-Labs/Lab0/Lab0_Dev/#because-you-can-write-stuff-in-it","text":"","title":"Because you can write stuff in it!"},{"location":"8-Labs/Lab0/Lab0_Dev/#is-that-it","text":"","title":"Is that it?"},{"location":"8-Labs/Lab0/Lab0_Dev/#nope-you-can-write-and-run-code-in-this-notebook-plus-a-bunch-of-other-cool-stuff-such-as-making-graphs-running-tests-and-simulations-adding-images-and-prepare-documents-such-as-this-one","text":"","title":"Nope! you can write and run CODE in this notebook! Plus a bunch of other cool stuff such as making graphs, running tests and simulations, adding images, and prepare documents (such as this one!)."},{"location":"8-Labs/Lab0/Lab0_Dev/#how-do-we-get-this","text":"","title":"How do we get this?"},{"location":"8-Labs/Lab0/Lab0_Dev/#there-are-online-services-that-allow-you-create-modify-and-export-jupyter-notebooks-however-to-have-this-on-your-local-machines-computers-you-can-install-anaconda-anaconda-is-a-package-of-different-software-suits-including-jupyter-notebook-you-can-find-videos-on-how-to-install-anaconda-on-your-devices-on-blackboard","text":"Go to Anaconda.com Scroll down to the bottom of the page or click on products > individual edition Download the right version for your system: Windows, MacOS, and Linux- This may take a while depending on your connection speed Once the installer file is downloaded, run it and install Anaconda on your machine. Anaconda requires almost 3 GB of free space Install it in a separate folder- Preferably on a drive with lots of free memory! BE PATIENT!- It will take a while.","title":"There are online services that allow you create, modify, and export Jupyter notebooks. However, to have this on your local machines (computers), you can install Anaconda. Anaconda is a package of different software suits including \"Jupyter Notebook\". You can find videos on how to install Anaconda on your devices on BlackBoard:"},{"location":"8-Labs/Lab0/Lab0_Dev/#the-environment-lets-have-a-look-around-this-window","text":"The tabs File Edit View Insert Cell Kernel The Icons Save Insert Cell Below Cut Copy Paste Cells Below Move Up Move Down Run Intruppt Kernel Restart Kernel Cell Type Selector (Dropdown list)","title":"The Environment - Let's have a look around this window!"},{"location":"8-Labs/Lab0/Lab0_Dev/#the-notebook-consists-of-a-sequence-of-cells-a-cell-is-a-multiline-text-input-field-and-its-contents-can-be-executed-by-using-shift-enter-or-by-clicking-run-in-the-menu-bar-the-execution-behavior-of-a-cell-is-determined-by-the-cells-type","text":"","title":"The notebook consists of a sequence of cells. A cell is a multiline text input field, and its contents can be executed by using Shift-Enter, or by clicking Run in the menu bar. The execution behavior of a cell is determined by the cell\u2019s type."},{"location":"8-Labs/Lab0/Lab0_Dev/#there-are-three-types-of-cells-code-cells-markdown-cells-and-raw-cells-every-cell-starts-off-being-a-code-cell-but-its-type-can-be-changed-by-using-a-drop-down-on-the-toolbar-which-will-be-code-initially","text":"","title":"There are three types of cells: code cells, markdown cells, and raw cells. Every cell starts off being a code cell, but its type can be changed by using a drop-down on the toolbar (which will be \u201cCode\u201d, initially)."},{"location":"8-Labs/Lab0/Lab0_Dev/#code-cells","text":"","title":"Code Cells:"},{"location":"8-Labs/Lab0/Lab0_Dev/#a-code-cell-allows-you-to-edit-and-write-new-code-with-full-syntax-highlighting-and-tab-completion-the-programming-language-you-use-depends-on-the-kernel-what-we-will-use-for-this-course-and-the-default-kernel-ipython-runs-is-python-code","text":"","title":"A code cell allows you to edit and write new code, with full syntax highlighting and tab completion. The programming language you use depends on the kernel. What we will use for this course and the default kernel IPython runs, is Python code."},{"location":"8-Labs/Lab0/Lab0_Dev/#when-a-code-cell-is-executed-code-that-it-contains-is-sent-to-the-kernel-associated-with-the-notebook-the-results-that-are-returned-from-this-computation-are-then-displayed-in-the-notebook-as-the-cells-output-the-output-is-not-limited-to-text-with-many-other-possible-forms-of-output-are-also-possible-including-matplotlib-figures-and-html-tables-this-is-known-as-ipythons-rich-display-capability","text":"","title":"When a code cell is executed, code that it contains is sent to the kernel associated with the notebook. The results that are returned from this computation are then displayed in the notebook as the cell\u2019s output. The output is not limited to text, with many other possible forms of output are also possible, including matplotlib figures and HTML tables. This is known as IPython\u2019s rich display capability."},{"location":"8-Labs/Lab0/Lab0_Dev/#markdown-cells","text":"","title":"Markdown Cells:"},{"location":"8-Labs/Lab0/Lab0_Dev/#you-can-document-the-computational-process-in-a-literate-way-alternating-descriptive-text-with-code-using-rich-text-in-ipython-this-is-accomplished-by-marking-up-text-with-the-markdown-language-the-corresponding-cells-are-called-markdown-cells-the-markdown-language-provides-a-simple-way-to-perform-this-text-markup-that-is-to-specify-which-parts-of-the-text-should-be-emphasized-italics-bold-form-lists-etc-in-fact-markdown-cells-allow-a-variety-of-cool-modifications-to-be-applied","text":"","title":"You can document the computational process in a literate way, alternating descriptive text with code, using rich text. In IPython this is accomplished by marking up text with the Markdown language. The corresponding cells are called Markdown cells. The Markdown language provides a simple way to perform this text markup, that is, to specify which parts of the text should be emphasized (italics), bold, form lists, etc. In fact, markdown cells allow a variety of cool modifications to be applied:"},{"location":"8-Labs/Lab0/Lab0_Dev/#if-you-want-to-provide-structure-for-your-document-you-can-use-markdown-headings-markdown-headings-consist-of-1-to-5-hash-signs-followed-by-a-space-and-the-title-of-your-section-the-markdown-heading-will-be-converted-to-a-clickable-link-for-a-section-of-the-notebook-it-is-also-used-as-a-hint-when-exporting-to-other-document-formats-like-pdf-here-is-how-it-looks","text":"","title":"If you want to provide structure for your document, you can use markdown headings. Markdown headings consist of 1 to 5 hash # signs followed by a space and the title of your section. (The markdown heading will be converted to a clickable link for a section of the notebook. It is also used as a hint when exporting to other document formats, like PDF.) Here is how it looks:"},{"location":"8-Labs/Lab0/Lab0_Dev/#title","text":"","title":"# title"},{"location":"8-Labs/Lab0/Lab0_Dev/#major-headings","text":"","title":"## major headings"},{"location":"8-Labs/Lab0/Lab0_Dev/#subheadings","text":"","title":"### subheadings"},{"location":"8-Labs/Lab0/Lab0_Dev/#4th-level-subheadings","text":"","title":"#### 4th level subheadings"},{"location":"8-Labs/Lab0/Lab0_Dev/#5th-level-subheadings","text":"","title":"##### 5th level subheadings"},{"location":"8-Labs/Lab0/Lab0_Dev/#these-codes-are-also-quite-useful","text":"Use triple \" * \" before and after a word (without spacing) to make the word bold and italic B&I: string __ or before and after a word (without spacing) to make the word bold Bold: string or string** _ or * before and after a word (without spacing to make the word italic Italic: string or string Double ~ before and after a word (without spacing to make the word scratched Scratched: ~~string~~ For line breaks use \"br\" in the middle of <> For colors use this code: Text Text Text For indented quoting, use a greater than sign (>) and then a space, then type the text. The text is indented and has a gray horizontal line to the left of it until the next carriage return. here is an example of how it works! For bullets, use the dash sign (- ) with a space after it, or a space, a dash, and a space ( - ), to create a circular bullet. To create a sub bullet, use a tab followed a dash and a space. You can also use an asterisk instead of a dash, and it works the same. For numbered lists, start with 1. followed by a space, then it starts numbering for you. Start each line with some number and a period, then a space. Tab to indent to get subnumbering. first second third ... For horizontal lines: Use three asterisks: *** For graphics, you can attach image files directly to a notebook only in Markdown cells. Drag and drop your images to the Mardown cell to attach it to the notebook. You can also use images from online sources be using this format: ![](put the image address here.image format)","title":"These codes are also quite useful:"},{"location":"8-Labs/Lab0/Lab0_Dev/#raw-cells","text":"","title":"Raw Cells:"},{"location":"8-Labs/Lab0/Lab0_Dev/#raw-cells-provide-a-place-in-which-you-can-write-output-directly-raw-cells-are-not-evaluated-by-the-notebook","text":"","title":"Raw cells provide a place in which you can write output directly. Raw cells are not evaluated by the notebook."},{"location":"8-Labs/Lab0/Lab0_Dev/#lets-meet-worlds-most-popular-python","text":"","title":"Let's meet world's most popular python!"},{"location":"8-Labs/Lab0/Lab0_Dev/#what-is-python","text":"\"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\" - Wikipedia @ https://en.wikipedia.org/wiki/Python_(programming_language)","title":"What is python?"},{"location":"8-Labs/Lab0/Lab0_Dev/#how-to-have-access-to-it","text":"","title":"How to have access to it?"},{"location":"8-Labs/Lab0/Lab0_Dev/#there-are-plenty-of-ways-from-online-compilers-to-our-beloved-jupyter-notebook-on-your-local-machines-here-are-a-few-examples-of-online-compilers","text":"a. https://www.programiz.com/python-programming/online-compiler/ b. https://www.onlinegdb.com/online_python_compiler c. https://www.w3schools.com/python/python_compiler.asp d. https://repl.it/languages/python3","title":"There are plenty of ways, from online compilers to our beloved Jupyter Notebook on your local machines. Here are a few examples of online compilers:"},{"location":"8-Labs/Lab0/Lab0_Dev/#we-can-do-the-exact-same-thing-in-this-notebook-but-we-need-a-code-cell","text":"print(\"Hello World\") Hello World","title":"We can do the exact same thing in this notebook. But we need a CODE cell."},{"location":"8-Labs/Lab0/Lab0_Dev/#this-is-the-classic-first-program-of-many-languages-the-script-input-is-quite-simple-we-instruct-the-computer-to-print-the-literal-string-hello-world-to-standard-inputoutput-device-which-is-the-console-lets-change-it-and-see-what-happens","text":"print(\"This is my first notebook!\") This is my first notebook!","title":"This is the classic \"first program\" of many languages! The script input is quite simple, we instruct the computer to print the literal string \"hello world\" to standard input/output device which is the console. Let's change it and see what happens:"},{"location":"8-Labs/Lab0/Lab0_Dev/#how-to-save-a-notebook","text":"As a notebook file (.ipynb): Go to File > Download As > Notebook (.ipynb) As an HTML file (.html): Go to File > Download As > HTML (.html) As a Pdf (.pdf): Go to File > Download As > PDF via LaTex (.pdf) or Save it as an HTML file and then convert that to a pdf via a website such as https://html2pdf.com/ Unless stated otherwise, we want you to submit your weekly lab assignments in PDF and your exam and project deliverables in both PDF and .ipynb formats. This notebook was inspired by several blogposts including: \"Markdown for Jupyter notebooks cheatsheet\" by Inge Halilovic available at *https://medium.com/@ingeh/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed \"Jupyter Notebook: An Introduction\" by Mike Driscoll available at *https://realpython.com/jupyter-notebook-introduction/ Here are some great reads on this topic: - \"Jupyter Notebook Tutorial: The Definitive Guide\" by Karlijn Willems available at https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook - \"Introduction to Jupyter Notebooks\" by Quinn Dombrowski, Tassie Gniady, and David Kloster available at https://programminghistorian.org/en/lessons/jupyter-notebooks - \"12 Things to know about Jupyter Notebook Markdown\" by Dayal Chand Aichara available at *https://medium.com/game-of-data/12-things-to-know-about-jupyter-notebook-markdown-3f6cef811707 Here are some great videos on these topics: - \"Jupyter Notebook Tutorial: Introduction, Setup, and Walkthrough\" by Corey Schafer available at https://www.youtube.com/watch?v=HW29067qVWk - \"Quick introduction to Jupyter Notebook\" by Michael Fudge available at https://www.youtube.com/watch?v=jZ952vChhuI - \"What is Jupyter Notebook?\" by codebasics available at *https://www.youtube.com/watch?v=q_BzsPxwLOE","title":"How to save a notebook?"},{"location":"8-Labs/Lab0/Lab0_Dev/#exercise-lets-see-who-you-are","text":"","title":"Exercise: Let's see who you are! "},{"location":"8-Labs/Lab0/Lab0_Dev/#similar-to-the-example-use-a-code-cell-and-print-a-paragraph-about-you-you-can-introduce-yourselves-and-write-about-interesting-things-to-and-about-you","text":"","title":"Similar to the example, use a code cell and print a paragraph about you. You can introduce yourselves and write about interesting things to and about you!"},{"location":"8-Labs/Lab1/Lab1_Dev/","text":"Laboratory 1: First Steps... Notice the code cell below! From this notebook forward please include and run the script in the cell, it will help in debugging a notebook. # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) DESKTOP-EH6HD63 desktop-eh6hd63\\farha C:\\Users\\Farha\\Anaconda3\\python.exe 3.7.4 (default, Aug 9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0) Also, from now on, please make sure that you have the following markdown cell, filled with your own information, on top of your notebooks: Full name: R#: Title of the notebook: Date: Now, let's get to work! Variables Variables are names given to data that we want to store and manipulate in programs. A variable has a name and a value. The value representation depends on what type of object the variable represents. The utility of variables comes in when we have a structure that is universal, but values of variables within the structure will change - otherwise it would be simple enough to just hardwire the arithmetic. Suppose we want to store the time of concentration for some hydrologic calculation. To do so, we can name a variable TimeOfConcentration , and then assign a value to the variable, for instance: TimeOfConcentration = 0.0 After this assignment statement the variable is created in the program and has a value of 0.0. The use of a decimal point in the initial assignment establishes the variable as a float (a real variable is called a floating point representation -- or just a float). TimeOfConcentration + 5 5.0 Naming Rules Variable names in Python can only contain letters (a - z, A - Z), numerals (0 - 9), or underscores. The first character cannot be a number, otherwise there is considerable freedom in naming. The names can be reasonably long. runTime , run_Time , _run_Time2 , _2runTime are all valid names, but 2runTime is not valid, and will create an error when you try to use it. # Script to illustrate variable names runTime = 1 _2runTime = 2 # change to 2runTime = 2 and rerun script runTime2 = 2 print(runTime,_2runTime,runTime2) 1 2 2 There are some reserved words that cannot be used as variable names because they have preassigned meaning in Parseltongue. These words include print, input, if, while, and for. There are several more; the interpreter won't allow you to use these names as variables and will issue an error message when you attempt to run a program with such words used as variables. Operators The = sign used in the variable definition is called an assignment operator (or assignment sign). The symbol means that the expression to the right of the symbol is to be evaluated and the result placed into the variable on the left side of the symbol. The \"operation\" is assignment, the \"=\" symbol is the operator name. Consider the script below: # Assignment Operator x = 5 y = 10 print (x,y) x=y # reverse order y=x and re-run, what happens? print (x,y) 5 10 10 10 So look at what happened. When we assigned values to the variables named x and y , they started life as 5 and 10. We then wrote those values to the console, and the program returned 5 and 10. Then we assigned y to x which took the value in y and replaced the value that was in x with this value. We then wrote the contents again, and both variables have the value 10. What's it with # ? Comments are added by writing a hashtag symbol (#) followed by any text of your choice. Any text that follows the hashtag symbol on the same line is ignored by the Python interpreter. Arithmetic Operators In addition to assignment we can also perform arithmetic operations on variables. The fundamental arithmetic operators are: Symbol Meaning Example = Assignment x=3 Assigns value of 3 to x. + Addition x+y Adds values in x and y. - Subtraction x-y Subtracts values in y from x. * Multiplication x*y Multiplies values in x and y. / Division x/y Divides value in x by value in y. // Floor division x//y Divide x by y, truncate result to whole number. % Modulus x%y Returns remainder when x is divided by y. ** Exponentation x ** y Raises value in x by value in y. ( e.g. xy) += Additive assignment x+=2 Equivalent to x = x+2. -= Subtractive assignment x-=2 Equivalent to x = x-2. *= Multiplicative assignment x*=3 Equivalent to x = x*3. /= Divide assignment x/3 Equivalent to x = x/3. Run the script in the next cell for some illustrative results # Uniary Arithmetic Operators x = 10 y = 5 print(x, y) print(x+y) print(x-y) print(x*y) print(x/y) print((x+1)//y) print((x+1)%y) print(x**y) 10 5 15 5 50 2.0 2 1 100000 # Arithmetic assignment operators x = 1 x += 2 print(type(x),x) x = 1 x -= 2 print(type(x),x) x = 1 x *=3 print(type(x),x) x = 10 x /= 2 print(type(x),x) # Interesting what division does to variable type <class 'int'> 3 <class 'int'> -1 <class 'int'> 3 <class 'float'> 5.0 Data Type In the computer data are all binary digits (actually 0 and +5 volts). At a higher level of abstraction data are typed into integers, real, or alphanumeric representation. The type affects the kind of arithmetic operations that are allowed (as well as the kind of arithmetic - integer versus real arithmetic; lexicographical ordering of alphanumeric , etc.) In scientific programming, a common (and really difficult to detect) source of slight inaccuracies (that tend to snowball as the program runs) is mixed mode arithmetic required because two numeric values are of different types (integer and real). Learn more from the textbook https://www.inferentialthinking.com/chapters/04/Data_Types.html Here we present a quick summary Integer Integers are numbers without any fractional portion (nothing after the decimal point { which is not used in integers). Numbers like -3, -2, -1, 0, 1, 2, 200 are integers. A number like 1.1 is not an integer, and 1.0 is also not an integer (the presence of the decimal point makes the number a real). To declare an integer in Python, just assign the variable name to an integer for example MyPhoneNumber = 14158576309 Real (Float) A real or float is a number that has (or can have) a fractional portion - the number has decimal parts. The numbers 3.14159, -0.001, 11.11, 1., are all floats. The last one is especially tricky, if you don't notice the decimal point you might think it is an integer but the inclusion of the decimal point in Python tells the program that the value is to be treated as a float. To declare a float in Python, just assign the variable name to a float for example MyMassInKilos = 74.8427 String(Alphanumeric) A string is a data type that is treated as text elements. The usual letters are strings, but numbers can be included. The numbers in a string are simply characters and cannot be directly used in arithmetic. There are some kinds of arithmetic that can be performed on strings but generally we process string variables to capture the text nature of their contents. To declare a string in Python, just assign the variable name to a string value - the trick is the value is enclosed in quotes. The quotes are delimiters that tell the program that the characters between the quotes are characters and are to be treated as literal representation. For example MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" are all string variables. The last assignment is made a string on purpose. String variables can be combined using an operation called concatenation. The symbol for concatenation is the plus symbol + . Strings can also be converted to all upper case using the upper() function. The syntax for the upper() function is 'string to be upper case'.upper() . Notice the \"dot\" in the syntax. The operation passes everything to the left of the dot to the function which then operates on that content and returns the result all upper case (or an error if the input stream is not a string). # Variable Types Example MyPhoneNumber = 14158576309 MyMassInKilos = 74.8427 MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" print(\"All about me\") print(\"Name: \",MyName, \" Mass :\",MyMassInKilos,\"Kg\" ) print('Phone : ',MyPhoneNumber) print('My cat\\'s name :', MyCatName) # the \\ escape character is used to get the ' into the literal print(\"All about concatenation!\") print(\"A Silly String : \",MyCatName+MyName+DustyMassInKilos) print(\"A SILLY STRING : \", (MyCatName+MyName+DustyMassInKilos).upper()) print(MyName[0:4]) # Notice how the string is sliced- This is Python: ALWAYS start counting from zero! All about me Name: Theodore Mass : 74.8427 Kg Phone : 14158576309 My cat's name : Dusty All about concatenation! A Silly String : DustyTheodore7.48427 A SILLY STRING : DUSTYTHEODORE7.48427 Theo Strings can be formatted using the % operator or the format() function. The concepts will be introduced later on as needed in the workbook, you can Google search for examples of how to do such formatting. Changing Types A variable type can be changed. This activity is called type casting. Three functions allow type casting: int() , float() , and str() . The function names indicate the result of using the function, hence int() returns an integer, float() returns a oat, and str() returns a string. There is also the useful function type() which returns the type of variable. The easiest way to understand is to see an example. # Type Casting Examples MyInteger = 234 MyFloat = 876.543 MyString = 'What is your name?' print(MyInteger,MyFloat,MyString) print('Integer as float',float(MyInteger)) print('Float as integer',int(MyFloat)) print('Integer as string',str(MyInteger)) print('Integer as hexadecimal',hex(MyInteger)) print('Integer Type',type((MyInteger))) # insert the hex conversion and see what happens! Expressions Expressions are the \"algebraic\" constructions that are evaluated and then placed into a variable. Consider x1 = 7 + 3 * 6 / 2 - 1 The expression is evaluated from the left to right and in words is Into the object named x1 place the result of: integer 7 + (integer 6 divide by integer 2 = float 3 * integer 3 = float 9 - integer 1 = float 8) = float 15 The division operation by default produces a float result unless forced otherwise. The result is the variable x1 is a float with a value of 15.0 # Expressions Example x1 = 7 + 3 * 6 // 2 - 1 # Change / into // and see what happens! print(type(x1),x1) ## Simple I/O (Input/Output) <class 'int'> 15 Example: Simple Input/Output Get two floating point numbers via the input() function and store them under the variable names float1 and float2 . Then, compare them, and try a few operations on them! float1 = input(\"Please enter float1: \") float1 = float(float1) ... Print float1 and float2 to the output screen. print(\"float1:\", float1) ... Then check whether float1 is greater than or equal to float2 . float1 = input(\"Please enter float1: \") float2 = input(\"Please enter float2: \") Please enter float1: 2.5 Please enter float2: 5 print(\"float1:\", float1) print(\"float2:\", float2) float1: 2.5 float2: 5 float1 = float(float1) float2 = float(float2) print(\"float1:\", float1) print(\"float2:\", float2) float1: 2.5 float2: 5.0 float1>float2 False float1+float2 7.5 float1/float2 0.5 Here are some great reads on this topic: - \"Variables in Python\" by John Sturtz available at https://realpython.com/python-variables/ - \"A Beginner\u2019s Guide To Python Variables\" by Avijeet Biswal available at https://www.simplilearn.com/tutorials/python-tutorial/python-variables - \"A Very Basic Introduction to Variables in Python\" by Dr. Python available at *https://medium.com/@doctorsmonsters/a-very-basic-introduction-to-variables-in-python-4231e36dac52 Here are some great videos on these topics: - \"Python Tutorial for Absolute Beginners #1 - What Are Variables?\" by CS Dojo available at https://www.youtube.com/watch?v=Z1Yd7upQsXY - \"#4 Python Tutorial for Beginners | Variables in Python\" by Telusko available at https://www.youtube.com/watch?v=TqPzwenhMj0 - \"Variables and Types in Python\" by DataCamp available at *https://www.youtube.com/watch?v=OH86oLzVzzw Exercise: Integer or Float? Think of a few cases where one might need to convert a float into an integer. * Make sure to cite any resources that you may use.","title":"Workshop 1"},{"location":"8-Labs/Lab1/Lab1_Dev/#laboratory-1-first-steps","text":"","title":"Laboratory 1: First Steps... "},{"location":"8-Labs/Lab1/Lab1_Dev/#notice-the-code-cell-below","text":"","title":"Notice the code cell below!"},{"location":"8-Labs/Lab1/Lab1_Dev/#from-this-notebook-forward-please-include-and-run-the-script-in-the-cell-it-will-help-in-debugging-a-notebook","text":"# Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) DESKTOP-EH6HD63 desktop-eh6hd63\\farha C:\\Users\\Farha\\Anaconda3\\python.exe 3.7.4 (default, Aug 9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)","title":"From this notebook forward please include and run the script in the cell, it will help in debugging a notebook."},{"location":"8-Labs/Lab1/Lab1_Dev/#also-from-now-on-please-make-sure-that-you-have-the-following-markdown-cell-filled-with-your-own-information-on-top-of-your-notebooks","text":"","title":"Also, from now on, please make sure that you have the following markdown cell, filled with your own information, on top of your notebooks:"},{"location":"8-Labs/Lab1/Lab1_Dev/#full-name","text":"","title":"Full name:"},{"location":"8-Labs/Lab1/Lab1_Dev/#r","text":"","title":"R#:"},{"location":"8-Labs/Lab1/Lab1_Dev/#title-of-the-notebook","text":"","title":"Title of the notebook:"},{"location":"8-Labs/Lab1/Lab1_Dev/#date","text":"","title":"Date:"},{"location":"8-Labs/Lab1/Lab1_Dev/#now-lets-get-to-work","text":"","title":"Now, let's get to work!"},{"location":"8-Labs/Lab1/Lab1_Dev/#variables","text":"Variables are names given to data that we want to store and manipulate in programs. A variable has a name and a value. The value representation depends on what type of object the variable represents. The utility of variables comes in when we have a structure that is universal, but values of variables within the structure will change - otherwise it would be simple enough to just hardwire the arithmetic. Suppose we want to store the time of concentration for some hydrologic calculation. To do so, we can name a variable TimeOfConcentration , and then assign a value to the variable, for instance: TimeOfConcentration = 0.0 After this assignment statement the variable is created in the program and has a value of 0.0. The use of a decimal point in the initial assignment establishes the variable as a float (a real variable is called a floating point representation -- or just a float). TimeOfConcentration + 5 5.0","title":"Variables"},{"location":"8-Labs/Lab1/Lab1_Dev/#naming-rules","text":"Variable names in Python can only contain letters (a - z, A - Z), numerals (0 - 9), or underscores. The first character cannot be a number, otherwise there is considerable freedom in naming. The names can be reasonably long. runTime , run_Time , _run_Time2 , _2runTime are all valid names, but 2runTime is not valid, and will create an error when you try to use it. # Script to illustrate variable names runTime = 1 _2runTime = 2 # change to 2runTime = 2 and rerun script runTime2 = 2 print(runTime,_2runTime,runTime2) 1 2 2 There are some reserved words that cannot be used as variable names because they have preassigned meaning in Parseltongue. These words include print, input, if, while, and for. There are several more; the interpreter won't allow you to use these names as variables and will issue an error message when you attempt to run a program with such words used as variables.","title":"Naming Rules"},{"location":"8-Labs/Lab1/Lab1_Dev/#operators","text":"The = sign used in the variable definition is called an assignment operator (or assignment sign). The symbol means that the expression to the right of the symbol is to be evaluated and the result placed into the variable on the left side of the symbol. The \"operation\" is assignment, the \"=\" symbol is the operator name. Consider the script below: # Assignment Operator x = 5 y = 10 print (x,y) x=y # reverse order y=x and re-run, what happens? print (x,y) 5 10 10 10 So look at what happened. When we assigned values to the variables named x and y , they started life as 5 and 10. We then wrote those values to the console, and the program returned 5 and 10. Then we assigned y to x which took the value in y and replaced the value that was in x with this value. We then wrote the contents again, and both variables have the value 10.","title":"Operators"},{"location":"8-Labs/Lab1/Lab1_Dev/#whats-it-with","text":"Comments are added by writing a hashtag symbol (#) followed by any text of your choice. Any text that follows the hashtag symbol on the same line is ignored by the Python interpreter.","title":"What's it with # ?"},{"location":"8-Labs/Lab1/Lab1_Dev/#arithmetic-operators","text":"In addition to assignment we can also perform arithmetic operations on variables. The fundamental arithmetic operators are: Symbol Meaning Example = Assignment x=3 Assigns value of 3 to x. + Addition x+y Adds values in x and y. - Subtraction x-y Subtracts values in y from x. * Multiplication x*y Multiplies values in x and y. / Division x/y Divides value in x by value in y. // Floor division x//y Divide x by y, truncate result to whole number. % Modulus x%y Returns remainder when x is divided by y. ** Exponentation x ** y Raises value in x by value in y. ( e.g. xy) += Additive assignment x+=2 Equivalent to x = x+2. -= Subtractive assignment x-=2 Equivalent to x = x-2. *= Multiplicative assignment x*=3 Equivalent to x = x*3. /= Divide assignment x/3 Equivalent to x = x/3. Run the script in the next cell for some illustrative results # Uniary Arithmetic Operators x = 10 y = 5 print(x, y) print(x+y) print(x-y) print(x*y) print(x/y) print((x+1)//y) print((x+1)%y) print(x**y) 10 5 15 5 50 2.0 2 1 100000 # Arithmetic assignment operators x = 1 x += 2 print(type(x),x) x = 1 x -= 2 print(type(x),x) x = 1 x *=3 print(type(x),x) x = 10 x /= 2 print(type(x),x) # Interesting what division does to variable type <class 'int'> 3 <class 'int'> -1 <class 'int'> 3 <class 'float'> 5.0","title":"Arithmetic Operators"},{"location":"8-Labs/Lab1/Lab1_Dev/#data-type","text":"In the computer data are all binary digits (actually 0 and +5 volts). At a higher level of abstraction data are typed into integers, real, or alphanumeric representation. The type affects the kind of arithmetic operations that are allowed (as well as the kind of arithmetic - integer versus real arithmetic; lexicographical ordering of alphanumeric , etc.) In scientific programming, a common (and really difficult to detect) source of slight inaccuracies (that tend to snowball as the program runs) is mixed mode arithmetic required because two numeric values are of different types (integer and real). Learn more from the textbook https://www.inferentialthinking.com/chapters/04/Data_Types.html Here we present a quick summary","title":"Data Type"},{"location":"8-Labs/Lab1/Lab1_Dev/#integer","text":"Integers are numbers without any fractional portion (nothing after the decimal point { which is not used in integers). Numbers like -3, -2, -1, 0, 1, 2, 200 are integers. A number like 1.1 is not an integer, and 1.0 is also not an integer (the presence of the decimal point makes the number a real). To declare an integer in Python, just assign the variable name to an integer for example MyPhoneNumber = 14158576309","title":"Integer"},{"location":"8-Labs/Lab1/Lab1_Dev/#real-float","text":"A real or float is a number that has (or can have) a fractional portion - the number has decimal parts. The numbers 3.14159, -0.001, 11.11, 1., are all floats. The last one is especially tricky, if you don't notice the decimal point you might think it is an integer but the inclusion of the decimal point in Python tells the program that the value is to be treated as a float. To declare a float in Python, just assign the variable name to a float for example MyMassInKilos = 74.8427","title":"Real (Float)"},{"location":"8-Labs/Lab1/Lab1_Dev/#stringalphanumeric","text":"A string is a data type that is treated as text elements. The usual letters are strings, but numbers can be included. The numbers in a string are simply characters and cannot be directly used in arithmetic. There are some kinds of arithmetic that can be performed on strings but generally we process string variables to capture the text nature of their contents. To declare a string in Python, just assign the variable name to a string value - the trick is the value is enclosed in quotes. The quotes are delimiters that tell the program that the characters between the quotes are characters and are to be treated as literal representation. For example MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" are all string variables. The last assignment is made a string on purpose. String variables can be combined using an operation called concatenation. The symbol for concatenation is the plus symbol + . Strings can also be converted to all upper case using the upper() function. The syntax for the upper() function is 'string to be upper case'.upper() . Notice the \"dot\" in the syntax. The operation passes everything to the left of the dot to the function which then operates on that content and returns the result all upper case (or an error if the input stream is not a string). # Variable Types Example MyPhoneNumber = 14158576309 MyMassInKilos = 74.8427 MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" print(\"All about me\") print(\"Name: \",MyName, \" Mass :\",MyMassInKilos,\"Kg\" ) print('Phone : ',MyPhoneNumber) print('My cat\\'s name :', MyCatName) # the \\ escape character is used to get the ' into the literal print(\"All about concatenation!\") print(\"A Silly String : \",MyCatName+MyName+DustyMassInKilos) print(\"A SILLY STRING : \", (MyCatName+MyName+DustyMassInKilos).upper()) print(MyName[0:4]) # Notice how the string is sliced- This is Python: ALWAYS start counting from zero! All about me Name: Theodore Mass : 74.8427 Kg Phone : 14158576309 My cat's name : Dusty All about concatenation! A Silly String : DustyTheodore7.48427 A SILLY STRING : DUSTYTHEODORE7.48427 Theo Strings can be formatted using the % operator or the format() function. The concepts will be introduced later on as needed in the workbook, you can Google search for examples of how to do such formatting.","title":"String(Alphanumeric)"},{"location":"8-Labs/Lab1/Lab1_Dev/#changing-types","text":"A variable type can be changed. This activity is called type casting. Three functions allow type casting: int() , float() , and str() . The function names indicate the result of using the function, hence int() returns an integer, float() returns a oat, and str() returns a string. There is also the useful function type() which returns the type of variable. The easiest way to understand is to see an example. # Type Casting Examples MyInteger = 234 MyFloat = 876.543 MyString = 'What is your name?' print(MyInteger,MyFloat,MyString) print('Integer as float',float(MyInteger)) print('Float as integer',int(MyFloat)) print('Integer as string',str(MyInteger)) print('Integer as hexadecimal',hex(MyInteger)) print('Integer Type',type((MyInteger))) # insert the hex conversion and see what happens!","title":"Changing Types"},{"location":"8-Labs/Lab1/Lab1_Dev/#expressions","text":"Expressions are the \"algebraic\" constructions that are evaluated and then placed into a variable. Consider x1 = 7 + 3 * 6 / 2 - 1 The expression is evaluated from the left to right and in words is Into the object named x1 place the result of: integer 7 + (integer 6 divide by integer 2 = float 3 * integer 3 = float 9 - integer 1 = float 8) = float 15 The division operation by default produces a float result unless forced otherwise. The result is the variable x1 is a float with a value of 15.0 # Expressions Example x1 = 7 + 3 * 6 // 2 - 1 # Change / into // and see what happens! print(type(x1),x1) ## Simple I/O (Input/Output) <class 'int'> 15","title":"Expressions"},{"location":"8-Labs/Lab1/Lab1_Dev/#example-simple-inputoutput","text":"Get two floating point numbers via the input() function and store them under the variable names float1 and float2 . Then, compare them, and try a few operations on them! float1 = input(\"Please enter float1: \") float1 = float(float1) ... Print float1 and float2 to the output screen. print(\"float1:\", float1) ... Then check whether float1 is greater than or equal to float2 . float1 = input(\"Please enter float1: \") float2 = input(\"Please enter float2: \") Please enter float1: 2.5 Please enter float2: 5 print(\"float1:\", float1) print(\"float2:\", float2) float1: 2.5 float2: 5 float1 = float(float1) float2 = float(float2) print(\"float1:\", float1) print(\"float2:\", float2) float1: 2.5 float2: 5.0 float1>float2 False float1+float2 7.5 float1/float2 0.5 Here are some great reads on this topic: - \"Variables in Python\" by John Sturtz available at https://realpython.com/python-variables/ - \"A Beginner\u2019s Guide To Python Variables\" by Avijeet Biswal available at https://www.simplilearn.com/tutorials/python-tutorial/python-variables - \"A Very Basic Introduction to Variables in Python\" by Dr. Python available at *https://medium.com/@doctorsmonsters/a-very-basic-introduction-to-variables-in-python-4231e36dac52 Here are some great videos on these topics: - \"Python Tutorial for Absolute Beginners #1 - What Are Variables?\" by CS Dojo available at https://www.youtube.com/watch?v=Z1Yd7upQsXY - \"#4 Python Tutorial for Beginners | Variables in Python\" by Telusko available at https://www.youtube.com/watch?v=TqPzwenhMj0 - \"Variables and Types in Python\" by DataCamp available at *https://www.youtube.com/watch?v=OH86oLzVzzw","title":"Example: Simple Input/Output"},{"location":"8-Labs/Lab1/Lab1_Dev/#exercise-integer-or-float","text":"","title":"Exercise: Integer or Float? "},{"location":"8-Labs/Lab1/Lab1_Dev/#think-of-a-few-cases-where-one-might-need-to-convert-a-float-into-an-integer","text":"","title":"Think of a few cases where one might need to convert a float into an integer."},{"location":"8-Labs/Lab1/Lab1_Dev/#make-sure-to-cite-any-resources-that-you-may-use","text":"","title":"* Make sure to cite any resources that you may use."},{"location":"8-Labs/Lab2/Lab2_Dev/","text":"Laboratory 2: Structures and Conditions. # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) DESKTOP-EH6HD63 desktop-eh6hd63\\farha C:\\Users\\Farha\\Anaconda3\\python.exe 3.7.4 (default, Aug 9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0) Full name: R#: Title of the notebook: Date: Data Structures: List (Array) A list is a collection of data that are somehow related. It is a convenient way to refer to a collection of similar things by a single name, and using an index (like a subscript in math) to identify a particular item. Consider the \"math-like\" variable x below: \\begin{gather} x_0= 7 \\ x_1= 11 \\ x_2= 5 \\ x_3= 9 \\ x_4= 13 \\ ... \\ x_N= 223 \\ \\end{gather} The variable name is x and the subscripts correspond to different values. Thus the value of the variable named x associated with subscript 3 is the number 9 . The figure below is a visual representation of a the concept that treats a variable as a collection of cells. In the figure, the variable name is MyList , the subscripts are replaced by an index which identifies which cell is being referenced. The value is the cell content at the particular index. So in the figure the value of MyList at Index = 3 is the number 9.' In engineering and data science we use lists a lot - we often call then vectors, arrays, matrices and such, but they are ultimately just lists. To declare a list you can write the list name and assign it values. The square brackets are used to identify that the variable is a list. Like: MyList = [7,11,5,9,13,66,99,223] One can also declare a null list and use the append() method to fill it as needed. MyOtherList = [ ] Python indices start at ZERO. Alot of other lnguages start at ONE. Its just the convention. The first element in a list has an index of 0, the second an index of 1, and so on. We access the contents of a list by referring to its name and index. For example MyList[3] has a value of the number 9. MyOtherList = [] #Create an empty list MyOtherList.append(765) #Add one item to the list print(MyOtherList) MyList = [7,11,5,9,13,66,99,223] #Define a list print(MyList) sublist = MyList[3:6] #slice a sublist print(\"sublist is: \", sublist) mysum = sum(sublist) #sum the numbers in the sublist print(\"Sum: \", mysum) mylength = len(sublist) #get the length of the sublist print(\"Length: \", mylength) [765] [7, 11, 5, 9, 13, 66, 99, 223] sublist is: [9, 13, 66] Sum: 88 Length: 3 Data Structures: Special List | Tuple A tuple is a special kind of list where the values cannot be changed after the list is created. It is useful for list-like things that are static - like days in a week, or months of a year. You declare a tuple like a list, except use round brackets instead of square brackets. MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") Data Structures: Special List | Dictionary A dictionary is a special kind of list where the items are related data PAIRS. It is a lot like a relational database (it probably is one in fact) where the first item in the pair is called the key, and must be unique in a dictionary, and the second item in the pair is the data. The second item could itself be a list, so a dictionary would be a meaningful way to build a database in Python. To declare a dictionary using curly brackets MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} To declare a dictionary using the dict() method MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) Some examples follow: MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") MyTupleName ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec') MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} print(MyPetsNamesAndMass) MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) print(MyPetsNamesAndMassToo) {'Dusty': 7.8, 'Aspen': 6.3, 'Merrimee': 0.03} {'Dusty': 7.8, 'Aspen': 6.3, 'Merrimee': 0.03} # Tuples MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") # Access a Tuple print (\"5th element of the tuple:\", MyTupleName[4]) # Dictionary MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} # Access the Dictionary print (\"Aspen's mass = \", MyPetsNamesAndMass[\"Aspen\"]) # Change a value in a dictionary print (\"Merrimee's mass\" , MyPetsNamesAndMass[\"Merrimee\"]) MyPetsNamesAndMass[\"Merrimee\"] = 0.01 print (\"Merrimee's mass\" , MyPetsNamesAndMass[\"Merrimee\"], \"She lost weight !\") # Alternate dictionary MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) print (\"Merrimee's mass\" , MyPetsNamesAndMassToo[\"Merrimee\"]) # Attempt to change a Tuple #MyTupleName[3]=(\"Fred\") # Activate this line and see what happens! 5th element of the tuple: May Aspen's mass = 6.3 Merrimee's mass 0.03 Merrimee's mass 0.01 She lost weight ! Merrimee's mass 0.03 Example: Nested Dictionary From the dictionary below, print \"Pandemic\" and \"Tokyo\": FD = {\"Quentin\":\"Tarantino\",\"2020\":[2020,\"COVID\",19,\"Pandemic\"],\"Bond\":[\"James\",\"Gun\",(\"Paris\",\"Tokyo\",\"London\")]} #A nested dictionary print(FD) {'Quentin': 'Tarantino', '2020': [2020, 'COVID', 19, 'Pandemic'], 'Bond': ['James', 'Gun', ('Paris', 'Tokyo', 'London')]} FD['2020'][3] 'Pandemic' FD['Bond'][2][1] 'Tokyo' Conditional Execution Conditional statements are logical expressions that evaluate as TRUE or FALSE and using these results to perform further operations based on these conditions. All flow control in a program depends on evaluating conditions. The program will proceed diferently based on the outcome of one or more conditions - really sophisticated AI programs are a collection of conditions and correlations. Amazon knowing what you kind of want is based on correlations of your past behavior compared to other peoples similar, butmore recent behavior, and then it uses conditional statements to decide what item to offer you in your recommendation items. It's spooky, but ultimately just a program running in the background trying to make your money theirs. Conditional Execution: Comparison The most common conditional operation is comparison. If we wish to compare whether two variables are the same we use the == (double equal sign). For example x == y means the program will ask whether x and y have the same value. If they do, the result is TRUE if not then the result is FALSE. Other comparison signs are != does NOT equal, < smaller than, > larger than, <= less than or equal, and >= greater than or equal. There are also three logical operators when we want to build multiple compares (multiple conditioning); these are and , or , and not . The and operator returns TRUE if (and only if) all conditions are TRUE. For instance 5 == 5 and 5 < 6 will return a TRUE because both conditions are true. The or operator returns TRUE if at least one condition is true. If all conditions are FALSE, then it will return a FALSE. For instance 4 > 3 or 17 > 20 or 3 == 2 will return TRUE because the first condition is true. The not operator returns TRUE if the condition after the not keyword is false. Think of it as a way to do a logic reversal. # Compare x = 7 y = 10 print(\"x =: \",x,\"y =: \",y) print(\"x is equal to y : \",x==y) print(\"x is not equal to y : \",x!=y) print(\"x is greater than y : \",x>y) print(\"x is less than y : \",x<y) x =: 7 y =: 10 x is equal to y : False x is not equal to y : True x is greater than y : False x is less than y : True # Logical operators print(\"5 == 5 and 5 < 6 ? \",5 == 5 and 5 < 6) print(\"4 > 3 or 17 > 20 \",4 > 3 or 17 > 20) print(\"not 5 == 5\",not 5 == 5) 5 == 5 and 5 < 6 ? True 4 > 3 or 17 > 20 True not 5 == 5 False Conditional Execution: Block if statement The if statement is a common flow control statement. It allows the program to evaluate if a certain condition is satisfied and to perform a designed action based on the result of the evaluation. The structure of an if statement is if condition1 is met: do A elif condition 2 is met: do b elif condition 3 is met: do c else: do e The elif means \"else if\". The : colon is an important part of the structure it tells where the action begins. Also there are no scope delimiters like (), or {} . Instead Python uses indentation to isolate blocks of code. This convention is hugely important - many other coding environments use delimiters (called scoping delimiters), but Python does not. The indentation itself is the scoping delimiter. The next code fragment illustrates illustrates how the if statements work. The program asks the user for input. The use of raw_input() will let the program read any input as a string so non-numeric results will not throw an error. The input is stored in the variable named userInput . Next the statement if userInput == \"1\": compares the value of userInput with the string \"1\" . If the value in the variable is indeed \\1\", then the program will execute the block of code in the indentation after the colon. In this case it will execute print \"Hello World\" print \"How do you do? \" Alternatively, if the value of userInput is the string '2' , then the program will execute print \"Snakes on a plane \" For all other values the program will execute print \"You did not enter a valid number\" # Block if example userInput = input('Enter the number 1 or 2') # Use block if structure if userInput == '1': print(\"Hello World\") print(\"How do you do? \") elif userInput == '2': print(\"Snakes on a plane \") else: print(\"You did not enter a valid number\") Enter the number 1 or 21 Hello World How do you do? Conditional Execution: Inline if statement An inline if statement is a simpler form of an if statement and is more convenient if you only need to perform a simple conditional task. The syntax is: do TaskA `if` condition is true `else` do TaskB An example would be myInt = 3 num1 = 12 if myInt == 0 else 13 num1 An alternative way is to enclose the condition in brackets for some clarity like myInt = 3 num1 = 12 if (myInt == 0) else 13 num1 In either case the result is that num1 will have the value 13 (unless you set myInt to 0). One can also use if to construct extremely inefficient loops. myInt = 0 num1 = 12 if (myInt == 0) else 13 num1 12 Example: Pass or Fail? Take the following inputs from the user: 1. Grade for Lesson 1 (from 0 to 5) 2. Grade for Lesson 2 (from 0 to 5) 3. Grade for Lesson 3 (from 0 to 5) Compute the average of the three grades. Use the result to decide whether the student will pass or fail. Lesson1 = int(input('Enter the grade for Lesson 1')) Lesson2 = int(input('Enter the grade for Lesson 2')) Lesson3 = int(input('Enter the grade for Lesson 3')) Average = int(Lesson1+Lesson2+Lesson3)/3 print('Average Course Grade:',Average) if Average >= 5: print(\"Passed\") else: print(\"Failed\") Enter the grade for Lesson 12 Enter the grade for Lesson 25 Enter the grade for Lesson 31 Average Course Grade: 2.6666666666666665 Failed Here are some great reads on this topic: - \"Common Python Data Structures (Guide)\" by Dan Bader available at https://realpython.com/python-data-structures/ - \"Data Structures You Need To Learn In Python\" by Akash available at https://www.edureka.co/blog/data-structures-in-python/ - \"Data Structures in Python\u2014 A Brief Introduction\" by Sowmya Krishnan available at https://towardsdatascience.com/data-structures-in-python-a-brief-introduction-b4135d7a9b7d - \"Everything you Should Know About Data Structures in Python\" by ANIRUDDHA BHANDARI available at https://www.analyticsvidhya.com/blog/2020/06/data-structures-python/ - \"Conditional Statements in Python\" by John Sturtz available at https://realpython.com/python-conditional-statements/ - \"Python If Statement explained with examples\" by CHAITANYA SINGH available at https://beginnersbook.com/2018/01/python-if-statement-example/ Here are some great videos on these topics: - \"Python: Data Structures - Lists, Tuples, Sets & Dictionaries tutorial\" by Joe James available at https://www.youtube.com/watch?v=R-HLU9Fl5ug&t=92s - \"Python Tutorial for Beginners 5: Dictionaries - Working with Key-Value Pairs\" by Corey Schafer available at https://www.youtube.com/watch?v=daefaLgNkw0 - \"How to Use If Else Statements in Python (Python Tutorial #2)\" by CS Dojo available at https://www.youtube.com/watch?v=AWek49wXGzI - \"Python If Statements | Python Tutorial #10\" by Amigoscode available at https://www.youtube.com/watch?v=wKQRmXR3jhc Exercise: Why dictionaries? Why do we need to use dictionaries in python? * Make sure to cite any resources that you may use.","title":"Workshop 2"},{"location":"8-Labs/Lab2/Lab2_Dev/#laboratory-2-structures-and-conditions","text":"# Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) DESKTOP-EH6HD63 desktop-eh6hd63\\farha C:\\Users\\Farha\\Anaconda3\\python.exe 3.7.4 (default, Aug 9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)","title":"Laboratory 2: Structures and Conditions. "},{"location":"8-Labs/Lab2/Lab2_Dev/#full-name","text":"","title":"Full name:"},{"location":"8-Labs/Lab2/Lab2_Dev/#r","text":"","title":"R#:"},{"location":"8-Labs/Lab2/Lab2_Dev/#title-of-the-notebook","text":"","title":"Title of the notebook:"},{"location":"8-Labs/Lab2/Lab2_Dev/#date","text":"","title":"Date:"},{"location":"8-Labs/Lab2/Lab2_Dev/#data-structures-list-array","text":"A list is a collection of data that are somehow related. It is a convenient way to refer to a collection of similar things by a single name, and using an index (like a subscript in math) to identify a particular item. Consider the \"math-like\" variable x below: \\begin{gather} x_0= 7 \\ x_1= 11 \\ x_2= 5 \\ x_3= 9 \\ x_4= 13 \\ ... \\ x_N= 223 \\ \\end{gather} The variable name is x and the subscripts correspond to different values. Thus the value of the variable named x associated with subscript 3 is the number 9 . The figure below is a visual representation of a the concept that treats a variable as a collection of cells. In the figure, the variable name is MyList , the subscripts are replaced by an index which identifies which cell is being referenced. The value is the cell content at the particular index. So in the figure the value of MyList at Index = 3 is the number 9.' In engineering and data science we use lists a lot - we often call then vectors, arrays, matrices and such, but they are ultimately just lists. To declare a list you can write the list name and assign it values. The square brackets are used to identify that the variable is a list. Like: MyList = [7,11,5,9,13,66,99,223] One can also declare a null list and use the append() method to fill it as needed. MyOtherList = [ ] Python indices start at ZERO. Alot of other lnguages start at ONE. Its just the convention. The first element in a list has an index of 0, the second an index of 1, and so on. We access the contents of a list by referring to its name and index. For example MyList[3] has a value of the number 9. MyOtherList = [] #Create an empty list MyOtherList.append(765) #Add one item to the list print(MyOtherList) MyList = [7,11,5,9,13,66,99,223] #Define a list print(MyList) sublist = MyList[3:6] #slice a sublist print(\"sublist is: \", sublist) mysum = sum(sublist) #sum the numbers in the sublist print(\"Sum: \", mysum) mylength = len(sublist) #get the length of the sublist print(\"Length: \", mylength) [765] [7, 11, 5, 9, 13, 66, 99, 223] sublist is: [9, 13, 66] Sum: 88 Length: 3","title":"Data Structures: List (Array)"},{"location":"8-Labs/Lab2/Lab2_Dev/#data-structures-special-list-tuple","text":"A tuple is a special kind of list where the values cannot be changed after the list is created. It is useful for list-like things that are static - like days in a week, or months of a year. You declare a tuple like a list, except use round brackets instead of square brackets. MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\")","title":"Data Structures: Special List | Tuple"},{"location":"8-Labs/Lab2/Lab2_Dev/#data-structures-special-list-dictionary","text":"A dictionary is a special kind of list where the items are related data PAIRS. It is a lot like a relational database (it probably is one in fact) where the first item in the pair is called the key, and must be unique in a dictionary, and the second item in the pair is the data. The second item could itself be a list, so a dictionary would be a meaningful way to build a database in Python. To declare a dictionary using curly brackets MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} To declare a dictionary using the dict() method MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) Some examples follow: MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") MyTupleName ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec') MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} print(MyPetsNamesAndMass) MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) print(MyPetsNamesAndMassToo) {'Dusty': 7.8, 'Aspen': 6.3, 'Merrimee': 0.03} {'Dusty': 7.8, 'Aspen': 6.3, 'Merrimee': 0.03} # Tuples MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") # Access a Tuple print (\"5th element of the tuple:\", MyTupleName[4]) # Dictionary MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} # Access the Dictionary print (\"Aspen's mass = \", MyPetsNamesAndMass[\"Aspen\"]) # Change a value in a dictionary print (\"Merrimee's mass\" , MyPetsNamesAndMass[\"Merrimee\"]) MyPetsNamesAndMass[\"Merrimee\"] = 0.01 print (\"Merrimee's mass\" , MyPetsNamesAndMass[\"Merrimee\"], \"She lost weight !\") # Alternate dictionary MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) print (\"Merrimee's mass\" , MyPetsNamesAndMassToo[\"Merrimee\"]) # Attempt to change a Tuple #MyTupleName[3]=(\"Fred\") # Activate this line and see what happens! 5th element of the tuple: May Aspen's mass = 6.3 Merrimee's mass 0.03 Merrimee's mass 0.01 She lost weight ! Merrimee's mass 0.03","title":"Data Structures: Special List | Dictionary"},{"location":"8-Labs/Lab2/Lab2_Dev/#example-nested-dictionary","text":"From the dictionary below, print \"Pandemic\" and \"Tokyo\": FD = {\"Quentin\":\"Tarantino\",\"2020\":[2020,\"COVID\",19,\"Pandemic\"],\"Bond\":[\"James\",\"Gun\",(\"Paris\",\"Tokyo\",\"London\")]} #A nested dictionary print(FD) {'Quentin': 'Tarantino', '2020': [2020, 'COVID', 19, 'Pandemic'], 'Bond': ['James', 'Gun', ('Paris', 'Tokyo', 'London')]} FD['2020'][3] 'Pandemic' FD['Bond'][2][1] 'Tokyo'","title":"Example: Nested Dictionary"},{"location":"8-Labs/Lab2/Lab2_Dev/#conditional-execution","text":"Conditional statements are logical expressions that evaluate as TRUE or FALSE and using these results to perform further operations based on these conditions. All flow control in a program depends on evaluating conditions. The program will proceed diferently based on the outcome of one or more conditions - really sophisticated AI programs are a collection of conditions and correlations. Amazon knowing what you kind of want is based on correlations of your past behavior compared to other peoples similar, butmore recent behavior, and then it uses conditional statements to decide what item to offer you in your recommendation items. It's spooky, but ultimately just a program running in the background trying to make your money theirs.","title":"Conditional Execution"},{"location":"8-Labs/Lab2/Lab2_Dev/#conditional-execution-comparison","text":"The most common conditional operation is comparison. If we wish to compare whether two variables are the same we use the == (double equal sign). For example x == y means the program will ask whether x and y have the same value. If they do, the result is TRUE if not then the result is FALSE. Other comparison signs are != does NOT equal, < smaller than, > larger than, <= less than or equal, and >= greater than or equal. There are also three logical operators when we want to build multiple compares (multiple conditioning); these are and , or , and not . The and operator returns TRUE if (and only if) all conditions are TRUE. For instance 5 == 5 and 5 < 6 will return a TRUE because both conditions are true. The or operator returns TRUE if at least one condition is true. If all conditions are FALSE, then it will return a FALSE. For instance 4 > 3 or 17 > 20 or 3 == 2 will return TRUE because the first condition is true. The not operator returns TRUE if the condition after the not keyword is false. Think of it as a way to do a logic reversal. # Compare x = 7 y = 10 print(\"x =: \",x,\"y =: \",y) print(\"x is equal to y : \",x==y) print(\"x is not equal to y : \",x!=y) print(\"x is greater than y : \",x>y) print(\"x is less than y : \",x<y) x =: 7 y =: 10 x is equal to y : False x is not equal to y : True x is greater than y : False x is less than y : True # Logical operators print(\"5 == 5 and 5 < 6 ? \",5 == 5 and 5 < 6) print(\"4 > 3 or 17 > 20 \",4 > 3 or 17 > 20) print(\"not 5 == 5\",not 5 == 5) 5 == 5 and 5 < 6 ? True 4 > 3 or 17 > 20 True not 5 == 5 False","title":"Conditional Execution: Comparison"},{"location":"8-Labs/Lab2/Lab2_Dev/#conditional-execution-block-if-statement","text":"The if statement is a common flow control statement. It allows the program to evaluate if a certain condition is satisfied and to perform a designed action based on the result of the evaluation. The structure of an if statement is if condition1 is met: do A elif condition 2 is met: do b elif condition 3 is met: do c else: do e The elif means \"else if\". The : colon is an important part of the structure it tells where the action begins. Also there are no scope delimiters like (), or {} . Instead Python uses indentation to isolate blocks of code. This convention is hugely important - many other coding environments use delimiters (called scoping delimiters), but Python does not. The indentation itself is the scoping delimiter. The next code fragment illustrates illustrates how the if statements work. The program asks the user for input. The use of raw_input() will let the program read any input as a string so non-numeric results will not throw an error. The input is stored in the variable named userInput . Next the statement if userInput == \"1\": compares the value of userInput with the string \"1\" . If the value in the variable is indeed \\1\", then the program will execute the block of code in the indentation after the colon. In this case it will execute print \"Hello World\" print \"How do you do? \" Alternatively, if the value of userInput is the string '2' , then the program will execute print \"Snakes on a plane \" For all other values the program will execute print \"You did not enter a valid number\" # Block if example userInput = input('Enter the number 1 or 2') # Use block if structure if userInput == '1': print(\"Hello World\") print(\"How do you do? \") elif userInput == '2': print(\"Snakes on a plane \") else: print(\"You did not enter a valid number\") Enter the number 1 or 21 Hello World How do you do?","title":"Conditional Execution:  Block if statement"},{"location":"8-Labs/Lab2/Lab2_Dev/#conditional-execution-inline-if-statement","text":"An inline if statement is a simpler form of an if statement and is more convenient if you only need to perform a simple conditional task. The syntax is: do TaskA `if` condition is true `else` do TaskB An example would be myInt = 3 num1 = 12 if myInt == 0 else 13 num1 An alternative way is to enclose the condition in brackets for some clarity like myInt = 3 num1 = 12 if (myInt == 0) else 13 num1 In either case the result is that num1 will have the value 13 (unless you set myInt to 0). One can also use if to construct extremely inefficient loops. myInt = 0 num1 = 12 if (myInt == 0) else 13 num1 12","title":"Conditional Execution:  Inline if statement"},{"location":"8-Labs/Lab2/Lab2_Dev/#example-pass-or-fail","text":"Take the following inputs from the user: 1. Grade for Lesson 1 (from 0 to 5) 2. Grade for Lesson 2 (from 0 to 5) 3. Grade for Lesson 3 (from 0 to 5) Compute the average of the three grades. Use the result to decide whether the student will pass or fail. Lesson1 = int(input('Enter the grade for Lesson 1')) Lesson2 = int(input('Enter the grade for Lesson 2')) Lesson3 = int(input('Enter the grade for Lesson 3')) Average = int(Lesson1+Lesson2+Lesson3)/3 print('Average Course Grade:',Average) if Average >= 5: print(\"Passed\") else: print(\"Failed\") Enter the grade for Lesson 12 Enter the grade for Lesson 25 Enter the grade for Lesson 31 Average Course Grade: 2.6666666666666665 Failed Here are some great reads on this topic: - \"Common Python Data Structures (Guide)\" by Dan Bader available at https://realpython.com/python-data-structures/ - \"Data Structures You Need To Learn In Python\" by Akash available at https://www.edureka.co/blog/data-structures-in-python/ - \"Data Structures in Python\u2014 A Brief Introduction\" by Sowmya Krishnan available at https://towardsdatascience.com/data-structures-in-python-a-brief-introduction-b4135d7a9b7d - \"Everything you Should Know About Data Structures in Python\" by ANIRUDDHA BHANDARI available at https://www.analyticsvidhya.com/blog/2020/06/data-structures-python/ - \"Conditional Statements in Python\" by John Sturtz available at https://realpython.com/python-conditional-statements/ - \"Python If Statement explained with examples\" by CHAITANYA SINGH available at https://beginnersbook.com/2018/01/python-if-statement-example/ Here are some great videos on these topics: - \"Python: Data Structures - Lists, Tuples, Sets & Dictionaries tutorial\" by Joe James available at https://www.youtube.com/watch?v=R-HLU9Fl5ug&t=92s - \"Python Tutorial for Beginners 5: Dictionaries - Working with Key-Value Pairs\" by Corey Schafer available at https://www.youtube.com/watch?v=daefaLgNkw0 - \"How to Use If Else Statements in Python (Python Tutorial #2)\" by CS Dojo available at https://www.youtube.com/watch?v=AWek49wXGzI - \"Python If Statements | Python Tutorial #10\" by Amigoscode available at https://www.youtube.com/watch?v=wKQRmXR3jhc","title":"Example: Pass or Fail?"},{"location":"8-Labs/Lab2/Lab2_Dev/#exercise-why-dictionaries","text":"","title":"Exercise: Why dictionaries? "},{"location":"8-Labs/Lab2/Lab2_Dev/#why-do-we-need-to-use-dictionaries-in-python","text":"","title":"Why do we need to use dictionaries in python?"},{"location":"8-Labs/Lab2/Lab2_Dev/#make-sure-to-cite-any-resources-that-you-may-use","text":"","title":"* Make sure to cite any resources that you may use."},{"location":"8-Labs/Lab6/Lab6_Dev/","text":"Laboratory 6: Numpy for Bread! # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) DESKTOP-EH6HD63 desktop-eh6hd63\\farha C:\\Users\\Farha\\Anaconda3\\python.exe 3.7.4 (default, Aug 9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0) Full name: R#: Title of the notebook: Date: Numpy Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays. The library\u2019s name is short for \u201cNumeric Python\u201d or \u201cNumerical Python\u201d. If you are curious about NumPy, this cheat sheet is recommended: https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf Arrays A numpy array is a grid of values, all of the same type, and is indexed by a tuple of nonnegative integers. The number of dimensions is the rank of the array; the shape of an array is a tuple of integers giving the size of the array along each dimension. In other words, an array contains information about the raw data, how to locate an element and how to interpret an element.To make a numpy array, you can just use the np.array() function. All you need to do is pass a list to it. Don\u2019t forget that, in order to work with the np.array() function, you need to make sure that the numpy library is present in your environment. If you want to read more about the differences between a Python list and NumPy array, this link is recommended: https://webcourses.ucf.edu/courses/1249560/pages/python-lists-vs-numpy-arrays-what-is-the-difference Example- 1D Arrays Let's create a 1D array from the 2000s (2000-2009): import numpy as np #First, we need to impoty \"numpy\" mylist = [2000,2001,2002,2003,2004,2005,2006,2007,2008,2009] #Create a list of the years print(mylist) #Check how it looks np.array(mylist) #Define it as a numpy array [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009] array([2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009]) Example- n-Dimensional Arrays Let's create a 5x2 array from the 2000s (2000-2009): myotherlist = [[2000,2001],[2002,2003],[2004,2005],[2006,2007],[2008,2009]] #Since I want a 5x2 array, I should group the years two by two print(myotherlist) #See how it looks as a list np.array(myotherlist) #See how it looks as a numpy array [[2000, 2001], [2002, 2003], [2004, 2005], [2006, 2007], [2008, 2009]] array([[2000, 2001], [2002, 2003], [2004, 2005], [2006, 2007], [2008, 2009]]) Arrays Arithmetic Once you have created the arrays, you can do basic Numpy operations. Numpy offers a variety of operations applicable on arrays. From basic operations such as summation, subtraction, multiplication and division to more advanced and essential operations such as matrix multiplication and other elementwise operations. In the examples below, we will go over some of these: Example- 1D Array Arithmetic Define a 1D array with [0,12,24,36,48,60,72,84,96] Multiple all elements by 2 Take all elements to the power of 2 Find the maximum value of the array and its position Find the minimum value of the array and its position Define another 1D array with [-12,0,12,24,36,48,60,72,84] Find the summation and subtraction of these two arrays Find the multiplication of these two arrays import numpy as np #import numpy Array1 = np.array([0,12,24,36,48,60,72,84,96]) #Step1: Define Array1 print(Array1) print(Array1*2) #Step2: Multiple all elements by 2 print(Array1**2) #Step3: Take all elements to the power of 2 print(np.power(Array1,2)) #Another way to do the same thing, by using a function in numpy print(np.max(Array1)) #Step4: Find the maximum value of the array print(np.argmax(Array1)) ##Step4: Find the postition of the maximum value print(np.min(Array1)) #Step5: Find the minimum value of the array print(np.argmin(Array1)) ##Step5: Find the postition of the minimum value Array2 = np.array([-12,0,12,24,36,48,60,72,84]) #Step6: Define Array2 print(Array2) print(Array1+Array2) #Step7: Find the summation of these two arrays print(Array1-Array2) #Step7: Find the subtraction of these two arrays print(Array1*Array2) #Step8: Find the multiplication of these two arrays [ 0 12 24 36 48 60 72 84 96] [ 0 24 48 72 96 120 144 168 192] [ 0 144 576 1296 2304 3600 5184 7056 9216] [ 0 144 576 1296 2304 3600 5184 7056 9216] 96 8 0 0 [-12 0 12 24 36 48 60 72 84] [-12 12 36 60 84 108 132 156 180] [12 12 12 12 12 12 12 12 12] [ 0 0 288 864 1728 2880 4320 6048 8064] Example- n-Dimensional Array Arithmetic Define a 2x2 array with [5,10,15,20] Define another 2x2 array with [3,6,9,12] Find the summation and subtraction of these two arrays Find the minimum number in the multiplication of these two arrays Find the position of the maximum in the multiplication of these two arrays Find the mean of the multiplication of these two arrays Find the mean of the first row of the multiplication of these two arrays import numpy as np #import numpy Array1 = np.array([[5,10],[15,20]]) #Step1: Define Array1 print(Array1) Array2 = np.array([[3,6],[9,12]]) #Step2: Define Array2 print(Array2) print(Array1+Array2) #Step3: Find the summation print(Array1-Array2) #Step3: Find the subtraction MultArray = Array1@Array2 #Step4: To perform a typical matrix multiplication (or matrix product) MultArray1 = Array1.dot(Array2) #Step4: Another way To perform a matrix multiplication print(MultArray) print(MultArray1) print(np.min(MultArray)) #Step4: Find the minimum value of the multiplication print(np.argmax(MultArray)) ##Step5: Find the postition of the maximum value print(np.mean(MultArray)) ##Step6: Find the mean of the multiplication of these two arrays print(np.mean(MultArray[0,:])) ##Step7: Find the mean of the first row of the multiplication of these two arrays [[ 5 10] [15 20]] [[ 3 6] [ 9 12]] [[ 8 16] [24 32]] [[2 4] [6 8]] [[105 150] [225 330]] [[105 150] [225 330]] 105 3 202.5 127.5 Arrays Comparison Comparing two NumPy arrays determines whether they are equivalent by checking if every element at each corresponding index are the same. Example- 1D Array Comparison Define a 1D array with [1.0,2.5,3.4,7,7] Define another 1D array with [5.0/5.0,5.0/2,6.8/2,21/3,14/2] Compare and see if the two arrays are equal Define another 1D array with [6,1.4,2.2,7.5,7] Compare and see if the first array is greater than or equal to the third array import numpy as np #import numpy Array1 = np.array([1.0,2.5,3.4,7,7]) #Step1: Define Array1 print(Array1) Array2 = np.array([5.0/5.0,5.0/2,6.8/2,21/3,14/2]) #Step2: Define Array1 print(Array2) print(np.equal(Array1, Array2)) #Step3: Compare and see if the two arrays are equal Array3 = np.array([6,1.4,2.2,7.5,7]) #Step4: Define Array3 print(Array3) print(np.greater_equal(Array1, Array3)) #Step3: Compare and see if the two arrays are equal [1. 2.5 3.4 7. 7. ] [1. 2.5 3.4 7. 7. ] [ True True True True True] [6. 1.4 2.2 7.5 7. ] [False True True False True] Arrays Manipulation numpy.copy() allows us to create a copy of an array. This is particularly useful when we need to manipulate an array while keeping an original copy in memory. The numpy.delete() function returns a new array with sub-arrays along an axis deleted. Let's have a look at the examples. Example- Copying and Deleting Arrays and Elements Define a 1D array, named \"x\" with [1,2,3] Define \"y\" so that \"y=x\" Define \"z\" as a copy of \"x\" Discuss the difference between y and z Delete the second element of x import numpy as np #import numpy x = np.array([1,2,3]) #Step1: Define x print(x) y = x #Step2: Define y as y=x print(y) z = np.copy(x) #Step3: Define z as a copy of x print(z) # For Step4: They look similar but check this out: x[1] = 8 # If we change x ... print(x) print(y) print(z) # By modifying x, y changes but z remains as a copy of the initial version of x. x = np.delete(x, 1) #Step5: Delete the second element of x print(x) [1 2 3] [1 2 3] [1 2 3] [1 8 3] [1 8 3] [1 2 3] [1 3] Sorting Arrays Sorting means putting elements in an ordered sequence. Ordered sequence is any sequence that has an order corresponding to elements, like numeric or alphabetical, ascending or descending. If you use the sort() method on a 2-D array, both arrays will be sorted. Example- Sorting 1D Arrays Define a 1D array as ['FIFA 2020','Red Dead Redemption','Fallout','GTA','NBA 2018','Need For Speed'] and print it out. Then, sort the array alphabetically. import numpy as np #import numpy games = np.array(['FIFA 2020','Red Dead Redemption','Fallout','GTA','NBA 2018','Need For Speed']) print(games) print(np.sort(games)) ['FIFA 2020' 'Red Dead Redemption' 'Fallout' 'GTA' 'NBA 2018' 'Need For Speed'] ['FIFA 2020' 'Fallout' 'GTA' 'NBA 2018' 'Need For Speed' 'Red Dead Redemption'] Example- Sorting n-Dimensional Arrays Define a 3x3 array with 17,-6,2,86,-12,0,0,23,12 and print it out. Then, sort the array. import numpy as np #import numpy a = np.array([[17,-6,2],[86,-12,0],[0,23,12]]) print(a) print (\"Along columns : \\n\", np.sort(a,axis = 0) ) #This will be sorting in each column print (\"Along rows : \\n\", np.sort(a,axis = 1) ) #This will be sorting in each row print (\"Sorting by default : \\n\", np.sort(a) ) #Same as above print (\"Along None Axis : \\n\", np.sort(a,axis = None) ) #This will be sorted like a 1D array [[ 17 -6 2] [ 86 -12 0] [ 0 23 12]] Along columns : [[ 0 -12 0] [ 17 -6 2] [ 86 23 12]] Along rows : [[ -6 2 17] [-12 0 86] [ 0 12 23]] Sorting by default : [[ -6 2 17] [-12 0 86] [ 0 12 23]] Along None Axis : [-12 -6 0 0 2 12 17 23 86] Partitioning (Slice) Arrays Slicing in python means taking elements from one given index to another given index. We can do slicing like this: [start:end]. We can also define the step, like this: [start:end:step]. If we don't pass start its considered 0 If we don't pass end its considered length of array in that dimension If we don't pass step its considered 1 Example- Slicing 1D Arrays Define a 1D array as [1,3,5,7,9], slice out the [3,5,7] and print it out. import numpy as np #import numpy a = np.array([1,3,5,7,9]) #Define the array print(a) aslice = a[1:4] #slice the [3,5,7] print(aslice) #print it out [1 3 5 7 9] [3 5 7] Example- Slicing n-Dimensional Arrays Define a 5x5 array with \"Superman, Batman, Jim Hammond, Captain America, Green Arrow, Aquaman, Wonder Woman, Martian Manhunter, Barry Allen, Hal Jordan, Hawkman, Ray Palmer, Spider Man, Thor, Hank Pym, Solar, Iron Man, Dr. Strange, Daredevil, Ted Kord, Captian Marvel, Black Panther, Wolverine, Booster Gold, Spawn \" and print it out. Then: - Slice the first column and print it out - Slice the third row and print it out - Slice 'Wolverine' and print it out - Slice a 3x3 array with 'Wonder Woman, Ray Palmer, Iron Man, Martian Manhunter, Spider Man, Dr. Strange, Barry Allen, Thor, Daredevil' import numpy as np #import numpy Superheroes = np.array([['Superman', 'Batman', 'Jim Hammond', 'Captain America', 'Green Arrow'], ['Aquaman', 'Wonder Woman', 'Martian Manhunter', 'Barry Allen', 'Hal Jordan'], ['Hawkman', 'Ray Palmer', 'Spider Man', 'Thor', 'Hank Pym'], ['Solar', 'Iron Man', 'Dr. Strange', 'Daredevil', 'Ted Kord'], ['Captian Marvel', 'Black Panther', 'Wolverine', 'Booster Gold', 'Spawn']]) print(Superheroes) #Step1 print(Superheroes[:,0]) print(Superheroes[2,:]) print(Superheroes[4,2]) print(Superheroes[1:4,1:4]) [['Superman' 'Batman' 'Jim Hammond' 'Captain America' 'Green Arrow'] ['Aquaman' 'Wonder Woman' 'Martian Manhunter' 'Barry Allen' 'Hal Jordan'] ['Hawkman' 'Ray Palmer' 'Spider Man' 'Thor' 'Hank Pym'] ['Solar' 'Iron Man' 'Dr. Strange' 'Daredevil' 'Ted Kord'] ['Captian Marvel' 'Black Panther' 'Wolverine' 'Booster Gold' 'Spawn']] ['Superman' 'Aquaman' 'Hawkman' 'Solar' 'Captian Marvel'] ['Hawkman' 'Ray Palmer' 'Spider Man' 'Thor' 'Hank Pym'] Wolverine [['Wonder Woman' 'Martian Manhunter' 'Barry Allen'] ['Ray Palmer' 'Spider Man' 'Thor'] ['Iron Man' 'Dr. Strange' 'Daredevil']] This is a Numpy Cheat Sheet- similar to the one you had on top of this notebook! Check out this link for more: https://blog.finxter.com/collection-10-best-numpy-cheat-sheets-every-python-coder-must-own/ Here are some of the resources used for creating this notebook: - Johnson, J. (2020). Python Numpy Tutorial (with Jupyter and Colab). Retrieved September 15, 2020, from https://cs231n.github.io/python-numpy-tutorial/ - Willems, K. (2019). (Tutorial) Python NUMPY Array TUTORIAL. Retrieved September 15, 2020, from https://www.datacamp.com/community/tutorials/python-numpy-tutorial?utm_source=adwords_ppc - Willems, K. (2017). NumPy Cheat Sheet: Data Analysis in Python. Retrieved September 15, 2020, from https://www.datacamp.com/community/blog/python-numpy-cheat-sheet - W3resource. (2020). NumPy: Compare two given arrays. Retrieved September 15, 2020, from https://www.w3resource.com/python-exercises/numpy/python-numpy-exercise-28.php Here are some great reads on this topic: - \"Python NumPy Tutorial\" available at https://www.geeksforgeeks.org/python-numpy-tutorial/ - \"What Is NumPy?\" a collection of blogs, available at https://realpython.com/tutorials/numpy/ - \"Look Ma, No For-Loops: Array Programming With NumPy\" by Brad Solomon available at https://realpython.com/numpy-array-programming/ - \"The Ultimate Beginner\u2019s Guide to NumPy\" by Anne Bonner available at https://towardsdatascience.com/the-ultimate-beginners-guide-to-numpy-f5a2f99aef54 Here are some great videos on these topics: - \"Learn NUMPY in 5 minutes - BEST Python Library!\" by Python Programmer available at https://www.youtube.com/watch?v=xECXZ3tyONo - \"Python NumPy Tutorial for Beginners\" by freeCodeCamp.org available at https://www.youtube.com/watch?v=QUT1VHiLmmI - \"Complete Python NumPy Tutorial (Creating Arrays, Indexing, Math, Statistics, Reshaping)\" by Keith Galli available at https://www.youtube.com/watch?v=GB9ByFAIAH4 - \"Python NumPy Tutorial | NumPy Array | Python Tutorial For Beginners | Python Training | Edureka\" by edureka! available at https://www.youtube.com/watch?v=8JfDAm9y_7s Exercise: Python List vs. Numpy Arrays? What are some differences between Python lists and Numpy arrays? * Make sure to cite any resources that you may use.","title":"Workshop 6"},{"location":"8-Labs/Lab6/Lab6_Dev/#laboratory-6-numpy-for-bread","text":"# Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) DESKTOP-EH6HD63 desktop-eh6hd63\\farha C:\\Users\\Farha\\Anaconda3\\python.exe 3.7.4 (default, Aug 9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)","title":"Laboratory 6: Numpy for Bread! "},{"location":"8-Labs/Lab6/Lab6_Dev/#full-name","text":"","title":"Full name:"},{"location":"8-Labs/Lab6/Lab6_Dev/#r","text":"","title":"R#:"},{"location":"8-Labs/Lab6/Lab6_Dev/#title-of-the-notebook","text":"","title":"Title of the notebook:"},{"location":"8-Labs/Lab6/Lab6_Dev/#date","text":"","title":"Date:"},{"location":"8-Labs/Lab6/Lab6_Dev/#numpy","text":"Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays. The library\u2019s name is short for \u201cNumeric Python\u201d or \u201cNumerical Python\u201d. If you are curious about NumPy, this cheat sheet is recommended: https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf","title":"Numpy"},{"location":"8-Labs/Lab6/Lab6_Dev/#arrays","text":"A numpy array is a grid of values, all of the same type, and is indexed by a tuple of nonnegative integers. The number of dimensions is the rank of the array; the shape of an array is a tuple of integers giving the size of the array along each dimension. In other words, an array contains information about the raw data, how to locate an element and how to interpret an element.To make a numpy array, you can just use the np.array() function. All you need to do is pass a list to it. Don\u2019t forget that, in order to work with the np.array() function, you need to make sure that the numpy library is present in your environment. If you want to read more about the differences between a Python list and NumPy array, this link is recommended: https://webcourses.ucf.edu/courses/1249560/pages/python-lists-vs-numpy-arrays-what-is-the-difference","title":"Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-1d-arrays","text":"Let's create a 1D array from the 2000s (2000-2009): import numpy as np #First, we need to impoty \"numpy\" mylist = [2000,2001,2002,2003,2004,2005,2006,2007,2008,2009] #Create a list of the years print(mylist) #Check how it looks np.array(mylist) #Define it as a numpy array [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009] array([2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009])","title":"Example- 1D Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-n-dimensional-arrays","text":"Let's create a 5x2 array from the 2000s (2000-2009): myotherlist = [[2000,2001],[2002,2003],[2004,2005],[2006,2007],[2008,2009]] #Since I want a 5x2 array, I should group the years two by two print(myotherlist) #See how it looks as a list np.array(myotherlist) #See how it looks as a numpy array [[2000, 2001], [2002, 2003], [2004, 2005], [2006, 2007], [2008, 2009]] array([[2000, 2001], [2002, 2003], [2004, 2005], [2006, 2007], [2008, 2009]])","title":"Example- n-Dimensional Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#arrays-arithmetic","text":"Once you have created the arrays, you can do basic Numpy operations. Numpy offers a variety of operations applicable on arrays. From basic operations such as summation, subtraction, multiplication and division to more advanced and essential operations such as matrix multiplication and other elementwise operations. In the examples below, we will go over some of these:","title":"Arrays Arithmetic"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-1d-array-arithmetic","text":"Define a 1D array with [0,12,24,36,48,60,72,84,96] Multiple all elements by 2 Take all elements to the power of 2 Find the maximum value of the array and its position Find the minimum value of the array and its position Define another 1D array with [-12,0,12,24,36,48,60,72,84] Find the summation and subtraction of these two arrays Find the multiplication of these two arrays import numpy as np #import numpy Array1 = np.array([0,12,24,36,48,60,72,84,96]) #Step1: Define Array1 print(Array1) print(Array1*2) #Step2: Multiple all elements by 2 print(Array1**2) #Step3: Take all elements to the power of 2 print(np.power(Array1,2)) #Another way to do the same thing, by using a function in numpy print(np.max(Array1)) #Step4: Find the maximum value of the array print(np.argmax(Array1)) ##Step4: Find the postition of the maximum value print(np.min(Array1)) #Step5: Find the minimum value of the array print(np.argmin(Array1)) ##Step5: Find the postition of the minimum value Array2 = np.array([-12,0,12,24,36,48,60,72,84]) #Step6: Define Array2 print(Array2) print(Array1+Array2) #Step7: Find the summation of these two arrays print(Array1-Array2) #Step7: Find the subtraction of these two arrays print(Array1*Array2) #Step8: Find the multiplication of these two arrays [ 0 12 24 36 48 60 72 84 96] [ 0 24 48 72 96 120 144 168 192] [ 0 144 576 1296 2304 3600 5184 7056 9216] [ 0 144 576 1296 2304 3600 5184 7056 9216] 96 8 0 0 [-12 0 12 24 36 48 60 72 84] [-12 12 36 60 84 108 132 156 180] [12 12 12 12 12 12 12 12 12] [ 0 0 288 864 1728 2880 4320 6048 8064]","title":"Example- 1D Array Arithmetic"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-n-dimensional-array-arithmetic","text":"Define a 2x2 array with [5,10,15,20] Define another 2x2 array with [3,6,9,12] Find the summation and subtraction of these two arrays Find the minimum number in the multiplication of these two arrays Find the position of the maximum in the multiplication of these two arrays Find the mean of the multiplication of these two arrays Find the mean of the first row of the multiplication of these two arrays import numpy as np #import numpy Array1 = np.array([[5,10],[15,20]]) #Step1: Define Array1 print(Array1) Array2 = np.array([[3,6],[9,12]]) #Step2: Define Array2 print(Array2) print(Array1+Array2) #Step3: Find the summation print(Array1-Array2) #Step3: Find the subtraction MultArray = Array1@Array2 #Step4: To perform a typical matrix multiplication (or matrix product) MultArray1 = Array1.dot(Array2) #Step4: Another way To perform a matrix multiplication print(MultArray) print(MultArray1) print(np.min(MultArray)) #Step4: Find the minimum value of the multiplication print(np.argmax(MultArray)) ##Step5: Find the postition of the maximum value print(np.mean(MultArray)) ##Step6: Find the mean of the multiplication of these two arrays print(np.mean(MultArray[0,:])) ##Step7: Find the mean of the first row of the multiplication of these two arrays [[ 5 10] [15 20]] [[ 3 6] [ 9 12]] [[ 8 16] [24 32]] [[2 4] [6 8]] [[105 150] [225 330]] [[105 150] [225 330]] 105 3 202.5 127.5","title":"Example- n-Dimensional Array Arithmetic"},{"location":"8-Labs/Lab6/Lab6_Dev/#arrays-comparison","text":"Comparing two NumPy arrays determines whether they are equivalent by checking if every element at each corresponding index are the same.","title":"Arrays Comparison"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-1d-array-comparison","text":"Define a 1D array with [1.0,2.5,3.4,7,7] Define another 1D array with [5.0/5.0,5.0/2,6.8/2,21/3,14/2] Compare and see if the two arrays are equal Define another 1D array with [6,1.4,2.2,7.5,7] Compare and see if the first array is greater than or equal to the third array import numpy as np #import numpy Array1 = np.array([1.0,2.5,3.4,7,7]) #Step1: Define Array1 print(Array1) Array2 = np.array([5.0/5.0,5.0/2,6.8/2,21/3,14/2]) #Step2: Define Array1 print(Array2) print(np.equal(Array1, Array2)) #Step3: Compare and see if the two arrays are equal Array3 = np.array([6,1.4,2.2,7.5,7]) #Step4: Define Array3 print(Array3) print(np.greater_equal(Array1, Array3)) #Step3: Compare and see if the two arrays are equal [1. 2.5 3.4 7. 7. ] [1. 2.5 3.4 7. 7. ] [ True True True True True] [6. 1.4 2.2 7.5 7. ] [False True True False True]","title":"Example- 1D Array Comparison"},{"location":"8-Labs/Lab6/Lab6_Dev/#arrays-manipulation","text":"numpy.copy() allows us to create a copy of an array. This is particularly useful when we need to manipulate an array while keeping an original copy in memory. The numpy.delete() function returns a new array with sub-arrays along an axis deleted. Let's have a look at the examples.","title":"Arrays Manipulation"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-copying-and-deleting-arrays-and-elements","text":"Define a 1D array, named \"x\" with [1,2,3] Define \"y\" so that \"y=x\" Define \"z\" as a copy of \"x\" Discuss the difference between y and z Delete the second element of x import numpy as np #import numpy x = np.array([1,2,3]) #Step1: Define x print(x) y = x #Step2: Define y as y=x print(y) z = np.copy(x) #Step3: Define z as a copy of x print(z) # For Step4: They look similar but check this out: x[1] = 8 # If we change x ... print(x) print(y) print(z) # By modifying x, y changes but z remains as a copy of the initial version of x. x = np.delete(x, 1) #Step5: Delete the second element of x print(x) [1 2 3] [1 2 3] [1 2 3] [1 8 3] [1 8 3] [1 2 3] [1 3]","title":"Example- Copying and Deleting Arrays and Elements"},{"location":"8-Labs/Lab6/Lab6_Dev/#sorting-arrays","text":"Sorting means putting elements in an ordered sequence. Ordered sequence is any sequence that has an order corresponding to elements, like numeric or alphabetical, ascending or descending. If you use the sort() method on a 2-D array, both arrays will be sorted.","title":"Sorting Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-sorting-1d-arrays","text":"Define a 1D array as ['FIFA 2020','Red Dead Redemption','Fallout','GTA','NBA 2018','Need For Speed'] and print it out. Then, sort the array alphabetically. import numpy as np #import numpy games = np.array(['FIFA 2020','Red Dead Redemption','Fallout','GTA','NBA 2018','Need For Speed']) print(games) print(np.sort(games)) ['FIFA 2020' 'Red Dead Redemption' 'Fallout' 'GTA' 'NBA 2018' 'Need For Speed'] ['FIFA 2020' 'Fallout' 'GTA' 'NBA 2018' 'Need For Speed' 'Red Dead Redemption']","title":"Example- Sorting 1D Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-sorting-n-dimensional-arrays","text":"Define a 3x3 array with 17,-6,2,86,-12,0,0,23,12 and print it out. Then, sort the array. import numpy as np #import numpy a = np.array([[17,-6,2],[86,-12,0],[0,23,12]]) print(a) print (\"Along columns : \\n\", np.sort(a,axis = 0) ) #This will be sorting in each column print (\"Along rows : \\n\", np.sort(a,axis = 1) ) #This will be sorting in each row print (\"Sorting by default : \\n\", np.sort(a) ) #Same as above print (\"Along None Axis : \\n\", np.sort(a,axis = None) ) #This will be sorted like a 1D array [[ 17 -6 2] [ 86 -12 0] [ 0 23 12]] Along columns : [[ 0 -12 0] [ 17 -6 2] [ 86 23 12]] Along rows : [[ -6 2 17] [-12 0 86] [ 0 12 23]] Sorting by default : [[ -6 2 17] [-12 0 86] [ 0 12 23]] Along None Axis : [-12 -6 0 0 2 12 17 23 86]","title":"Example- Sorting n-Dimensional Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#partitioning-slice-arrays","text":"Slicing in python means taking elements from one given index to another given index. We can do slicing like this: [start:end]. We can also define the step, like this: [start:end:step]. If we don't pass start its considered 0 If we don't pass end its considered length of array in that dimension If we don't pass step its considered 1","title":"Partitioning (Slice) Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-slicing-1d-arrays","text":"Define a 1D array as [1,3,5,7,9], slice out the [3,5,7] and print it out. import numpy as np #import numpy a = np.array([1,3,5,7,9]) #Define the array print(a) aslice = a[1:4] #slice the [3,5,7] print(aslice) #print it out [1 3 5 7 9] [3 5 7]","title":"Example- Slicing 1D Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#example-slicing-n-dimensional-arrays","text":"Define a 5x5 array with \"Superman, Batman, Jim Hammond, Captain America, Green Arrow, Aquaman, Wonder Woman, Martian Manhunter, Barry Allen, Hal Jordan, Hawkman, Ray Palmer, Spider Man, Thor, Hank Pym, Solar, Iron Man, Dr. Strange, Daredevil, Ted Kord, Captian Marvel, Black Panther, Wolverine, Booster Gold, Spawn \" and print it out. Then: - Slice the first column and print it out - Slice the third row and print it out - Slice 'Wolverine' and print it out - Slice a 3x3 array with 'Wonder Woman, Ray Palmer, Iron Man, Martian Manhunter, Spider Man, Dr. Strange, Barry Allen, Thor, Daredevil' import numpy as np #import numpy Superheroes = np.array([['Superman', 'Batman', 'Jim Hammond', 'Captain America', 'Green Arrow'], ['Aquaman', 'Wonder Woman', 'Martian Manhunter', 'Barry Allen', 'Hal Jordan'], ['Hawkman', 'Ray Palmer', 'Spider Man', 'Thor', 'Hank Pym'], ['Solar', 'Iron Man', 'Dr. Strange', 'Daredevil', 'Ted Kord'], ['Captian Marvel', 'Black Panther', 'Wolverine', 'Booster Gold', 'Spawn']]) print(Superheroes) #Step1 print(Superheroes[:,0]) print(Superheroes[2,:]) print(Superheroes[4,2]) print(Superheroes[1:4,1:4]) [['Superman' 'Batman' 'Jim Hammond' 'Captain America' 'Green Arrow'] ['Aquaman' 'Wonder Woman' 'Martian Manhunter' 'Barry Allen' 'Hal Jordan'] ['Hawkman' 'Ray Palmer' 'Spider Man' 'Thor' 'Hank Pym'] ['Solar' 'Iron Man' 'Dr. Strange' 'Daredevil' 'Ted Kord'] ['Captian Marvel' 'Black Panther' 'Wolverine' 'Booster Gold' 'Spawn']] ['Superman' 'Aquaman' 'Hawkman' 'Solar' 'Captian Marvel'] ['Hawkman' 'Ray Palmer' 'Spider Man' 'Thor' 'Hank Pym'] Wolverine [['Wonder Woman' 'Martian Manhunter' 'Barry Allen'] ['Ray Palmer' 'Spider Man' 'Thor'] ['Iron Man' 'Dr. Strange' 'Daredevil']]","title":"Example- Slicing n-Dimensional Arrays"},{"location":"8-Labs/Lab6/Lab6_Dev/#this-is-a-numpy-cheat-sheet-similar-to-the-one-you-had-on-top-of-this-notebook","text":"","title":"This is a Numpy Cheat Sheet- similar to the one you had on top of this notebook!"},{"location":"8-Labs/Lab6/Lab6_Dev/#check-out-this-link-for-more","text":"https://blog.finxter.com/collection-10-best-numpy-cheat-sheets-every-python-coder-must-own/ Here are some of the resources used for creating this notebook: - Johnson, J. (2020). Python Numpy Tutorial (with Jupyter and Colab). Retrieved September 15, 2020, from https://cs231n.github.io/python-numpy-tutorial/ - Willems, K. (2019). (Tutorial) Python NUMPY Array TUTORIAL. Retrieved September 15, 2020, from https://www.datacamp.com/community/tutorials/python-numpy-tutorial?utm_source=adwords_ppc - Willems, K. (2017). NumPy Cheat Sheet: Data Analysis in Python. Retrieved September 15, 2020, from https://www.datacamp.com/community/blog/python-numpy-cheat-sheet - W3resource. (2020). NumPy: Compare two given arrays. Retrieved September 15, 2020, from https://www.w3resource.com/python-exercises/numpy/python-numpy-exercise-28.php Here are some great reads on this topic: - \"Python NumPy Tutorial\" available at https://www.geeksforgeeks.org/python-numpy-tutorial/ - \"What Is NumPy?\" a collection of blogs, available at https://realpython.com/tutorials/numpy/ - \"Look Ma, No For-Loops: Array Programming With NumPy\" by Brad Solomon available at https://realpython.com/numpy-array-programming/ - \"The Ultimate Beginner\u2019s Guide to NumPy\" by Anne Bonner available at https://towardsdatascience.com/the-ultimate-beginners-guide-to-numpy-f5a2f99aef54 Here are some great videos on these topics: - \"Learn NUMPY in 5 minutes - BEST Python Library!\" by Python Programmer available at https://www.youtube.com/watch?v=xECXZ3tyONo - \"Python NumPy Tutorial for Beginners\" by freeCodeCamp.org available at https://www.youtube.com/watch?v=QUT1VHiLmmI - \"Complete Python NumPy Tutorial (Creating Arrays, Indexing, Math, Statistics, Reshaping)\" by Keith Galli available at https://www.youtube.com/watch?v=GB9ByFAIAH4 - \"Python NumPy Tutorial | NumPy Array | Python Tutorial For Beginners | Python Training | Edureka\" by edureka! available at https://www.youtube.com/watch?v=8JfDAm9y_7s","title":"Check out this link for more: "},{"location":"8-Labs/Lab6/Lab6_Dev/#exercise-python-list-vs-numpy-arrays","text":"","title":"Exercise: Python List vs. Numpy Arrays? "},{"location":"8-Labs/Lab6/Lab6_Dev/#what-are-some-differences-between-python-lists-and-numpy-arrays","text":"","title":"What are some differences between Python lists and Numpy arrays?"},{"location":"8-Labs/Lab6/Lab6_Dev/#make-sure-to-cite-any-resources-that-you-may-use","text":"","title":"* Make sure to cite any resources that you may use."},{"location":"8-Labs/Lab7/Lab7_Dev/","text":"Laboratory 7: Pandas for Butter! # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) Full name: R#: Title of the notebook: Date: Pandas A data table is called a DataFrame in pandas (and other programming environments too). The figure below from https://pandas.pydata.org/docs/getting_started/index.html illustrates a dataframe model: Each column and each row in a dataframe is called a series, the header row, and index column are special. To use pandas, we need to import the module, generally pandas has numpy as a dependency so it also must be imported import numpy as np #Importing NumPy library as \"np\" import pandas as pd #Importing Pandas library as \"pd\" Dataframe-structure using primative python First lets construct a dataframe like object using python primatives. We will construct 3 lists, one for row names, one for column names, and one for the content. mytabular = np.random.randint(1,100,(5,4)) myrowname = ['A','B','C','D','E'] mycolname = ['W','X','Y','Z'] mytable = [['' for jcol in range(len(mycolname)+1)] for irow in range(len(myrowname)+1)] #non-null destination matrix, note the implied loop construction print(mytabular) [[61 82 48 85] [45 36 97 72] [91 3 22 35] [18 65 30 63] [79 71 8 45]] The above builds a placeholder named mytable for the psuedo-dataframe. Next we populate the table, using a for loop to write the column names in the first row, row names in the first column, and the table fill for the rest of the table. for irow in range(1,len(myrowname)+1): # write the row names mytable[irow][0]=myrowname[irow-1] for jcol in range(1,len(mycolname)+1): # write the column names mytable[0][jcol]=mycolname[jcol-1] for irow in range(1,len(myrowname)+1): # fill the table (note the nested loop) for jcol in range(1,len(mycolname)+1): mytable[irow][jcol]=mytabular[irow-1][jcol-1] Now lets print the table out by row and we see we have a very dataframe-like structure for irow in range(0,len(myrowname)+1): print(mytable[irow][0:len(mycolname)+1]) ['', 'W', 'X', 'Y', 'Z'] ['A', 61, 82, 48, 85] ['B', 45, 36, 97, 72] ['C', 91, 3, 22, 35] ['D', 18, 65, 30, 63] ['E', 79, 71, 8, 45] We can also query by row print(mytable[3][0:len(mycolname)+1]) ['C', 91, 3, 22, 35] Or by column for irow in range(0,len(myrowname)+1): #cannot use implied loop in a column slice print(mytable[irow][2]) X 82 36 3 65 71 Or by row+column index; sort of looks like a spreadsheet syntax. print(' ',mytable[0][3]) print(mytable[3][0],mytable[3][3]) Y C 22 Create a proper dataframe We will now do the same using pandas df = pd.DataFrame(np.random.randint(1,100,(5,4)), ['A','B','C','D','E'], ['W','X','Y','Z']) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 52 34 33 4 B 11 40 9 69 C 59 60 71 32 D 96 51 89 63 E 9 46 81 84 We can also turn our table into a dataframe, notice how the constructor adds header row and index column df1 = pd.DataFrame(mytable) df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 0 W X Y Z 1 A 61 82 48 85 2 B 45 36 97 72 3 C 91 3 22 35 4 D 18 65 30 63 5 E 79 71 8 45 To get proper behavior, we can just reuse our original objects df2 = pd.DataFrame(mytabular,myrowname,mycolname) df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 61 82 48 85 B 45 36 97 72 C 91 3 22 35 D 18 65 30 63 E 79 71 8 45 Getting the shape of dataframes The shape method will return the row and column rank (count) of a dataframe. df.shape (5, 4) df1.shape (6, 5) df2.shape (5, 4) Appending new columns To append a column simply assign a value to a new column name to the dataframe df['new']= 'NA' df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 52 34 33 4 NA B 11 40 9 69 NA C 59 60 71 32 NA D 96 51 89 63 NA E 9 46 81 84 NA Appending new rows A bit trickier but we can create a copy of a row and concatenate it back into the dataframe. newrow = df.loc[['E']].rename(index={\"E\": \"X\"}) # create a single row, rename the index newtable = pd.concat([df,newrow]) # concatenate the row to bottom of df - note the syntax newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 52 34 33 4 NA B 11 40 9 69 NA C 59 60 71 32 NA D 96 51 89 63 NA E 9 46 81 84 NA X 9 46 81 84 NA Removing Rows and Columns To remove a column is straightforward, we use the drop method newtable.drop('new', axis=1, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 52 34 33 4 B 11 40 9 69 C 59 60 71 32 D 96 51 89 63 E 9 46 81 84 X 9 46 81 84 To remove a row, you really got to want to, easiest is probablty to create a new dataframe with the row removed newtable = newtable.loc[['A','B','D','E','X']] # select all rows except C newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 52 34 33 4 B 11 40 9 69 D 96 51 89 63 E 9 46 81 84 X 9 46 81 84 Indexing We have already been indexing, but a few examples follow: newtable['X'] #Selecing a single column A 34 B 40 D 51 E 46 X 46 Name: X, dtype: int64 newtable[['X','W']] #Selecing multiple columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X W A 34 52 B 40 11 D 51 96 E 46 9 X 46 9 newtable.loc['E'] #Selecing rows based on label via loc[ ] indexer W 9 X 46 Y 81 Z 84 Name: E, dtype: int64 newtable.loc[['E','X','B']] #Selecing multiple rows based on label via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z E 9 46 81 84 X 9 46 81 84 B 11 40 9 69 newtable.loc[['B','E','D'],['X','Y']] #Selecting elemens via both rows and columns via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X Y B 40 9 E 46 81 D 51 89 Conditional Selection df = pd.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach #What fruit corresponds to the number 555 in \u2018col2\u2019? df[df['col2']==555]['col3'] 1 apple Name: col3, dtype: object #What fruit corresponds to the minimum number in \u2018col2\u2019? df[df['col2']==df['col2'].min()]['col3'] 5 watermelon Name: col3, dtype: object Descriptor Functions #Creating a dataframe from a dictionary df = pd.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach head method Returns the first few rows, useful to infer structure #Returns only the first five rows df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit info method Returns the data model (data column count, names, data types) #Info about the dataframe df.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 8 entries, 0 to 7 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 col1 8 non-null int64 1 col2 8 non-null int64 2 col3 8 non-null object dtypes: int64(2), object(1) memory usage: 320.0+ bytes describe method Returns summary statistics of each numeric column. Also returns the minimum and maximum value in each column, and the IQR (Interquartile Range). Again useful to understand structure of the columns. #Statistics of the dataframe df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 count 8.00000 8.0000 mean 4.50000 416.2500 std 2.44949 211.8576 min 1.00000 111.0000 25% 2.75000 222.0000 50% 4.50000 444.0000 75% 6.25000 582.7500 max 8.00000 666.0000 Counting and Sum methods There are also methods for counts and sums by specific columns df['col2'].sum() #Sum of a specified column 3330 The unique method returns a list of unique values (filters out duplicates in the list, underlying dataframe is preserved) df['col2'].unique() #Returns the list of unique values along the indexed column array([444, 555, 666, 111, 222]) The nunique method returns a count of unique values df['col2'].nunique() #Returns the total number of unique values along the indexed column 5 The value_counts() method returns the count of each unique value (kind of like a histogram, but each value is the bin) df['col2'].value_counts() #Returns the number of occurences of each unique value 222 2 444 2 666 2 111 1 555 1 Name: col2, dtype: int64 Using functions in dataframes - symbolic apply The power of pandas is an ability to apply a function to each element of a dataframe series (or a whole frame) by a technique called symbolic (or synthetic programming) application of the function. Its pretty complicated but quite handy, best shown by an example def times2(x): # A prototype function to scalar multiply an object x by 2 return(x*2) print(df) print('Apply the times2 function to col2') df['col2'].apply(times2) #Symbolic apply the function to each element of column col2, result is another dataframe col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach Apply the times2 function to col2 0 888 1 1110 2 1332 3 888 4 1332 5 222 6 444 7 444 Name: col2, dtype: int64 Sorts df.sort_values('col2', ascending = True) #Sorting based on columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 5 6 111 watermelon 6 7 222 banana 7 8 222 peach 0 1 444 orange 3 4 444 mango 1 2 555 apple 2 3 666 grape 4 5 666 jackfruit Aggregating (Grouping Values) dataframe contents #Creating a dataframe from a dictionary data = { 'key' : ['A', 'B', 'C', 'A', 'B', 'C'], 'data1' : [1, 2, 3, 4, 5, 6], 'data2' : [10, 11, 12, 13, 14, 15], 'data3' : [20, 21, 22, 13, 24, 25] } df1 = pd.DataFrame(data) df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 data3 0 A 1 10 20 1 B 2 11 21 2 C 3 12 22 3 A 4 13 13 4 B 5 14 24 5 C 6 15 25 # Grouping and summing values in all the columns based on the column 'key' df1.groupby('key').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 data3 key A 5 23 33 B 7 25 45 C 9 27 47 # Grouping and summing values in the selected columns based on the column 'key' df1.groupby('key')[['data1', 'data2']].sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key A 5 23 B 7 25 C 9 27 Filtering out missing values #Creating a dataframe from a dictionary df = pd.DataFrame({'col1':[1,2,3,4,None,6,7,None], 'col2':[444,555,None,444,666,111,None,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 NaN grape 3 4.0 444.0 mango 4 NaN 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 NaN banana 7 NaN 222.0 peach Below we drop any row that contains a NaN code. df_dropped = df.dropna() df_dropped .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 3 4.0 444.0 mango 5 6.0 111.0 watermelon Below we replace NaN codes with some value, in this case 0 df_filled1 = df.fillna(0) df_filled1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 0.0 grape 3 4.0 444.0 mango 4 0.0 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 0.0 banana 7 0.0 222.0 peach Below we replace NaN codes with some value, in this case the mean value of of the column in which the missing value code resides. df_filled2 = df.fillna(df.mean()) df_filled2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.000000 444.0 orange 1 2.000000 555.0 apple 2 3.000000 407.0 grape 3 4.000000 444.0 mango 4 3.833333 666.0 jackfruit 5 6.000000 111.0 watermelon 6 7.000000 407.0 banana 7 3.833333 222.0 peach Reading a File into a Dataframe Pandas has methods to read common file types, such as csv , xlsx , and json . Ordinary text files are also quite manageable. On a machine you control you can write script to retrieve files from the internet and process them. import pandas as pd readfilecsv = pd.read_csv('CSV_ReadingFile.csv') #Reading a .csv file print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 Similar to reading and writing .csv files, you can also read and write .xslx files as below (useful to know this) readfileexcel = pd.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') #Reading a .xlsx file print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 Writing a dataframe to file #Creating and writing to a .csv file readfilecsv = pd.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile1.csv') readfilecsv = pd.read_csv('CSV_WritingFile1.csv') print(readfilecsv) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 #Creating and writing to a .csv file by excluding row labels readfilecsv = pd.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile2.csv', index = False) readfilecsv = pd.read_csv('CSV_WritingFile2.csv') print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 #Creating and writing to a .xlsx file readfileexcel = pd.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') readfileexcel.to_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', engine='openpyxl') readfileexcel = pd.read_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', engine='openpyxl') print(readfileexcel) Unnamed: 0 Unnamed: 0.1 a b c d 0 0 0 0 1 2 3 1 1 1 4 5 6 7 2 2 2 8 9 10 11 3 3 3 12 13 14 15 This is a Pandas Cheat Sheet Here are some of the resources used for creating this notebook: Pandas foundations. Retrieved February 15, 2021, from https://www.datacamp.com/courses/pandas-foundations Pandas tutorial. Retrieved February 15, 2021, from https://www.w3schools.com/python/pandas/default.asp Pandas tutorial: Dataframes in Python. Retrieved February 15, 2021, from https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python Here are some great reads on this topic: - \"Introduction to Pandas in Python\" available at https://www.geeksforgeeks.org/introduction-to-pandas-in-python/ - \"Pandas Introduction & Tutorials for Beginners\" by Walker Rowe , available at https://www.bmc.com/blogs/pandas-basics/ - \"Using Pandas and Python to Explore Your Dataset\" by Reka Horvath available at https://realpython.com/pandas-python-explore-dataset/ - \"Python Pandas Tutorial: A Complete Introduction for Beginners\" by George McIntire, Lauren Washington, and Brendan Martin available at https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/ Here are some great videos on these topics: - \"Python: Pandas Tutorial | Intro to DataFrames\" by Joe James available at https://www.youtube.com/watch?v=e60ItwlZTKM - \"Complete Python Pandas Data Science Tutorial! (Reading CSV/Excel files, Sorting, Filtering, Groupby)\" by Keith Galli available at https://www.youtube.com/watch?v=vmEHCJofslg - \"What is Pandas? Why and How to Use Pandas in Python\" by Python Programmer available at *https://www.youtube.com/watch?v=dcqPhpY7tWk Exercise: Pandas of Data Pandas library supports three major types of data structures: Series, DataFrames, and Panels. What are some differences between the three structures? * Make sure to cite any resources that you may use.","title":"Workshop 7"},{"location":"8-Labs/Lab7/Lab7_Dev/#laboratory-7-pandas-for-butter","text":"# Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Laboratory 7: Pandas for Butter! "},{"location":"8-Labs/Lab7/Lab7_Dev/#full-name","text":"","title":"Full name:"},{"location":"8-Labs/Lab7/Lab7_Dev/#r","text":"","title":"R#:"},{"location":"8-Labs/Lab7/Lab7_Dev/#title-of-the-notebook","text":"","title":"Title of the notebook:"},{"location":"8-Labs/Lab7/Lab7_Dev/#date","text":"","title":"Date:"},{"location":"8-Labs/Lab7/Lab7_Dev/#pandas","text":"A data table is called a DataFrame in pandas (and other programming environments too). The figure below from https://pandas.pydata.org/docs/getting_started/index.html illustrates a dataframe model: Each column and each row in a dataframe is called a series, the header row, and index column are special. To use pandas, we need to import the module, generally pandas has numpy as a dependency so it also must be imported import numpy as np #Importing NumPy library as \"np\" import pandas as pd #Importing Pandas library as \"pd\"","title":"Pandas"},{"location":"8-Labs/Lab7/Lab7_Dev/#dataframe-structure-using-primative-python","text":"First lets construct a dataframe like object using python primatives. We will construct 3 lists, one for row names, one for column names, and one for the content. mytabular = np.random.randint(1,100,(5,4)) myrowname = ['A','B','C','D','E'] mycolname = ['W','X','Y','Z'] mytable = [['' for jcol in range(len(mycolname)+1)] for irow in range(len(myrowname)+1)] #non-null destination matrix, note the implied loop construction print(mytabular) [[61 82 48 85] [45 36 97 72] [91 3 22 35] [18 65 30 63] [79 71 8 45]] The above builds a placeholder named mytable for the psuedo-dataframe. Next we populate the table, using a for loop to write the column names in the first row, row names in the first column, and the table fill for the rest of the table. for irow in range(1,len(myrowname)+1): # write the row names mytable[irow][0]=myrowname[irow-1] for jcol in range(1,len(mycolname)+1): # write the column names mytable[0][jcol]=mycolname[jcol-1] for irow in range(1,len(myrowname)+1): # fill the table (note the nested loop) for jcol in range(1,len(mycolname)+1): mytable[irow][jcol]=mytabular[irow-1][jcol-1] Now lets print the table out by row and we see we have a very dataframe-like structure for irow in range(0,len(myrowname)+1): print(mytable[irow][0:len(mycolname)+1]) ['', 'W', 'X', 'Y', 'Z'] ['A', 61, 82, 48, 85] ['B', 45, 36, 97, 72] ['C', 91, 3, 22, 35] ['D', 18, 65, 30, 63] ['E', 79, 71, 8, 45] We can also query by row print(mytable[3][0:len(mycolname)+1]) ['C', 91, 3, 22, 35] Or by column for irow in range(0,len(myrowname)+1): #cannot use implied loop in a column slice print(mytable[irow][2]) X 82 36 3 65 71 Or by row+column index; sort of looks like a spreadsheet syntax. print(' ',mytable[0][3]) print(mytable[3][0],mytable[3][3]) Y C 22","title":"Dataframe-structure using primative python"},{"location":"8-Labs/Lab7/Lab7_Dev/#create-a-proper-dataframe","text":"We will now do the same using pandas df = pd.DataFrame(np.random.randint(1,100,(5,4)), ['A','B','C','D','E'], ['W','X','Y','Z']) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 52 34 33 4 B 11 40 9 69 C 59 60 71 32 D 96 51 89 63 E 9 46 81 84 We can also turn our table into a dataframe, notice how the constructor adds header row and index column df1 = pd.DataFrame(mytable) df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 0 W X Y Z 1 A 61 82 48 85 2 B 45 36 97 72 3 C 91 3 22 35 4 D 18 65 30 63 5 E 79 71 8 45 To get proper behavior, we can just reuse our original objects df2 = pd.DataFrame(mytabular,myrowname,mycolname) df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 61 82 48 85 B 45 36 97 72 C 91 3 22 35 D 18 65 30 63 E 79 71 8 45","title":"Create a proper dataframe"},{"location":"8-Labs/Lab7/Lab7_Dev/#getting-the-shape-of-dataframes","text":"The shape method will return the row and column rank (count) of a dataframe. df.shape (5, 4) df1.shape (6, 5) df2.shape (5, 4)","title":"Getting the shape of dataframes"},{"location":"8-Labs/Lab7/Lab7_Dev/#appending-new-columns","text":"To append a column simply assign a value to a new column name to the dataframe df['new']= 'NA' df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 52 34 33 4 NA B 11 40 9 69 NA C 59 60 71 32 NA D 96 51 89 63 NA E 9 46 81 84 NA","title":"Appending new columns"},{"location":"8-Labs/Lab7/Lab7_Dev/#appending-new-rows","text":"A bit trickier but we can create a copy of a row and concatenate it back into the dataframe. newrow = df.loc[['E']].rename(index={\"E\": \"X\"}) # create a single row, rename the index newtable = pd.concat([df,newrow]) # concatenate the row to bottom of df - note the syntax newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 52 34 33 4 NA B 11 40 9 69 NA C 59 60 71 32 NA D 96 51 89 63 NA E 9 46 81 84 NA X 9 46 81 84 NA","title":"Appending new rows"},{"location":"8-Labs/Lab7/Lab7_Dev/#removing-rows-and-columns","text":"To remove a column is straightforward, we use the drop method newtable.drop('new', axis=1, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 52 34 33 4 B 11 40 9 69 C 59 60 71 32 D 96 51 89 63 E 9 46 81 84 X 9 46 81 84 To remove a row, you really got to want to, easiest is probablty to create a new dataframe with the row removed newtable = newtable.loc[['A','B','D','E','X']] # select all rows except C newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 52 34 33 4 B 11 40 9 69 D 96 51 89 63 E 9 46 81 84 X 9 46 81 84","title":"Removing Rows and Columns"},{"location":"8-Labs/Lab7/Lab7_Dev/#indexing","text":"We have already been indexing, but a few examples follow: newtable['X'] #Selecing a single column A 34 B 40 D 51 E 46 X 46 Name: X, dtype: int64 newtable[['X','W']] #Selecing multiple columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X W A 34 52 B 40 11 D 51 96 E 46 9 X 46 9 newtable.loc['E'] #Selecing rows based on label via loc[ ] indexer W 9 X 46 Y 81 Z 84 Name: E, dtype: int64 newtable.loc[['E','X','B']] #Selecing multiple rows based on label via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z E 9 46 81 84 X 9 46 81 84 B 11 40 9 69 newtable.loc[['B','E','D'],['X','Y']] #Selecting elemens via both rows and columns via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X Y B 40 9 E 46 81 D 51 89","title":"Indexing"},{"location":"8-Labs/Lab7/Lab7_Dev/#conditional-selection","text":"df = pd.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach #What fruit corresponds to the number 555 in \u2018col2\u2019? df[df['col2']==555]['col3'] 1 apple Name: col3, dtype: object #What fruit corresponds to the minimum number in \u2018col2\u2019? df[df['col2']==df['col2'].min()]['col3'] 5 watermelon Name: col3, dtype: object","title":"Conditional Selection"},{"location":"8-Labs/Lab7/Lab7_Dev/#descriptor-functions","text":"#Creating a dataframe from a dictionary df = pd.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach","title":"Descriptor Functions"},{"location":"8-Labs/Lab7/Lab7_Dev/#head-method","text":"Returns the first few rows, useful to infer structure #Returns only the first five rows df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit","title":"head method"},{"location":"8-Labs/Lab7/Lab7_Dev/#info-method","text":"Returns the data model (data column count, names, data types) #Info about the dataframe df.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 8 entries, 0 to 7 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 col1 8 non-null int64 1 col2 8 non-null int64 2 col3 8 non-null object dtypes: int64(2), object(1) memory usage: 320.0+ bytes","title":"info method"},{"location":"8-Labs/Lab7/Lab7_Dev/#describe-method","text":"Returns summary statistics of each numeric column. Also returns the minimum and maximum value in each column, and the IQR (Interquartile Range). Again useful to understand structure of the columns. #Statistics of the dataframe df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 count 8.00000 8.0000 mean 4.50000 416.2500 std 2.44949 211.8576 min 1.00000 111.0000 25% 2.75000 222.0000 50% 4.50000 444.0000 75% 6.25000 582.7500 max 8.00000 666.0000","title":"describe method"},{"location":"8-Labs/Lab7/Lab7_Dev/#counting-and-sum-methods","text":"There are also methods for counts and sums by specific columns df['col2'].sum() #Sum of a specified column 3330 The unique method returns a list of unique values (filters out duplicates in the list, underlying dataframe is preserved) df['col2'].unique() #Returns the list of unique values along the indexed column array([444, 555, 666, 111, 222]) The nunique method returns a count of unique values df['col2'].nunique() #Returns the total number of unique values along the indexed column 5 The value_counts() method returns the count of each unique value (kind of like a histogram, but each value is the bin) df['col2'].value_counts() #Returns the number of occurences of each unique value 222 2 444 2 666 2 111 1 555 1 Name: col2, dtype: int64","title":"Counting and Sum methods"},{"location":"8-Labs/Lab7/Lab7_Dev/#using-functions-in-dataframes-symbolic-apply","text":"The power of pandas is an ability to apply a function to each element of a dataframe series (or a whole frame) by a technique called symbolic (or synthetic programming) application of the function. Its pretty complicated but quite handy, best shown by an example def times2(x): # A prototype function to scalar multiply an object x by 2 return(x*2) print(df) print('Apply the times2 function to col2') df['col2'].apply(times2) #Symbolic apply the function to each element of column col2, result is another dataframe col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach Apply the times2 function to col2 0 888 1 1110 2 1332 3 888 4 1332 5 222 6 444 7 444 Name: col2, dtype: int64","title":"Using functions in dataframes - symbolic apply"},{"location":"8-Labs/Lab7/Lab7_Dev/#sorts","text":"df.sort_values('col2', ascending = True) #Sorting based on columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 5 6 111 watermelon 6 7 222 banana 7 8 222 peach 0 1 444 orange 3 4 444 mango 1 2 555 apple 2 3 666 grape 4 5 666 jackfruit","title":"Sorts"},{"location":"8-Labs/Lab7/Lab7_Dev/#aggregating-grouping-values-dataframe-contents","text":"#Creating a dataframe from a dictionary data = { 'key' : ['A', 'B', 'C', 'A', 'B', 'C'], 'data1' : [1, 2, 3, 4, 5, 6], 'data2' : [10, 11, 12, 13, 14, 15], 'data3' : [20, 21, 22, 13, 24, 25] } df1 = pd.DataFrame(data) df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 data3 0 A 1 10 20 1 B 2 11 21 2 C 3 12 22 3 A 4 13 13 4 B 5 14 24 5 C 6 15 25 # Grouping and summing values in all the columns based on the column 'key' df1.groupby('key').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 data3 key A 5 23 33 B 7 25 45 C 9 27 47 # Grouping and summing values in the selected columns based on the column 'key' df1.groupby('key')[['data1', 'data2']].sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key A 5 23 B 7 25 C 9 27","title":"Aggregating (Grouping Values) dataframe contents"},{"location":"8-Labs/Lab7/Lab7_Dev/#filtering-out-missing-values","text":"#Creating a dataframe from a dictionary df = pd.DataFrame({'col1':[1,2,3,4,None,6,7,None], 'col2':[444,555,None,444,666,111,None,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 NaN grape 3 4.0 444.0 mango 4 NaN 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 NaN banana 7 NaN 222.0 peach Below we drop any row that contains a NaN code. df_dropped = df.dropna() df_dropped .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 3 4.0 444.0 mango 5 6.0 111.0 watermelon Below we replace NaN codes with some value, in this case 0 df_filled1 = df.fillna(0) df_filled1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 0.0 grape 3 4.0 444.0 mango 4 0.0 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 0.0 banana 7 0.0 222.0 peach Below we replace NaN codes with some value, in this case the mean value of of the column in which the missing value code resides. df_filled2 = df.fillna(df.mean()) df_filled2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.000000 444.0 orange 1 2.000000 555.0 apple 2 3.000000 407.0 grape 3 4.000000 444.0 mango 4 3.833333 666.0 jackfruit 5 6.000000 111.0 watermelon 6 7.000000 407.0 banana 7 3.833333 222.0 peach","title":"Filtering out missing values"},{"location":"8-Labs/Lab7/Lab7_Dev/#reading-a-file-into-a-dataframe","text":"Pandas has methods to read common file types, such as csv , xlsx , and json . Ordinary text files are also quite manageable. On a machine you control you can write script to retrieve files from the internet and process them. import pandas as pd readfilecsv = pd.read_csv('CSV_ReadingFile.csv') #Reading a .csv file print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 Similar to reading and writing .csv files, you can also read and write .xslx files as below (useful to know this) readfileexcel = pd.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') #Reading a .xlsx file print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15","title":"Reading a File into a Dataframe"},{"location":"8-Labs/Lab7/Lab7_Dev/#writing-a-dataframe-to-file","text":"#Creating and writing to a .csv file readfilecsv = pd.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile1.csv') readfilecsv = pd.read_csv('CSV_WritingFile1.csv') print(readfilecsv) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 #Creating and writing to a .csv file by excluding row labels readfilecsv = pd.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile2.csv', index = False) readfilecsv = pd.read_csv('CSV_WritingFile2.csv') print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 #Creating and writing to a .xlsx file readfileexcel = pd.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') readfileexcel.to_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', engine='openpyxl') readfileexcel = pd.read_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', engine='openpyxl') print(readfileexcel) Unnamed: 0 Unnamed: 0.1 a b c d 0 0 0 0 1 2 3 1 1 1 4 5 6 7 2 2 2 8 9 10 11 3 3 3 12 13 14 15","title":"Writing a dataframe to file"},{"location":"8-Labs/Lab7/Lab7_Dev/#this-is-a-pandas-cheat-sheet","text":"Here are some of the resources used for creating this notebook: Pandas foundations. Retrieved February 15, 2021, from https://www.datacamp.com/courses/pandas-foundations Pandas tutorial. Retrieved February 15, 2021, from https://www.w3schools.com/python/pandas/default.asp Pandas tutorial: Dataframes in Python. Retrieved February 15, 2021, from https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python Here are some great reads on this topic: - \"Introduction to Pandas in Python\" available at https://www.geeksforgeeks.org/introduction-to-pandas-in-python/ - \"Pandas Introduction & Tutorials for Beginners\" by Walker Rowe , available at https://www.bmc.com/blogs/pandas-basics/ - \"Using Pandas and Python to Explore Your Dataset\" by Reka Horvath available at https://realpython.com/pandas-python-explore-dataset/ - \"Python Pandas Tutorial: A Complete Introduction for Beginners\" by George McIntire, Lauren Washington, and Brendan Martin available at https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/ Here are some great videos on these topics: - \"Python: Pandas Tutorial | Intro to DataFrames\" by Joe James available at https://www.youtube.com/watch?v=e60ItwlZTKM - \"Complete Python Pandas Data Science Tutorial! (Reading CSV/Excel files, Sorting, Filtering, Groupby)\" by Keith Galli available at https://www.youtube.com/watch?v=vmEHCJofslg - \"What is Pandas? Why and How to Use Pandas in Python\" by Python Programmer available at *https://www.youtube.com/watch?v=dcqPhpY7tWk","title":"This is a Pandas Cheat Sheet"},{"location":"8-Labs/Lab7/Lab7_Dev/#exercise-pandas-of-data","text":"","title":"Exercise: Pandas of Data  "},{"location":"8-Labs/Lab7/Lab7_Dev/#pandas-library-supports-three-major-types-of-data-structures-series-dataframes-and-panels-what-are-some-differences-between-the-three-structures","text":"","title":"Pandas library supports three major types of data structures: Series, DataFrames, and Panels. What are some differences between the three structures?"},{"location":"8-Labs/Lab7/Lab7_Dev/#make-sure-to-cite-any-resources-that-you-may-use","text":"","title":"* Make sure to cite any resources that you may use."},{"location":"8-Labs/Lab8/Lab8_Dev/","text":"Laboratory 8: Matplotlib for Jam! # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) Full name: R#: Title of the notebook: Date: Matplotlip and Visual Display of Data This lesson will introduce the matplotlib external module package, and examine how to construct line charts, scatter plots, bar charts, and histograms using methods in matplotlib and pandas The theory of histograms will appear in later lessons, here we only show how to construct one using matplotlib About matplotlib Quoting from: https://matplotlib.org/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py matplotlib.pyplot is a collection of functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc. In matplotlib.pyplot various states are preserved across function calls, so that it keeps track of things like the current figure and plotting area, and the plotting functions are directed to the current axes (please note that \"axes\" here and in most places in the documentation refers to the axes part of a figure and not the strict mathematical term for more than one axis). Background Data are not always numerical. Data can music (audio files), or places on a map (georeferenced attributes files), images (various imge files, e.g. .png, jpeg) They can also be categorical into which you can place individuals: - The individuals are cartons of ice-cream, and the category is the flavor in the carton - The individuals are professional basketball players, and the category is the player's team. Bar Graphs Bar charts (graphs) are good display tools to graphically represent categorical information. The bars are evenly spaced and of constant width. The height/length of each bar is proportional to the relative frequency of the corresponding category. Relative frequency is the ratio of how many things in the category to how many things in the whole collection. The example below uses matplotlib to create a box plot for the ice cream analogy, the example is adapted from an example at https://www.geeksforgeeks.org/bar-plot-in-matplotlib/ ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! myfigure = matplotlib.pyplot.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot matplotlib.pyplot.bar(flavors, cartons, color ='maroon', width = 0.4) matplotlib.pyplot.xlabel(\"Flavors\") matplotlib.pyplot.ylabel(\"No. of Cartons in Stock\") matplotlib.pyplot.title(\"Current Ice Cream in Storage\") matplotlib.pyplot.show() Lets tidy up the script so it is more understandable, a small change in the import statement makes a simpler to read (for humans) script - also changed the bar colors just 'cause! ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot plt.bar(flavors, cartons, color ='orange', width = 0.4) plt.xlabel(\"Flavors\") plt.ylabel(\"No. of Cartons in Stock\") plt.title(\"Current Ice Cream in Storage\") plt.show() Using pandas, we can build bar charts a bit easier. import pandas as pd my_data = { \"Flavor\": ['Chocolate', 'Strawberry', 'Vanilla'], \"Number of Cartons\": [16, 5, 9] } df = pd.DataFrame(my_data) df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Flavor Number of Cartons 0 Chocolate 16 1 Strawberry 5 2 Vanilla 9 df.plot.bar(x='Flavor', y='Number of Cartons', color='magenta' ) <AxesSubplot:xlabel='Flavor'> df.plot.bar(x='Flavor', y='Number of Cartons', color=\"red\") # rotate the category labels <AxesSubplot:xlabel='Flavor'> Example- Language Bars! Consider the data set \"data\" defined as data = {'C':20, 'C++':15, 'Java':30, 'Python':35} which lists student count by programming language in some school. Produce a bar chart of number of students in each language, where language is the classification, and student count is the variable. # Code and run your solution here import numpy as np import matplotlib.pyplot as plt # creating the dataset data = {'C':20, 'C++':15, 'Java':30, 'Python':35} courses = list(data.keys()) values = list(data.values()) fig = plt.figure(figsize = (10, 5)) # creating the bar plot plt.bar(courses, values, color ='maroon', width = 0.4) plt.xlabel(\"Courses offered\") plt.ylabel(\"No. of students enrolled\") plt.title(\"Students enrolled in different courses\") plt.show() Plot it as a horizontal bar chart: # Code and run your solution here # creating the dataset data = {'C':20, 'C++':15, 'Java':30, 'Python':35} courses = list(data.keys()) values = list(data.values()) fig = plt.figure(figsize = (10, 5)) # creating the bar plot plt.barh(courses, values, color ='maroon', height = 0.4) plt.xlabel(\"Courses offered\") plt.ylabel(\"No. of students enrolled\") plt.title(\"Students enrolled in different courses\") plt.show() Line Charts A line chart or line plot or line graph or curve chart is a type of chart which displays information as a series of data points called 'markers' connected by straight line segments. It is a basic type of chart common in many fields. It is similar to a scatter plot (below) except that the measurement points are ordered (typically by their x-axis value) and joined with straight line segments. A line chart is often used to visualize a trend in data over intervals of time \u2013 a time series \u2013 thus the line is often drawn chronologically. The x-axis spacing is sometimes tricky, hence line charts can unintentionally decieve - so be careful that it is the appropriate chart for your application. Example- Speed vs Time Consider the experimental data below Elapsed Time (s) Speed (m/s) 0 0 1.0 3 2.0 7 3.0 12 4.0 20 5.0 30 6.0 45.6 Show the relationship between time and speed. Is the relationship indicating acceleration? How much? # Create two lists; time and speed. time = [0,1.0,2.0,3.0,4.0,5.0,6.0] speed = [0,3,7,12,20,30,45.6] # Create a line chart of speed on y axis and time on x axis mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='v',linewidth=1) # basic line plot plt.show() From examination of the plot, estimate the speed at time t = 5.0 (eyeball estimate) Example- Add a linear fit Using the same series from Exercise 1, Plot the speed vs time (speed on y-axis, time on x-axis) using a line plot. Plot a second line based on the linear model y = mx + b , where b=0~\\text{and}~m=7.6 . # Code and run your solution here: def ymodel(xmodel,slope,intercept): ymodel = slope*xmodel+intercept return(ymodel) yseries = [] slope = 7.6 intercept = 0.0 for i in range(0,len(time)): yseries.append(ymodel(time[i],slope,intercept)) # Create a markers only line chart mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='^',linewidth=0.5) # basic line plot plt.plot(time, yseries, c='blue') plt.show() Example- Find a better fit Using trial and error try to improve the 'fit' of the model, by adjusting values of m~\\text{and}~b . # Code and run your solution here: yseries = [] slope = 7.6 intercept = -8.0 for i in range(0,len(time)): yseries.append(ymodel(time[i],slope,intercept)) # Create a markers only line chart mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='^',linewidth=0) # basic scatter plot plt.plot(time, yseries, c='blue') plt.show() Scatter Plots A scatter plot (also called a scatterplot, scatter graph, scatter chart, scattergram, or scatter diagram) is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. If the points are coded (color/shape/size), one additional variable can be displayed. The data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis. A scatter plot can be used either when one continuous variable that is under the control of the experimenter and the other depends on it or when both continuous variables are independent. If a parameter exists that is systematically incremented and/or decremented by the other, it is called the control parameter or independent variable and is customarily plotted along the horizontal axis. The measured or dependent variable is customarily plotted along the vertical axis. If no dependent variable exists, either type of variable can be plotted on either axis and a scatter plot will illustrate only the degree of correlation (not causation) between two variables. A scatter plot can suggest various kinds of correlations between variables with a certain confidence interval. For example, weight and height, weight would be on y axis and height would be on the x axis. Correlations may be positive (rising), negative (falling), or null (uncorrelated). If the pattern of dots slopes from lower left to upper right, it indicates a positive correlation between the variables being studied. If the pattern of dots slopes from upper left to lower right, it indicates a negative correlation. A line of best fit (alternatively called 'trendline') can be drawn in order to study the relationship between the variables. An equation for the correlation between the variables can be determined by established best-fit procedures. For a linear correlation, the best-fit procedure is known as linear regression and is guaranteed to generate a correct solution in a finite time. No universal best-fit procedure is guaranteed to generate a solution for arbitrary relationships. A scatter plot is also very useful when we wish to see how two comparable data sets agree and to show nonlinear relationships between variables. Furthermore, if the data are represented by a mixture model of simple relationships, these relationships will be visually evident as superimposed patterns. Scatter charts can be built in the form of bubble, marker, or/and line charts. Much of the above is verbatim/adapted from: https://en.wikipedia.org/wiki/Scatter_plot Example- Examine the dataset with heights of fathers, mothers and sons df = pd.read_csv('galton_subset.csv') df['child']= df['son'] ; df.drop('son', axis=1, inplace = True) # rename son to child - got to imagine there are some daughters df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } father mother child 0 78.5 67.0 73.2 1 75.5 66.5 73.5 2 75.0 64.0 71.0 3 75.0 64.0 70.5 4 75.0 58.5 72.0 # build some lists dad = df['father'] ; mom = df['mother'] ; son = df['child'] myfamily = plt.figure(figsize = (10, 10)) # build a square drawing canvass from figure class plt.scatter(son, dad, c='red') # basic scatter plot plt.show() # Looks lousy, needs some labels myfamily = plt.figure(figsize = (10, 10)) # build a square drawing canvass from figure class plt.scatter(son, dad, c='red' , label='Father') # one plot series plt.scatter(son, mom, c='blue', label='Mother') # two plot series plt.xlabel(\"Child's height\") plt.ylabel(\"Parents' height\") plt.legend() plt.show() # render the two plots # Repeat in pandas - The dataframe already is built df.plot.scatter(x=\"child\", y=\"father\") <AxesSubplot:xlabel='child', ylabel='father'> ax = df.plot.scatter(x=\"child\", y=\"father\", c=\"red\", label='Father') df.plot.scatter(x=\"child\", y=\"mother\", c=\"blue\", label='Mother', ax=ax) ax.set_xlabel(\"Child's height\") ax.set_ylabel(\"Parents' Height\") Text(0, 0.5, \"Parents' Height\") Histograms Quoting from https://en.wikipedia.org/wiki/Histogram \"A histogram is an approximate representation of the distribution of numerical data. It was first introduced by Karl Pearson.[1] To construct a histogram, the first step is to \"bin\" (or \"bucket\") the range of values\u2014that is, divide the entire range of values into a series of intervals\u2014and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) must be adjacent, and are often (but not required to be) of equal size. If the bins are of equal size, a rectangle is erected over the bin with height proportional to the frequency\u2014the number of cases in each bin. A histogram may also be normalized to display \"relative\" frequencies. It then shows the proportion of cases that fall into each of several categories, with the sum of the heights equaling 1. However, bins need not be of equal width; in that case, the erected rectangle is defined to have its area proportional to the frequency of cases in the bin. The vertical axis is then not the frequency but frequency density\u2014the number of cases per unit of the variable on the horizontal axis. Examples of variable bin width are displayed on Census bureau data below. As the adjacent bins leave no gaps, the rectangles of a histogram touch each other to indicate that the original variable is continuous. Histograms give a rough sense of the density of the underlying distribution of the data, and often for density estimation: estimating the probability density function of the underlying variable. The total area of a histogram used for probability density is always normalized to 1. If the length of the intervals on the x-axis are all 1, then a histogram is identical to a relative frequency plot. A histogram can be thought of as a simplistic kernel density estimation, which uses a kernel to smooth frequencies over the bins. This yields a smoother probability density function, which will in general more accurately reflect distribution of the underlying variable. The density estimate could be plotted as an alternative to the histogram, and is usually drawn as a curve rather than a set of boxes. Histograms are nevertheless preferred in applications, when their statistical properties need to be modeled. The correlated variation of a kernel density estimate is very difficult to describe mathematically, while it is simple for a histogram where each bin varies independently. An alternative to kernel density estimation is the average shifted histogram, which is fast to compute and gives a smooth curve estimate of the density without using kernels. The histogram is one of the seven basic tools of quality control. Histograms are sometimes confused with bar charts. A histogram is used for continuous data, where the bins represent ranges of data, while a bar chart is a plot of categorical variables. Some authors recommend that bar charts have gaps between the rectangles to clarify the distinction.\" Example- Explore the \"top_movies\" dataset and draw histograms for Gross and Year. import pandas as pd df = pd.read_csv('top_movies.csv') df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Title Studio Gross Gross (Adjusted) Year 0 Star Wars: The Force Awakens Buena Vista (Disney) 906723418 906723400 2015 1 Avatar Fox 760507625 846120800 2009 2 Titanic Paramount 658672302 1178627900 1997 3 Jurassic World Universal 652270625 687728000 2015 4 Marvel's The Avengers Buena Vista (Disney) 623357910 668866600 2012 df[[\"Gross\"]].hist() array([[<AxesSubplot:title={'center':'Gross'}>]], dtype=object) df[[\"Year\"]].hist() array([[<AxesSubplot:title={'center':'Year'}>]], dtype=object) df[[\"Gross\"]].hist(bins=100) This is a Matplotlib Cheat Sheet Here are some of the resources used for creating this notebook: \"Discrete distribution as horizontal bar chart\" available at *https://matplotlib.org/stable/gallery/lines_bars_and_markers/horizontal_barchart_distribution.html \"Bar Plot in Matplotlib\" available at *https://www.geeksforgeeks.org/bar-plot-in-matplotlib/ Here are some great reads on this topic: - \"Python | Introduction to Matplotlib\" available at https://www.geeksforgeeks.org/python-introduction-matplotlib/ - \"Visualization with Matplotlib\" available at https://jakevdp.github.io/PythonDataScienceHandbook/04.00-introduction-to-matplotlib.html - \"Introduction to Matplotlib \u2014 Data Visualization in Python\" by Ehi Aigiomawu available at https://heartbeat.fritz.ai/introduction-to-matplotlib-data-visualization-in-python-d9143287ae39 - \"Python Plotting With Matplotlib (Guide)\" by Brad Solomon available at https://realpython.com/python-matplotlib-guide/ Here are some great videos on these topics: - \"Matplotlib Tutorial (Part 1): Creating and Customizing Our First Plots\" by Corey Schafer available at https://www.youtube.com/watch?v=UO98lJQ3QGI - \"Intro to Data Analysis / Visualization with Python, Matplotlib and Pandas | Matplotlib Tutorial\" by CS Dojo available at https://www.youtube.com/watch?v=a9UrKTVEeZA - \"Intro to Data Visualization in Python with Matplotlib! (line graph, bar chart, title, labels, size)\" by Keith Galli available at *https://www.youtube.com/watch?v=DAQNHzOcO5A Exercise: Bins, Bins, Bins! Selecting the number of bins is an important decision when working with histograms. Are there any rules or recommendations for choosing the number or width of bins? What happens if we use too many or too few bins? * Make sure to cite any resources that you may use.","title":"Workshop 8"},{"location":"8-Labs/Lab8/Lab8_Dev/#laboratory-8-matplotlib-for-jam","text":"# Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Laboratory 8: Matplotlib for Jam! "},{"location":"8-Labs/Lab8/Lab8_Dev/#full-name","text":"","title":"Full name:"},{"location":"8-Labs/Lab8/Lab8_Dev/#r","text":"","title":"R#:"},{"location":"8-Labs/Lab8/Lab8_Dev/#title-of-the-notebook","text":"","title":"Title of the notebook:"},{"location":"8-Labs/Lab8/Lab8_Dev/#date","text":"","title":"Date:"},{"location":"8-Labs/Lab8/Lab8_Dev/#matplotlip-and-visual-display-of-data","text":"This lesson will introduce the matplotlib external module package, and examine how to construct line charts, scatter plots, bar charts, and histograms using methods in matplotlib and pandas The theory of histograms will appear in later lessons, here we only show how to construct one using matplotlib","title":"Matplotlip and Visual Display of Data"},{"location":"8-Labs/Lab8/Lab8_Dev/#about-matplotlib","text":"Quoting from: https://matplotlib.org/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py matplotlib.pyplot is a collection of functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc. In matplotlib.pyplot various states are preserved across function calls, so that it keeps track of things like the current figure and plotting area, and the plotting functions are directed to the current axes (please note that \"axes\" here and in most places in the documentation refers to the axes part of a figure and not the strict mathematical term for more than one axis).","title":"About matplotlib"},{"location":"8-Labs/Lab8/Lab8_Dev/#background","text":"Data are not always numerical. Data can music (audio files), or places on a map (georeferenced attributes files), images (various imge files, e.g. .png, jpeg) They can also be categorical into which you can place individuals: - The individuals are cartons of ice-cream, and the category is the flavor in the carton - The individuals are professional basketball players, and the category is the player's team.","title":"Background"},{"location":"8-Labs/Lab8/Lab8_Dev/#bar-graphs","text":"Bar charts (graphs) are good display tools to graphically represent categorical information. The bars are evenly spaced and of constant width. The height/length of each bar is proportional to the relative frequency of the corresponding category. Relative frequency is the ratio of how many things in the category to how many things in the whole collection. The example below uses matplotlib to create a box plot for the ice cream analogy, the example is adapted from an example at https://www.geeksforgeeks.org/bar-plot-in-matplotlib/ ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! myfigure = matplotlib.pyplot.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot matplotlib.pyplot.bar(flavors, cartons, color ='maroon', width = 0.4) matplotlib.pyplot.xlabel(\"Flavors\") matplotlib.pyplot.ylabel(\"No. of Cartons in Stock\") matplotlib.pyplot.title(\"Current Ice Cream in Storage\") matplotlib.pyplot.show() Lets tidy up the script so it is more understandable, a small change in the import statement makes a simpler to read (for humans) script - also changed the bar colors just 'cause! ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot plt.bar(flavors, cartons, color ='orange', width = 0.4) plt.xlabel(\"Flavors\") plt.ylabel(\"No. of Cartons in Stock\") plt.title(\"Current Ice Cream in Storage\") plt.show() Using pandas, we can build bar charts a bit easier. import pandas as pd my_data = { \"Flavor\": ['Chocolate', 'Strawberry', 'Vanilla'], \"Number of Cartons\": [16, 5, 9] } df = pd.DataFrame(my_data) df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Flavor Number of Cartons 0 Chocolate 16 1 Strawberry 5 2 Vanilla 9 df.plot.bar(x='Flavor', y='Number of Cartons', color='magenta' ) <AxesSubplot:xlabel='Flavor'> df.plot.bar(x='Flavor', y='Number of Cartons', color=\"red\") # rotate the category labels <AxesSubplot:xlabel='Flavor'>","title":"Bar Graphs"},{"location":"8-Labs/Lab8/Lab8_Dev/#example-language-bars","text":"Consider the data set \"data\" defined as data = {'C':20, 'C++':15, 'Java':30, 'Python':35} which lists student count by programming language in some school. Produce a bar chart of number of students in each language, where language is the classification, and student count is the variable. # Code and run your solution here import numpy as np import matplotlib.pyplot as plt # creating the dataset data = {'C':20, 'C++':15, 'Java':30, 'Python':35} courses = list(data.keys()) values = list(data.values()) fig = plt.figure(figsize = (10, 5)) # creating the bar plot plt.bar(courses, values, color ='maroon', width = 0.4) plt.xlabel(\"Courses offered\") plt.ylabel(\"No. of students enrolled\") plt.title(\"Students enrolled in different courses\") plt.show()","title":"Example- Language Bars!"},{"location":"8-Labs/Lab8/Lab8_Dev/#plot-it-as-a-horizontal-bar-chart","text":"# Code and run your solution here # creating the dataset data = {'C':20, 'C++':15, 'Java':30, 'Python':35} courses = list(data.keys()) values = list(data.values()) fig = plt.figure(figsize = (10, 5)) # creating the bar plot plt.barh(courses, values, color ='maroon', height = 0.4) plt.xlabel(\"Courses offered\") plt.ylabel(\"No. of students enrolled\") plt.title(\"Students enrolled in different courses\") plt.show()","title":"Plot it as a horizontal bar chart:"},{"location":"8-Labs/Lab8/Lab8_Dev/#line-charts","text":"A line chart or line plot or line graph or curve chart is a type of chart which displays information as a series of data points called 'markers' connected by straight line segments. It is a basic type of chart common in many fields. It is similar to a scatter plot (below) except that the measurement points are ordered (typically by their x-axis value) and joined with straight line segments. A line chart is often used to visualize a trend in data over intervals of time \u2013 a time series \u2013 thus the line is often drawn chronologically. The x-axis spacing is sometimes tricky, hence line charts can unintentionally decieve - so be careful that it is the appropriate chart for your application.","title":"Line Charts"},{"location":"8-Labs/Lab8/Lab8_Dev/#example-speed-vs-time","text":"Consider the experimental data below Elapsed Time (s) Speed (m/s) 0 0 1.0 3 2.0 7 3.0 12 4.0 20 5.0 30 6.0 45.6 Show the relationship between time and speed. Is the relationship indicating acceleration? How much? # Create two lists; time and speed. time = [0,1.0,2.0,3.0,4.0,5.0,6.0] speed = [0,3,7,12,20,30,45.6] # Create a line chart of speed on y axis and time on x axis mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='v',linewidth=1) # basic line plot plt.show() From examination of the plot, estimate the speed at time t = 5.0 (eyeball estimate)","title":"Example- Speed vs Time"},{"location":"8-Labs/Lab8/Lab8_Dev/#example-add-a-linear-fit","text":"Using the same series from Exercise 1, Plot the speed vs time (speed on y-axis, time on x-axis) using a line plot. Plot a second line based on the linear model y = mx + b , where b=0~\\text{and}~m=7.6 . # Code and run your solution here: def ymodel(xmodel,slope,intercept): ymodel = slope*xmodel+intercept return(ymodel) yseries = [] slope = 7.6 intercept = 0.0 for i in range(0,len(time)): yseries.append(ymodel(time[i],slope,intercept)) # Create a markers only line chart mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='^',linewidth=0.5) # basic line plot plt.plot(time, yseries, c='blue') plt.show()","title":"Example- Add a linear fit"},{"location":"8-Labs/Lab8/Lab8_Dev/#example-find-a-better-fit","text":"Using trial and error try to improve the 'fit' of the model, by adjusting values of m~\\text{and}~b . # Code and run your solution here: yseries = [] slope = 7.6 intercept = -8.0 for i in range(0,len(time)): yseries.append(ymodel(time[i],slope,intercept)) # Create a markers only line chart mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='^',linewidth=0) # basic scatter plot plt.plot(time, yseries, c='blue') plt.show()","title":"Example- Find a better fit"},{"location":"8-Labs/Lab8/Lab8_Dev/#scatter-plots","text":"A scatter plot (also called a scatterplot, scatter graph, scatter chart, scattergram, or scatter diagram) is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. If the points are coded (color/shape/size), one additional variable can be displayed. The data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis. A scatter plot can be used either when one continuous variable that is under the control of the experimenter and the other depends on it or when both continuous variables are independent. If a parameter exists that is systematically incremented and/or decremented by the other, it is called the control parameter or independent variable and is customarily plotted along the horizontal axis. The measured or dependent variable is customarily plotted along the vertical axis. If no dependent variable exists, either type of variable can be plotted on either axis and a scatter plot will illustrate only the degree of correlation (not causation) between two variables. A scatter plot can suggest various kinds of correlations between variables with a certain confidence interval. For example, weight and height, weight would be on y axis and height would be on the x axis. Correlations may be positive (rising), negative (falling), or null (uncorrelated). If the pattern of dots slopes from lower left to upper right, it indicates a positive correlation between the variables being studied. If the pattern of dots slopes from upper left to lower right, it indicates a negative correlation. A line of best fit (alternatively called 'trendline') can be drawn in order to study the relationship between the variables. An equation for the correlation between the variables can be determined by established best-fit procedures. For a linear correlation, the best-fit procedure is known as linear regression and is guaranteed to generate a correct solution in a finite time. No universal best-fit procedure is guaranteed to generate a solution for arbitrary relationships. A scatter plot is also very useful when we wish to see how two comparable data sets agree and to show nonlinear relationships between variables. Furthermore, if the data are represented by a mixture model of simple relationships, these relationships will be visually evident as superimposed patterns. Scatter charts can be built in the form of bubble, marker, or/and line charts. Much of the above is verbatim/adapted from: https://en.wikipedia.org/wiki/Scatter_plot","title":"Scatter Plots"},{"location":"8-Labs/Lab8/Lab8_Dev/#example-examine-the-dataset-with-heights-of-fathers-mothers-and-sons","text":"df = pd.read_csv('galton_subset.csv') df['child']= df['son'] ; df.drop('son', axis=1, inplace = True) # rename son to child - got to imagine there are some daughters df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } father mother child 0 78.5 67.0 73.2 1 75.5 66.5 73.5 2 75.0 64.0 71.0 3 75.0 64.0 70.5 4 75.0 58.5 72.0 # build some lists dad = df['father'] ; mom = df['mother'] ; son = df['child'] myfamily = plt.figure(figsize = (10, 10)) # build a square drawing canvass from figure class plt.scatter(son, dad, c='red') # basic scatter plot plt.show() # Looks lousy, needs some labels myfamily = plt.figure(figsize = (10, 10)) # build a square drawing canvass from figure class plt.scatter(son, dad, c='red' , label='Father') # one plot series plt.scatter(son, mom, c='blue', label='Mother') # two plot series plt.xlabel(\"Child's height\") plt.ylabel(\"Parents' height\") plt.legend() plt.show() # render the two plots # Repeat in pandas - The dataframe already is built df.plot.scatter(x=\"child\", y=\"father\") <AxesSubplot:xlabel='child', ylabel='father'> ax = df.plot.scatter(x=\"child\", y=\"father\", c=\"red\", label='Father') df.plot.scatter(x=\"child\", y=\"mother\", c=\"blue\", label='Mother', ax=ax) ax.set_xlabel(\"Child's height\") ax.set_ylabel(\"Parents' Height\") Text(0, 0.5, \"Parents' Height\")","title":"Example- Examine the dataset with heights of fathers, mothers and sons"},{"location":"8-Labs/Lab8/Lab8_Dev/#histograms","text":"Quoting from https://en.wikipedia.org/wiki/Histogram \"A histogram is an approximate representation of the distribution of numerical data. It was first introduced by Karl Pearson.[1] To construct a histogram, the first step is to \"bin\" (or \"bucket\") the range of values\u2014that is, divide the entire range of values into a series of intervals\u2014and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) must be adjacent, and are often (but not required to be) of equal size. If the bins are of equal size, a rectangle is erected over the bin with height proportional to the frequency\u2014the number of cases in each bin. A histogram may also be normalized to display \"relative\" frequencies. It then shows the proportion of cases that fall into each of several categories, with the sum of the heights equaling 1. However, bins need not be of equal width; in that case, the erected rectangle is defined to have its area proportional to the frequency of cases in the bin. The vertical axis is then not the frequency but frequency density\u2014the number of cases per unit of the variable on the horizontal axis. Examples of variable bin width are displayed on Census bureau data below. As the adjacent bins leave no gaps, the rectangles of a histogram touch each other to indicate that the original variable is continuous. Histograms give a rough sense of the density of the underlying distribution of the data, and often for density estimation: estimating the probability density function of the underlying variable. The total area of a histogram used for probability density is always normalized to 1. If the length of the intervals on the x-axis are all 1, then a histogram is identical to a relative frequency plot. A histogram can be thought of as a simplistic kernel density estimation, which uses a kernel to smooth frequencies over the bins. This yields a smoother probability density function, which will in general more accurately reflect distribution of the underlying variable. The density estimate could be plotted as an alternative to the histogram, and is usually drawn as a curve rather than a set of boxes. Histograms are nevertheless preferred in applications, when their statistical properties need to be modeled. The correlated variation of a kernel density estimate is very difficult to describe mathematically, while it is simple for a histogram where each bin varies independently. An alternative to kernel density estimation is the average shifted histogram, which is fast to compute and gives a smooth curve estimate of the density without using kernels. The histogram is one of the seven basic tools of quality control. Histograms are sometimes confused with bar charts. A histogram is used for continuous data, where the bins represent ranges of data, while a bar chart is a plot of categorical variables. Some authors recommend that bar charts have gaps between the rectangles to clarify the distinction.\"","title":"Histograms"},{"location":"8-Labs/Lab8/Lab8_Dev/#example-explore-the-top_movies-dataset-and-draw-histograms-for-gross-and-year","text":"import pandas as pd df = pd.read_csv('top_movies.csv') df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Title Studio Gross Gross (Adjusted) Year 0 Star Wars: The Force Awakens Buena Vista (Disney) 906723418 906723400 2015 1 Avatar Fox 760507625 846120800 2009 2 Titanic Paramount 658672302 1178627900 1997 3 Jurassic World Universal 652270625 687728000 2015 4 Marvel's The Avengers Buena Vista (Disney) 623357910 668866600 2012 df[[\"Gross\"]].hist() array([[<AxesSubplot:title={'center':'Gross'}>]], dtype=object) df[[\"Year\"]].hist() array([[<AxesSubplot:title={'center':'Year'}>]], dtype=object) df[[\"Gross\"]].hist(bins=100)","title":"Example- Explore the \"top_movies\" dataset and draw histograms for Gross and Year."},{"location":"8-Labs/Lab8/Lab8_Dev/#this-is-a-matplotlib-cheat-sheet","text":"Here are some of the resources used for creating this notebook: \"Discrete distribution as horizontal bar chart\" available at *https://matplotlib.org/stable/gallery/lines_bars_and_markers/horizontal_barchart_distribution.html \"Bar Plot in Matplotlib\" available at *https://www.geeksforgeeks.org/bar-plot-in-matplotlib/ Here are some great reads on this topic: - \"Python | Introduction to Matplotlib\" available at https://www.geeksforgeeks.org/python-introduction-matplotlib/ - \"Visualization with Matplotlib\" available at https://jakevdp.github.io/PythonDataScienceHandbook/04.00-introduction-to-matplotlib.html - \"Introduction to Matplotlib \u2014 Data Visualization in Python\" by Ehi Aigiomawu available at https://heartbeat.fritz.ai/introduction-to-matplotlib-data-visualization-in-python-d9143287ae39 - \"Python Plotting With Matplotlib (Guide)\" by Brad Solomon available at https://realpython.com/python-matplotlib-guide/ Here are some great videos on these topics: - \"Matplotlib Tutorial (Part 1): Creating and Customizing Our First Plots\" by Corey Schafer available at https://www.youtube.com/watch?v=UO98lJQ3QGI - \"Intro to Data Analysis / Visualization with Python, Matplotlib and Pandas | Matplotlib Tutorial\" by CS Dojo available at https://www.youtube.com/watch?v=a9UrKTVEeZA - \"Intro to Data Visualization in Python with Matplotlib! (line graph, bar chart, title, labels, size)\" by Keith Galli available at *https://www.youtube.com/watch?v=DAQNHzOcO5A","title":"This is a Matplotlib Cheat Sheet"},{"location":"8-Labs/Lab8/Lab8_Dev/#exercise-bins-bins-bins","text":"","title":"Exercise: Bins, Bins, Bins!  "},{"location":"8-Labs/Lab8/Lab8_Dev/#selecting-the-number-of-bins-is-an-important-decision-when-working-with-histograms-are-there-any-rules-or-recommendations-for-choosing-the-number-or-width-of-bins-what-happens-if-we-use-too-many-or-too-few-bins","text":"","title":"Selecting the number of bins is an important decision when working with histograms. Are there any rules or recommendations for choosing the number or width of bins? What happens if we use too many or too few bins?"},{"location":"8-Labs/Lab8/Lab8_Dev/#make-sure-to-cite-any-resources-that-you-may-use","text":"","title":"* Make sure to cite any resources that you may use."},{"location":"8-Labs/Lab9/Lab9_Dev/","text":"# Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) Full name: R#: HEX: Title of the notebook Date: Lab9: Simulation Example1: Simulate a game of Russian Roulette: For 2 rounds For 5 rounds For 10 rounds import numpy as np #import numpy revolver = np.array([1,0,0,0,0,0]) #create a numpy array with 1 bullet and 5 empty chambers print(np.random.choice(revolver,2)) #randomly select a value from revolver - simulation [0 0] print(np.random.choice(revolver,5)) [0 0 0 1 1] print(np.random.choice(revolver,10)) [0 0 0 0 0 0 0 0 0 0] Exercise 1: Simulate the results of throwing a D6 (regular dice) for 10 times. Example2: Assume the following rules: If the dice shows 1 or 2 spots, my net gain is -1 dollar. If the dice shows 3 or 4 spots, my net gain is 0 dollars. If the dice shows 5 or 6 spots, my net gain is 1 dollar. Define a function to simulate a game with the above rules, assuming a D6, and compute the net gain of the player over any given number of rolls. Compute the net gain for 5, 50, and 500 rolls def D6game(nrolls): import numpy as np #import numpy dice = np.array([1,2,3,4,5,6]) #create a numpy array with values of a D6 rolls = np.random.choice(dice,nrolls) #randomly selecting a value from dice for nrolls times- simulation gainlist =[] #create an empty list for gains|losses for i in np.arange(len(rolls)): #Apply the rules if rolls[i]<=2: gainlist.append(-1) elif rolls[i]<=4: gainlist.append(0) elif rolls[i]<=6: gainlist.append(+1) return (np.sum(gainlist)) #sum up all gains|losses # return (gainlist,\"The net gain is equal to:\",np.sum(gainlist)) D6game(5) -2 D6game(50) -4 D6game(500) -16 Exercise2: Assume the following rules: If the dice shows 1 or 2 spots, my net gain is (-2*value of dice) dollars. If the dice shows 3 or 4 spots, my net gain is 1 dollars. If the dice shows 5 spots, my net gain is (2*value of dice) dollars. If the dice shows 6 spots, my net gain is -5 dollars. Define a function to simulate a game with the above rules, assuming a D6, and compute the net gain of the player over any given number of rolls. Compute the net gain for 5, 50, and 500 rolls # Define the function # Run for 5 rounds # Run for 50 rounds # Run for 500 rounds Example3: Simulate Monty Hall Game for 1000 times. Use a barplot and discuss whether players are better off sticking to their initial choice, or switching doors? def othergoat(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return \"Goat 2\" elif x == \"Goat 2\": return \"Goat 1\" Doors = np.array([\"Car\",\"Goat 1\",\"Goat 2\"]) #Define a list for objects behind the doors goats = np.array([\"Goat 1\" , \"Goat 2\"]) #Define a list for goats! def MHgame(): #Function to simulate the Monty Hall Game #For each guess, return [\"the guess\",\"the revealed\", \"the remaining\"] userguess=np.random.choice(Doors) #randomly selects a door as userguess if userguess == \"Goat 1\": return [userguess, \"Goat 2\",\"Car\"] if userguess == \"Goat 2\": return [userguess, \"Goat 1\",\"Car\"] if userguess == \"Car\": revealed = np.random.choice(goats) return [userguess, revealed,othergoat(revealed)] # Check and see if the MHgame function is doing what it is supposed to do: for i in np.arange(1): a =MHgame() print(a) print(a[0]) print(a[1]) print(a[2]) ['Goat 1', 'Goat 2', 'Car'] Goat 1 Goat 2 Car c1 = [] #Create an empty list for the userguess c2 = [] #Create an empty list for the revealed c3 = [] #Create an empty list for the remaining for i in np.arange(1000): #Simulate the game for 1000 rounds - or any other number of rounds you desire game = MHgame() c1.append(game[0]) #In each round, add the first element to the userguess list c2.append(game[1]) #In each round, add the second element to the revealed list c3.append(game[2]) #In each round, add the third element to the remaining list import pandas as pd #Create a data frame (gamedf) with 3 columns (\"Guess\",\"Revealed\", \"Remaining\") and 1000 (or how many number of rounds) rows gamedf = pd.DataFrame({'Guess':c1, 'Revealed':c2, 'Remaining':c3}) gamedf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Guess Revealed Remaining 0 Car Goat 1 Goat 2 1 Car Goat 2 Goat 1 2 Car Goat 2 Goat 1 3 Goat 2 Goat 1 Car 4 Goat 2 Goat 1 Car ... ... ... ... 995 Car Goat 2 Goat 1 996 Car Goat 2 Goat 1 997 Goat 2 Goat 1 Car 998 Goat 2 Goat 1 Car 999 Goat 2 Goat 1 Car 1000 rows \u00d7 3 columns # Get the count of each item in the first and 3rd column original_car =gamedf[gamedf.Guess == 'Car'].shape[0] remaining_car =gamedf[gamedf.Remaining == 'Car'].shape[0] original_g1 =gamedf[gamedf.Guess == 'Goat 1'].shape[0] remaining_g1 =gamedf[gamedf.Remaining == 'Goat 1'].shape[0] original_g2 =gamedf[gamedf.Guess == 'Goat 2'].shape[0] remaining_g2 =gamedf[gamedf.Remaining == 'Goat 2'].shape[0] # Let's plot a grouped barplot import matplotlib.pyplot as plt # set width of bar barWidth = 0.25 # set height of bar bars1 = [original_car,original_g1,original_g2] bars2 = [remaining_car,remaining_g1,remaining_g2] # Set position of bar on X axis r1 = np.arange(len(bars1)) r2 = [x + barWidth for x in r1] # Make the plot plt.bar(r1, bars1, color='darkorange', width=barWidth, edgecolor='white', label='Original Guess') plt.bar(r2, bars2, color='midnightblue', width=barWidth, edgecolor='white', label='Remaining Door') # Add xticks on the middle of the group bars plt.xlabel('Item', fontweight='bold') plt.xticks([r + barWidth/2 for r in range(len(bars1))], ['Car', 'Goat 1', 'Goat 2']) # Create legend & Show graphic plt.legend() plt.show() According to the plot, it is statitically beneficial for the players to switch doors because the initial chance for being correct is only 1/3 Example4: What if there were 4 doors and 3 goats? import numpy as np import pandas as pd import matplotlib.pyplot as plt Doors = np.array([\"Car\",\"Goat 1\",\"Goat 2\",\"Goat 3\"]) #Define a list for objects behind the doors goats = np.array([\"Goat 1\" , \"Goat 2\",\"Goat 3\"]) #Define a list for goats! def othergoat12(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return \"Goat 2\" elif x == \"Goat 2\": return \"Goat 1\" def othergoat23(x): #Define a function to return \"the other goat\"! if x == \"Goat 2\": return \"Goat 3\" elif x == \"Goat 3\": return \"Goat 2\" def othergoat13(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return \"Goat 3\" elif x == \"Goat 3\": return \"Goat 1\" ##################################### def othergoat123(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return np.random.choice([\"Goat 2\",\"Goat 3\"]) elif x == \"Goat 2\": return np.random.choice([\"Goat 1\",\"Goat 3\"]) elif x == \"Goat 3\": return np.random.choice([\"Goat 1\",\"Goat 2\"]) def MHgame(): #Function to simulate the Monty Hall Game #For each guess, return [\"the guess\",\"the revealed\", \"unrevealed1\", \"unrevealed2\"] goats = np.array([\"Goat 1\" , \"Goat 2\",\"Goat 3\"]) userguess=np.random.choice(Doors) #randomly selects a door as userguess if userguess == \"Goat 1\": #If the user chooses Goat 1 revealed = np.random.choice(goats[np.arange(len(goats))!=0]) unrevealed1 = othergoat23(revealed) unrevealed2 = \"Car\" return [userguess, revealed,unrevealed1,unrevealed2] if userguess == \"Goat 2\": #If the user chooses Goat 2 revealed = np.random.choice(goats[np.arange(len(goats))!=1]) unrevealed1 = othergoat13(revealed) unrevealed2 = \"Car\" return [userguess, revealed,unrevealed1,unrevealed2] if userguess == \"Goat 3\": #If the user chooses Goat 3 revealed = np.random.choice(goats[np.arange(len(goats))!=2]) unrevealed1 = othergoat12(revealed) unrevealed2 = \"Car\" return [userguess, revealed,unrevealed1,unrevealed2] if userguess == \"Car\": #If the user chooses Car revealed = np.random.choice(goats) newgoat = goats[goats != revealed] unrevealed1 = newgoat[0] unrevealed2 = newgoat[1] return [userguess, revealed,unrevealed1,unrevealed2] # Check and see if the MHgame function is doing what it is supposed to do: for i in np.arange(1): a =MHgame() print(a) print(a[0]) print(a[1]) print(a[2]) print(a[3]) ['Car', 'Goat 1', 'Goat 2', 'Goat 3'] Car Goat 1 Goat 2 Goat 3 c1 = [] #Create an empty list for the userguess c2 = [] #Create an empty list for the revealed c3 = [] #Create an empty list for the remaining1 c4 = [] #Create an empty list for the remaining2 for i in np.arange(1000): #Simulate the game for 1000 rounds - or any other number of rounds you desire game = MHgame() c1.append(game[0]) #In each round, add the first element to the userguess list c2.append(game[1]) #In each round, add the second element to the revealed list c3.append(game[2]) #In each round, add the third element to the remaining list1 c4.append(game[3]) #In each round, add the fourth element to the remaining list2 import pandas as pd #Create a data frame (gamedf) with 3 columns (\"Guess\",\"Revealed\", \"Remaining\") and 1000 (or how many number of rounds) rows gamedf = pd.DataFrame({'Guess':c1, 'Revealed':c2, 'Remaining1':c3, 'Remaining2':c4}) gamedf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Guess Revealed Remaining1 Remaining2 0 Goat 3 Goat 2 Goat 1 Car 1 Goat 3 Goat 2 Goat 1 Car 2 Goat 1 Goat 3 Goat 2 Car 3 Goat 1 Goat 2 Goat 3 Car 4 Goat 2 Goat 1 Goat 3 Car ... ... ... ... ... 995 Goat 1 Goat 2 Goat 3 Car 996 Car Goat 1 Goat 2 Goat 3 997 Goat 2 Goat 1 Goat 3 Car 998 Goat 3 Goat 1 Goat 2 Car 999 Goat 2 Goat 1 Goat 3 Car 1000 rows \u00d7 4 columns # Get the count of each item in the first and (3rd+4th) column original_car =gamedf[gamedf.Guess == 'Car'].shape[0] remaining_car =gamedf[gamedf.Remaining1 == 'Car'].shape[0] + gamedf[gamedf.Remaining2 == 'Car'].shape[0] original_g1 =gamedf[gamedf.Guess == 'Goat 1'].shape[0] remaining_g1 =gamedf[gamedf.Remaining1 == 'Goat 1'].shape[0] + gamedf[gamedf.Remaining2 == 'Goat 1'].shape[0] original_g2 =gamedf[gamedf.Guess == 'Goat 2'].shape[0] remaining_g2 =gamedf[gamedf.Remaining1 == 'Goat 2'].shape[0] + gamedf[gamedf.Remaining2 == 'Goat 2'].shape[0] original_g3 =gamedf[gamedf.Guess == 'Goat 3'].shape[0] remaining_g3 =gamedf[gamedf.Remaining1 == 'Goat 3'].shape[0] + gamedf[gamedf.Remaining2 == 'Goat 3'].shape[0] # Let's plot a grouped barplot import matplotlib.pyplot as plt # set width of bar barWidth = 0.25 # set height of bar bars1 = [original_car,original_g1,original_g2,original_g3] bars2 = [remaining_car,remaining_g1,remaining_g2,remaining_g3] # Set position of bar on X axis r1 = np.arange(len(bars1)) r2 = [x + barWidth for x in r1] # Make the plot plt.bar(r1, bars1, color='darkorange', width=barWidth, edgecolor='white', label='Original Guess') plt.bar(r2, bars2, color='midnightblue', width=barWidth, edgecolor='white', label='Remaining Door') # Add xticks on the middle of the group bars plt.xlabel('Item', fontweight='bold') plt.xticks([r + barWidth/2 for r in range(len(bars1))], ['Car', 'Goat 1', 'Goat 2','Goat 3']) # Create legend & Show graphic plt.legend() plt.show() Comparison of the plots show that as the number of doors (and goats) increases, it makes even more sense to switch! Exercise3: Run the modified Monty Hall game for 10,100, and 1000 rounds. Show the bar plots for each series and explain the difference. #Define necessary functions #Run and plot for 10 rounds #Run and plot for 100 rounds #Run and plot for 1000 rounds","title":"Workshop 9"},{"location":"8-Labs/Lab9/Lab9_Dev/#full-name","text":"","title":"Full name:"},{"location":"8-Labs/Lab9/Lab9_Dev/#r","text":"","title":"R#:"},{"location":"8-Labs/Lab9/Lab9_Dev/#hex","text":"","title":"HEX:"},{"location":"8-Labs/Lab9/Lab9_Dev/#title-of-the-notebook","text":"","title":"Title of the notebook"},{"location":"8-Labs/Lab9/Lab9_Dev/#date","text":"","title":"Date:"},{"location":"8-Labs/Lab9/Lab9_Dev/#lab9-simulation","text":"","title":"Lab9: Simulation"},{"location":"8-Labs/Lab9/Lab9_Dev/#example1-simulate-a-game-of-russian-roulette","text":"For 2 rounds For 5 rounds For 10 rounds import numpy as np #import numpy revolver = np.array([1,0,0,0,0,0]) #create a numpy array with 1 bullet and 5 empty chambers print(np.random.choice(revolver,2)) #randomly select a value from revolver - simulation [0 0] print(np.random.choice(revolver,5)) [0 0 0 1 1] print(np.random.choice(revolver,10)) [0 0 0 0 0 0 0 0 0 0]","title":"Example1: Simulate a game of Russian Roulette:"},{"location":"8-Labs/Lab9/Lab9_Dev/#exercise-1-simulate-the-results-of-throwing-a-d6-regular-dice-for-10-times","text":"","title":"Exercise 1: Simulate the results of throwing a D6 (regular dice) for 10 times."},{"location":"8-Labs/Lab9/Lab9_Dev/#example2-assume-the-following-rules","text":"If the dice shows 1 or 2 spots, my net gain is -1 dollar. If the dice shows 3 or 4 spots, my net gain is 0 dollars. If the dice shows 5 or 6 spots, my net gain is 1 dollar. Define a function to simulate a game with the above rules, assuming a D6, and compute the net gain of the player over any given number of rolls. Compute the net gain for 5, 50, and 500 rolls def D6game(nrolls): import numpy as np #import numpy dice = np.array([1,2,3,4,5,6]) #create a numpy array with values of a D6 rolls = np.random.choice(dice,nrolls) #randomly selecting a value from dice for nrolls times- simulation gainlist =[] #create an empty list for gains|losses for i in np.arange(len(rolls)): #Apply the rules if rolls[i]<=2: gainlist.append(-1) elif rolls[i]<=4: gainlist.append(0) elif rolls[i]<=6: gainlist.append(+1) return (np.sum(gainlist)) #sum up all gains|losses # return (gainlist,\"The net gain is equal to:\",np.sum(gainlist)) D6game(5) -2 D6game(50) -4 D6game(500) -16","title":"Example2: Assume the following rules:"},{"location":"8-Labs/Lab9/Lab9_Dev/#exercise2-assume-the-following-rules","text":"If the dice shows 1 or 2 spots, my net gain is (-2*value of dice) dollars. If the dice shows 3 or 4 spots, my net gain is 1 dollars. If the dice shows 5 spots, my net gain is (2*value of dice) dollars. If the dice shows 6 spots, my net gain is -5 dollars. Define a function to simulate a game with the above rules, assuming a D6, and compute the net gain of the player over any given number of rolls. Compute the net gain for 5, 50, and 500 rolls # Define the function # Run for 5 rounds # Run for 50 rounds # Run for 500 rounds","title":"Exercise2: Assume the following rules:"},{"location":"8-Labs/Lab9/Lab9_Dev/#example3-simulate-monty-hall-game-for-1000-times-use-a-barplot-and-discuss-whether-players-are-better-off-sticking-to-their-initial-choice-or-switching-doors","text":"def othergoat(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return \"Goat 2\" elif x == \"Goat 2\": return \"Goat 1\" Doors = np.array([\"Car\",\"Goat 1\",\"Goat 2\"]) #Define a list for objects behind the doors goats = np.array([\"Goat 1\" , \"Goat 2\"]) #Define a list for goats! def MHgame(): #Function to simulate the Monty Hall Game #For each guess, return [\"the guess\",\"the revealed\", \"the remaining\"] userguess=np.random.choice(Doors) #randomly selects a door as userguess if userguess == \"Goat 1\": return [userguess, \"Goat 2\",\"Car\"] if userguess == \"Goat 2\": return [userguess, \"Goat 1\",\"Car\"] if userguess == \"Car\": revealed = np.random.choice(goats) return [userguess, revealed,othergoat(revealed)] # Check and see if the MHgame function is doing what it is supposed to do: for i in np.arange(1): a =MHgame() print(a) print(a[0]) print(a[1]) print(a[2]) ['Goat 1', 'Goat 2', 'Car'] Goat 1 Goat 2 Car c1 = [] #Create an empty list for the userguess c2 = [] #Create an empty list for the revealed c3 = [] #Create an empty list for the remaining for i in np.arange(1000): #Simulate the game for 1000 rounds - or any other number of rounds you desire game = MHgame() c1.append(game[0]) #In each round, add the first element to the userguess list c2.append(game[1]) #In each round, add the second element to the revealed list c3.append(game[2]) #In each round, add the third element to the remaining list import pandas as pd #Create a data frame (gamedf) with 3 columns (\"Guess\",\"Revealed\", \"Remaining\") and 1000 (or how many number of rounds) rows gamedf = pd.DataFrame({'Guess':c1, 'Revealed':c2, 'Remaining':c3}) gamedf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Guess Revealed Remaining 0 Car Goat 1 Goat 2 1 Car Goat 2 Goat 1 2 Car Goat 2 Goat 1 3 Goat 2 Goat 1 Car 4 Goat 2 Goat 1 Car ... ... ... ... 995 Car Goat 2 Goat 1 996 Car Goat 2 Goat 1 997 Goat 2 Goat 1 Car 998 Goat 2 Goat 1 Car 999 Goat 2 Goat 1 Car 1000 rows \u00d7 3 columns # Get the count of each item in the first and 3rd column original_car =gamedf[gamedf.Guess == 'Car'].shape[0] remaining_car =gamedf[gamedf.Remaining == 'Car'].shape[0] original_g1 =gamedf[gamedf.Guess == 'Goat 1'].shape[0] remaining_g1 =gamedf[gamedf.Remaining == 'Goat 1'].shape[0] original_g2 =gamedf[gamedf.Guess == 'Goat 2'].shape[0] remaining_g2 =gamedf[gamedf.Remaining == 'Goat 2'].shape[0] # Let's plot a grouped barplot import matplotlib.pyplot as plt # set width of bar barWidth = 0.25 # set height of bar bars1 = [original_car,original_g1,original_g2] bars2 = [remaining_car,remaining_g1,remaining_g2] # Set position of bar on X axis r1 = np.arange(len(bars1)) r2 = [x + barWidth for x in r1] # Make the plot plt.bar(r1, bars1, color='darkorange', width=barWidth, edgecolor='white', label='Original Guess') plt.bar(r2, bars2, color='midnightblue', width=barWidth, edgecolor='white', label='Remaining Door') # Add xticks on the middle of the group bars plt.xlabel('Item', fontweight='bold') plt.xticks([r + barWidth/2 for r in range(len(bars1))], ['Car', 'Goat 1', 'Goat 2']) # Create legend & Show graphic plt.legend() plt.show() According to the plot, it is statitically beneficial for the players to switch doors because the initial chance for being correct is only 1/3","title":"Example3: Simulate Monty Hall Game for 1000 times. Use a barplot and discuss whether players are better off sticking to their initial choice, or switching doors?"},{"location":"8-Labs/Lab9/Lab9_Dev/#example4-what-if-there-were-4-doors-and-3-goats","text":"import numpy as np import pandas as pd import matplotlib.pyplot as plt Doors = np.array([\"Car\",\"Goat 1\",\"Goat 2\",\"Goat 3\"]) #Define a list for objects behind the doors goats = np.array([\"Goat 1\" , \"Goat 2\",\"Goat 3\"]) #Define a list for goats! def othergoat12(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return \"Goat 2\" elif x == \"Goat 2\": return \"Goat 1\" def othergoat23(x): #Define a function to return \"the other goat\"! if x == \"Goat 2\": return \"Goat 3\" elif x == \"Goat 3\": return \"Goat 2\" def othergoat13(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return \"Goat 3\" elif x == \"Goat 3\": return \"Goat 1\" ##################################### def othergoat123(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return np.random.choice([\"Goat 2\",\"Goat 3\"]) elif x == \"Goat 2\": return np.random.choice([\"Goat 1\",\"Goat 3\"]) elif x == \"Goat 3\": return np.random.choice([\"Goat 1\",\"Goat 2\"]) def MHgame(): #Function to simulate the Monty Hall Game #For each guess, return [\"the guess\",\"the revealed\", \"unrevealed1\", \"unrevealed2\"] goats = np.array([\"Goat 1\" , \"Goat 2\",\"Goat 3\"]) userguess=np.random.choice(Doors) #randomly selects a door as userguess if userguess == \"Goat 1\": #If the user chooses Goat 1 revealed = np.random.choice(goats[np.arange(len(goats))!=0]) unrevealed1 = othergoat23(revealed) unrevealed2 = \"Car\" return [userguess, revealed,unrevealed1,unrevealed2] if userguess == \"Goat 2\": #If the user chooses Goat 2 revealed = np.random.choice(goats[np.arange(len(goats))!=1]) unrevealed1 = othergoat13(revealed) unrevealed2 = \"Car\" return [userguess, revealed,unrevealed1,unrevealed2] if userguess == \"Goat 3\": #If the user chooses Goat 3 revealed = np.random.choice(goats[np.arange(len(goats))!=2]) unrevealed1 = othergoat12(revealed) unrevealed2 = \"Car\" return [userguess, revealed,unrevealed1,unrevealed2] if userguess == \"Car\": #If the user chooses Car revealed = np.random.choice(goats) newgoat = goats[goats != revealed] unrevealed1 = newgoat[0] unrevealed2 = newgoat[1] return [userguess, revealed,unrevealed1,unrevealed2] # Check and see if the MHgame function is doing what it is supposed to do: for i in np.arange(1): a =MHgame() print(a) print(a[0]) print(a[1]) print(a[2]) print(a[3]) ['Car', 'Goat 1', 'Goat 2', 'Goat 3'] Car Goat 1 Goat 2 Goat 3 c1 = [] #Create an empty list for the userguess c2 = [] #Create an empty list for the revealed c3 = [] #Create an empty list for the remaining1 c4 = [] #Create an empty list for the remaining2 for i in np.arange(1000): #Simulate the game for 1000 rounds - or any other number of rounds you desire game = MHgame() c1.append(game[0]) #In each round, add the first element to the userguess list c2.append(game[1]) #In each round, add the second element to the revealed list c3.append(game[2]) #In each round, add the third element to the remaining list1 c4.append(game[3]) #In each round, add the fourth element to the remaining list2 import pandas as pd #Create a data frame (gamedf) with 3 columns (\"Guess\",\"Revealed\", \"Remaining\") and 1000 (or how many number of rounds) rows gamedf = pd.DataFrame({'Guess':c1, 'Revealed':c2, 'Remaining1':c3, 'Remaining2':c4}) gamedf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Guess Revealed Remaining1 Remaining2 0 Goat 3 Goat 2 Goat 1 Car 1 Goat 3 Goat 2 Goat 1 Car 2 Goat 1 Goat 3 Goat 2 Car 3 Goat 1 Goat 2 Goat 3 Car 4 Goat 2 Goat 1 Goat 3 Car ... ... ... ... ... 995 Goat 1 Goat 2 Goat 3 Car 996 Car Goat 1 Goat 2 Goat 3 997 Goat 2 Goat 1 Goat 3 Car 998 Goat 3 Goat 1 Goat 2 Car 999 Goat 2 Goat 1 Goat 3 Car 1000 rows \u00d7 4 columns # Get the count of each item in the first and (3rd+4th) column original_car =gamedf[gamedf.Guess == 'Car'].shape[0] remaining_car =gamedf[gamedf.Remaining1 == 'Car'].shape[0] + gamedf[gamedf.Remaining2 == 'Car'].shape[0] original_g1 =gamedf[gamedf.Guess == 'Goat 1'].shape[0] remaining_g1 =gamedf[gamedf.Remaining1 == 'Goat 1'].shape[0] + gamedf[gamedf.Remaining2 == 'Goat 1'].shape[0] original_g2 =gamedf[gamedf.Guess == 'Goat 2'].shape[0] remaining_g2 =gamedf[gamedf.Remaining1 == 'Goat 2'].shape[0] + gamedf[gamedf.Remaining2 == 'Goat 2'].shape[0] original_g3 =gamedf[gamedf.Guess == 'Goat 3'].shape[0] remaining_g3 =gamedf[gamedf.Remaining1 == 'Goat 3'].shape[0] + gamedf[gamedf.Remaining2 == 'Goat 3'].shape[0] # Let's plot a grouped barplot import matplotlib.pyplot as plt # set width of bar barWidth = 0.25 # set height of bar bars1 = [original_car,original_g1,original_g2,original_g3] bars2 = [remaining_car,remaining_g1,remaining_g2,remaining_g3] # Set position of bar on X axis r1 = np.arange(len(bars1)) r2 = [x + barWidth for x in r1] # Make the plot plt.bar(r1, bars1, color='darkorange', width=barWidth, edgecolor='white', label='Original Guess') plt.bar(r2, bars2, color='midnightblue', width=barWidth, edgecolor='white', label='Remaining Door') # Add xticks on the middle of the group bars plt.xlabel('Item', fontweight='bold') plt.xticks([r + barWidth/2 for r in range(len(bars1))], ['Car', 'Goat 1', 'Goat 2','Goat 3']) # Create legend & Show graphic plt.legend() plt.show() Comparison of the plots show that as the number of doors (and goats) increases, it makes even more sense to switch!","title":"Example4: What if there were 4 doors and 3 goats?"},{"location":"8-Labs/Lab9/Lab9_Dev/#exercise3-run-the-modified-monty-hall-game-for-10100-and-1000-rounds-show-the-bar-plots-for-each-series-and-explain-the-difference","text":"#Define necessary functions #Run and plot for 10 rounds #Run and plot for 100 rounds #Run and plot for 1000 rounds","title":"Exercise3: Run the modified Monty Hall game for 10,100, and 1000 rounds. Show the bar plots for each series and explain the difference."},{"location":"lesson0/lesson0/","text":"table {margin-left: 0 !important;} ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 13 January 2021 Lesson 0 Introduction to Computational Thinking with Data Science: Computational thinking concepts Data science and practices JupyterLab (iPython) as a programming environment Programming as a problem solving process CCMR Approach Special Script Blocks In the lesson notebooks there will usually be two script blocks, identical to the ones below. The first block identifies the particular computer, the user, and the python kernel in use. The second block sets markdown tables to left edge when rendering. I usually put both blocks at the top of the notebook, just after some kind of title block, as done here. Computational Thinking Concepts Computational thinking (CT) refers to the thought processes involved in expressing solutions as computational steps or algorithms that can be carried out by a computer. Much of what follows is borrowed from (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2696102/). Computational thinking is taking an approach to solving problems, designing systems and understanding human behaviour that draws on concepts fundamental to computing (http://www.cs.cmu.edu/~15110-s13/Wing06-ct.pdf). Computational thinking is a kind of analytical thinking: It shares with mathematical thinking in the general ways in which we might approach solving a problem. It shares with engineering thinking in the general ways in which we might approach designing and evaluating a large, complex system that operates within the constraints of the real world. - It shares with scientific thinking in the general ways in which we might approach understanding computability, intelligence, the mind and human behaviour. The essence of computational thinking is abstraction and automation . In computing, we abstract notions beyond the physical dimensions of time and space. Our abstractions are extremely general because they are symbolic, where numeric abstractions are just a special case. CT Foundations CT is literally a process for breaking down a problem into smaller parts, looking for patterns in the problems, identifying what kind of information is needed, developing a step-by-step solution, and implementing that solution. Decomposition Pattern Recognition Abstraction Algorithms System Integration (implementation) Decomposition Decomposition is the process of taking a complex problem and breaking it into more manageable sub-problems. Examples include: - Writing a paper: - Introduction - Body - Conclusion Wide-viewed (Panorama) image: Taking multiple overlapped photos Stitch them Decomposition often leaves a framework of sub-problems that later have to be assembled (system integration) to produce a desired solution. Pattern Recognition Refers to finding similarities, or shared characteristics of problems. Allows a complex problem to become easier to solve. Allows use of same solution method for each occurrence of the pattern. Pattern recognition allows use of automation to process things - its a fundamental drilled shaft of CT. It also provides a way to use analogs from old problems to address new situations; it also will require assembly (system integration) to produce a desired solution. Abstraction Determine important characteristics of the problem and ignore characteristics that are not important. Use these characteristics to create a representation of what we are trying to solve. Books in an online bookstore Important NOT important title Cover color ISBN Author\u2019s hometown Authors ... ... ... Algorithms Step-by-step instructions of how to solve a problem (https://en.wikipedia.org/wiki/Algorithm). Identifies what is to be done, and the order in which they should be done. Image from https://www.newyorker.com/magazine/2021/01/18/whats-wrong-with-the-way-we-work?utm_source=pocket-newtab An algorithm is a finite sequence of defined, instructions, typically to solve a class of problems or to perform a computation. Algorithms are unambiguous and are used as specifications for performing calculations, data processing, automated reasoning, and other tasks. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, can incorporate random input. System Integration (implementation) System integration is the assembly of the parts above into the complete (integrated) solution. Integration combines parts into a program which is the realization of an algorithm using a syntax that the computer can understand. Data Science and Practice Data science is leveraging existing data sources, to create new ones as needed in order to extract meaningful information and actionable insights through business domain expertise, effective communication and results interpretation. Data science uses relevant statistical techniques, programming languages, software packages and libraries, and data infrastructure; The insights are used to drive business decisions and take actions intended to achieve business goals. Why is this important for engineers? Because engineering is a business! A list of typical skills (https://elitedatascience.com/data-science-resources): Foundational Skills Programming and Data Manipulation Statistics and Probability Technical Skills Data Collection SQL Data Visualization Applied Machine Learning Business Skills Communication Creativity and Innovation Operations and Strategy Business Analytics Supplementary Skills Natural Language Processing Recommendation Systems Time Series Analysis Practice Projects Competitions Problem Solving Challenges JupyterLab (iPython) Environment The tools: JupyterLab (https://jupyter.org/) is a web-based interactive development environment for Jupyter notebooks, code, and data. Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data organizing and transformation, numerical simulation, statistical modeling, visualization, machine learning, and other similar types of uses. JupyterHub (https://github.com/jupyterhub/jupyterhub) is a multi-user Hub that spawns, manages, and proxies multiple instances of the single-user Jupyter notebook server. All these tools allow use of various coding languages; Python is the choice for ENGR 1330. Installing JupyterLab on your own computer is relatively straightforward if it is an Intel-based Linux, Macintosh, or Windows machine - simply use Anaconda (https://www.anaconda.com/) as the installer. Installing onto an ARM-based machine is more difficult, but possible (this notebook was created on a Raspberry Pi). With both Apple and Microsoft abandoning Intel you can expect Anaconda builds for aarch64 (ARM) in the future. This course: You will create and use Jupyter Notebooks that use the ipython kernel, the notebook files will look like filename.ipynb ; these are ASCII files that the JupyterLab interprets and runs. Python The programming language we will use is Python (actually iPython). Python is an example of a high-level language; other high-level languages include C, C++, PHP, FORTRAN, ADA, Pascal, Go, Java, etc (there are a lot). As you might infer from the name high-level language, there are also low-level languages, sometimes referred to as machine languages or assembly languages. Machine language is the encoding of instructions in binary so that they can be directly executed by the computer. Assembly language uses a slightly easier format to refer to the low level instructions. Loosely speaking, computers can only execute programs written in low-level languages. To be exact, computers can actually only execute programs written in machine language. Thus, programs written in a high-level language (and even those in assembly language) have to be processed before they can run. This extra processing takes some time, which is a small disadvantage of high-level languages. However, the advantages to high-level languages are enormous. First, it is much easier to program in a high-level language. Programs written in a high-level language take less time to write, they are shorter and easier to read, and they are more likely to be correct. Second, high-level languages are portable, meaning that they can run on different kinds of computers with few or no modifications. Low-level programs can run on only one kind of computer and have to be rewritten to run on another. Due to these advantages, almost all programs are written in high-level languages. Low-level languages are used only for a few specialized applications, and for device drivers. Two kinds of programs process high-level languages into low-level languages: interpreters and compilers. An interpreter reads a high-level program and executes it, meaning that it does what the program says. It processes the program a little at a time, alternately reading lines and performing computations. Interpreted Program. Image from (https://runestone.academy/runestone/books/published/thinkcspy/GeneralIntro/ThePythonProgrammingLanguage.html) A compiler reads the program and translates it completely before the program starts running. In this case, the high-level program is called the source code, and the translated program is called the object code or the executable. Once a program is compiled, you can execute it repeatedly without further translation. Compiled Prorgam. Image from: (https://runestone.academy/runestone/books/published/thinkcspy/GeneralIntro/ThePythonProgrammingLanguage.html) Many modern languages use both processes. They are first compiled into a lower level language, called byte code, and then interpreted by a program called a virtual machine. Python uses both processes, but because of the way programmers interact with it, it is usually considered an interpreted language. As a language, python is a formal language that has certain requirements and structure called \"syntax.\" Formal languages are languages that are designed by people for specific applications. For example, the notation that mathematicians use is a formal language that is particularly good at denoting relationships among numbers and symbols. Chemists use a formal language to represent the chemical structure of molecules. Programming languages are formal languages that have been designed to express computations. Formal languages have strict rules about syntax. For example, 3+3=6 is a syntactically correct mathematical statement, but 3=+6& is not. Syntax rules come in two flavors, pertaining to tokens and structure . Tokens are the basic elements of the language, such as words, numbers, and chemical elements. One of the problems with 3=+6& is that & is not a legal token in mathematics (at least as far as we know). The second type of syntax rule pertains to the structure of a statement\u2014 that is, the way the tokens are arranged. The statement 3=+6& is structurally illegal (in mathematics) because you don\u2019t place a plus sign immediately after an equal sign (of course we will in python!). When you read a sentence in English or a statement in a formal language, you have to figure out what the structure of the sentence is; This process is called parsing . For example, when you hear the sentence, \u201cThe other shoe fell\u201d, you understand that the other shoe is the subject and fell is the verb. Once you have parsed a sentence, you can figure out what it means, or the semantics of the sentence. Assuming that you know what a shoe is and what it means to fall, you will understand the general implication of this sentence. Good Resources: Learn Python the Hard Way (Online Book) (https://learnpythonthehardway.org/book/) Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) (https://www.learnpython.org/) Short, interactive tutorial for those who just need a quick way to pick up Python syntax. How to Think Like a Computer Scientist (Interactive Book) (https://runestone.academy/runestone/books/published/thinkcspy/index.html) Interactive \"CS 101\" course taught in Python that really focuses on the art of problem solving. How to Learn Python for Data Science, The Self-Starter Way (https://elitedatascience.com/learn-python-for-data-science) Programming as a problem solving process The entire point of this course is to develop problem solving skills and begin using some tools (Statistics, Numerical Methods, Data Science, implemented as JupyterLab/Python programs). The scientific method (https://en.wikipedia.org/wiki/Scientific_method) is one example of an effective problem solving strategy. Stated as a protocol it goes something like: Observation: Formulation of a question Hypothesis: A conjecture that may explain observed behavior. Falsifiable by an experiment whose outcome conflicts with predictions deduced from the hypothesis Prediction: How the experiment should conclude if hypothesis is correct Testing: Experimental design, and conduct of the experiment. Analysis: Interpretation of experimental results This protocol can be directly adapted to CT/DS problems as: Define the problem (problem statement) Gather information (identify known and unknown values, and governing equations) Generate and evaluate potential solutions Refine and implement a solution Verify and test the solution. For actual computational methods the protocol becomes: Explicitly state the problem State: Input information Governing equations or principles, and The required output information. Work a sample problem by-hand for testing the general solution. Develop a general solution method (coding). Test the general solution against the by-hand example, then apply to the real problem. Oddly enough the first step is the most important and sometimes the most difficult. In a practical problem, step 2 is sometimes difficult because a skilled programmer is needed to translate the governing principles into an algorithm for the general solution (step 4). Example 1 Problem Solving Process Consider a need to compute an arithmetic mean, what would the process look like? Step 1. Develop script to compute the arithmetic mean of a stream of data of unknown length. Step 2. - Inputs: The data stream - Governing equation: \\bar x = \\frac{1}{N} \\sum_{i=1}^{N} x_i where N is the number of items in the data stream, and x_i is the value of the i-th element. - Outputs: The arithmetic mean \\bar x Step 3. Work a sample problem by-hand for testing the general solution. Data 23.43 37.43 34.91 28.37 30.62 The arithmetic mean requires us to count how many elements are in the data stream (in this case there are 5) and compute their sum (in this case 154.76), and finally divide the sum by the count and report this result as the arithmetic mean. \\bar x = \\frac{1}{5}(23.43+37.43+34.91+28.37+30.62)=\\frac{154.76}{5}=30.95 Step 4. Develop a general solution (code) The by-hand exercise helps identify the required steps in an \u201calgorithm\u201d or recipe to compute mean values. First we essentially capture or read the values then count how many there are (either as we go or as a separate step), then sum the values, then divide the values by the count, and finally report the result. In a flow-chart it would look like: Flowchart for Artihmetic Mean Algorithm Step 5. This step we would code the algorithm expressed in the figure and test it with the by-hand data and other small datasets until we are convinced it works correctly. In a simple JupyterLab script # Arithmetic Mean in Very Elementary and Primative Python xlist = [23.43,37.43,34.91,28.37,30.62] # list is a type of data structure howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + xlist[i] print(\"arithmetic mean = \",(accumulator/howlong)) arithmetic mean = 30.951999999999998 Step 6. This step we would refine the code to generalize the algorithm. In the example we want a way to supply the xlist from a file perhaps, and tidy the output by rounding to only two decimal places - rounding is relatively simple: # Arithmetic Mean in Very Elementary and Primative Python xlist = [23.43,37.43,34.91,28.37,30.62] # list is a type of data structure howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + xlist[i] print(\"arithmetic mean = \",round((accumulator/howlong),2)) arithmetic mean = 30.95 Reading from a file, is a bit more complicated. We need to create a connection to the file, then read the contents into our script, then put the contents into the xlist xlist=[] # list (null) is a type of data structure externalfile = open(\"data.txt\",'r') # create connection to file, set to read (r), file must exist how_many_lines = 0 for line in externalfile: # parse each line, append to xlist xlist.append(line) how_many_lines += 1 externalfile.close() # close the file connection howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + float(xlist[i]) print(\"arithmetic mean = \",round((accumulator/howlong),2)) arithmetic mean = 30.95 Finally, if we want to reuse the code a lot, it is convienent to make it into a function def average(inputlist): # inputlist should be a list of values howlong = len(inputlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + float(inputlist[i]) result = (accumulator/howlong) return(result) Put our file reading and compute mean code here xlist=[] # list (null) is a type of data structure externalfile = open(\"data.txt\",'r') # create connection to file, set to read (r), file must exist how_many_lines = 0 for line in externalfile: # parse each line, append to xlist xlist.append(line) how_many_lines += 1 externalfile.close() # close the file connection print(\"arithmetic mean = \",round(average(xlist),2)) arithmetic mean = 30.95 So the simple task of computing the mean of a collection of values, is a bit more complex when decomposed that it first appears, but illustrates a five step process (with a refinement step). Throughout the course this process is always in the background. CCMR Approach A lot of the problems we will encounter from a CT/DS perspective have already been solved, or at least analogs have been solved. It is perfectly acceptable to use prior work for a new set of conditions as long as proper attribution is made. We call this process CCMR: Copy: Find a solution to your problem from some online example: SourceForge, StackOverflow, GeeksForGeeks, DigitalOcean, etc. Cite: Cite the original source. In general a citation will look like one of the references below, but a URL to the source is sufficient at first. Modify: Modify the original cited work for your specific needs. Note the changes in the code using comment statements. Run: Apply the modified code to the problem of interest. In cases where we use CCMR we are not so much programming and developing our own work as scaffolding parts (https://en.wikipedia.org/wiki/Scaffold_(programming)) - a legitimate and valuable engineering activity. Readings Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 1 https://www.inferentialthinking.com/chapters/01/what-is-data-science.html # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /home/sensei/1330-textbook-webroot/docs/lesson0 /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Lesson 0"},{"location":"lesson0/lesson0/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 13 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson0/lesson0/#lesson-0-introduction-to-computational-thinking-with-data-science","text":"Computational thinking concepts Data science and practices JupyterLab (iPython) as a programming environment Programming as a problem solving process CCMR Approach","title":"Lesson 0 Introduction to Computational Thinking with Data Science:"},{"location":"lesson0/lesson0/#special-script-blocks","text":"In the lesson notebooks there will usually be two script blocks, identical to the ones below. The first block identifies the particular computer, the user, and the python kernel in use. The second block sets markdown tables to left edge when rendering. I usually put both blocks at the top of the notebook, just after some kind of title block, as done here.","title":"Special Script Blocks"},{"location":"lesson0/lesson0/#computational-thinking-concepts","text":"Computational thinking (CT) refers to the thought processes involved in expressing solutions as computational steps or algorithms that can be carried out by a computer. Much of what follows is borrowed from (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2696102/). Computational thinking is taking an approach to solving problems, designing systems and understanding human behaviour that draws on concepts fundamental to computing (http://www.cs.cmu.edu/~15110-s13/Wing06-ct.pdf). Computational thinking is a kind of analytical thinking: It shares with mathematical thinking in the general ways in which we might approach solving a problem. It shares with engineering thinking in the general ways in which we might approach designing and evaluating a large, complex system that operates within the constraints of the real world. - It shares with scientific thinking in the general ways in which we might approach understanding computability, intelligence, the mind and human behaviour. The essence of computational thinking is abstraction and automation . In computing, we abstract notions beyond the physical dimensions of time and space. Our abstractions are extremely general because they are symbolic, where numeric abstractions are just a special case.","title":"Computational Thinking Concepts"},{"location":"lesson0/lesson0/#ct-foundations","text":"CT is literally a process for breaking down a problem into smaller parts, looking for patterns in the problems, identifying what kind of information is needed, developing a step-by-step solution, and implementing that solution. Decomposition Pattern Recognition Abstraction Algorithms System Integration (implementation)","title":"CT Foundations"},{"location":"lesson0/lesson0/#decomposition","text":"Decomposition is the process of taking a complex problem and breaking it into more manageable sub-problems. Examples include: - Writing a paper: - Introduction - Body - Conclusion Wide-viewed (Panorama) image: Taking multiple overlapped photos Stitch them Decomposition often leaves a framework of sub-problems that later have to be assembled (system integration) to produce a desired solution.","title":"Decomposition"},{"location":"lesson0/lesson0/#pattern-recognition","text":"Refers to finding similarities, or shared characteristics of problems. Allows a complex problem to become easier to solve. Allows use of same solution method for each occurrence of the pattern. Pattern recognition allows use of automation to process things - its a fundamental drilled shaft of CT. It also provides a way to use analogs from old problems to address new situations; it also will require assembly (system integration) to produce a desired solution.","title":"Pattern Recognition"},{"location":"lesson0/lesson0/#abstraction","text":"Determine important characteristics of the problem and ignore characteristics that are not important. Use these characteristics to create a representation of what we are trying to solve. Books in an online bookstore Important NOT important title Cover color ISBN Author\u2019s hometown Authors ... ... ...","title":"Abstraction"},{"location":"lesson0/lesson0/#algorithms","text":"Step-by-step instructions of how to solve a problem (https://en.wikipedia.org/wiki/Algorithm). Identifies what is to be done, and the order in which they should be done. Image from https://www.newyorker.com/magazine/2021/01/18/whats-wrong-with-the-way-we-work?utm_source=pocket-newtab An algorithm is a finite sequence of defined, instructions, typically to solve a class of problems or to perform a computation. Algorithms are unambiguous and are used as specifications for performing calculations, data processing, automated reasoning, and other tasks. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, can incorporate random input.","title":"Algorithms"},{"location":"lesson0/lesson0/#system-integration-implementation","text":"System integration is the assembly of the parts above into the complete (integrated) solution. Integration combines parts into a program which is the realization of an algorithm using a syntax that the computer can understand.","title":"System Integration (implementation)"},{"location":"lesson0/lesson0/#data-science-and-practice","text":"Data science is leveraging existing data sources, to create new ones as needed in order to extract meaningful information and actionable insights through business domain expertise, effective communication and results interpretation. Data science uses relevant statistical techniques, programming languages, software packages and libraries, and data infrastructure; The insights are used to drive business decisions and take actions intended to achieve business goals. Why is this important for engineers? Because engineering is a business! A list of typical skills (https://elitedatascience.com/data-science-resources): Foundational Skills Programming and Data Manipulation Statistics and Probability Technical Skills Data Collection SQL Data Visualization Applied Machine Learning Business Skills Communication Creativity and Innovation Operations and Strategy Business Analytics Supplementary Skills Natural Language Processing Recommendation Systems Time Series Analysis Practice Projects Competitions Problem Solving Challenges","title":"Data Science and Practice"},{"location":"lesson0/lesson0/#jupyterlab-ipython-environment","text":"","title":"JupyterLab (iPython) Environment"},{"location":"lesson0/lesson0/#the-tools","text":"JupyterLab (https://jupyter.org/) is a web-based interactive development environment for Jupyter notebooks, code, and data. Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data organizing and transformation, numerical simulation, statistical modeling, visualization, machine learning, and other similar types of uses. JupyterHub (https://github.com/jupyterhub/jupyterhub) is a multi-user Hub that spawns, manages, and proxies multiple instances of the single-user Jupyter notebook server. All these tools allow use of various coding languages; Python is the choice for ENGR 1330. Installing JupyterLab on your own computer is relatively straightforward if it is an Intel-based Linux, Macintosh, or Windows machine - simply use Anaconda (https://www.anaconda.com/) as the installer. Installing onto an ARM-based machine is more difficult, but possible (this notebook was created on a Raspberry Pi). With both Apple and Microsoft abandoning Intel you can expect Anaconda builds for aarch64 (ARM) in the future.","title":"The tools:"},{"location":"lesson0/lesson0/#this-course","text":"You will create and use Jupyter Notebooks that use the ipython kernel, the notebook files will look like filename.ipynb ; these are ASCII files that the JupyterLab interprets and runs.","title":"This course:"},{"location":"lesson0/lesson0/#python","text":"The programming language we will use is Python (actually iPython). Python is an example of a high-level language; other high-level languages include C, C++, PHP, FORTRAN, ADA, Pascal, Go, Java, etc (there are a lot). As you might infer from the name high-level language, there are also low-level languages, sometimes referred to as machine languages or assembly languages. Machine language is the encoding of instructions in binary so that they can be directly executed by the computer. Assembly language uses a slightly easier format to refer to the low level instructions. Loosely speaking, computers can only execute programs written in low-level languages. To be exact, computers can actually only execute programs written in machine language. Thus, programs written in a high-level language (and even those in assembly language) have to be processed before they can run. This extra processing takes some time, which is a small disadvantage of high-level languages. However, the advantages to high-level languages are enormous. First, it is much easier to program in a high-level language. Programs written in a high-level language take less time to write, they are shorter and easier to read, and they are more likely to be correct. Second, high-level languages are portable, meaning that they can run on different kinds of computers with few or no modifications. Low-level programs can run on only one kind of computer and have to be rewritten to run on another. Due to these advantages, almost all programs are written in high-level languages. Low-level languages are used only for a few specialized applications, and for device drivers. Two kinds of programs process high-level languages into low-level languages: interpreters and compilers. An interpreter reads a high-level program and executes it, meaning that it does what the program says. It processes the program a little at a time, alternately reading lines and performing computations. Interpreted Program. Image from (https://runestone.academy/runestone/books/published/thinkcspy/GeneralIntro/ThePythonProgrammingLanguage.html) A compiler reads the program and translates it completely before the program starts running. In this case, the high-level program is called the source code, and the translated program is called the object code or the executable. Once a program is compiled, you can execute it repeatedly without further translation. Compiled Prorgam. Image from: (https://runestone.academy/runestone/books/published/thinkcspy/GeneralIntro/ThePythonProgrammingLanguage.html) Many modern languages use both processes. They are first compiled into a lower level language, called byte code, and then interpreted by a program called a virtual machine. Python uses both processes, but because of the way programmers interact with it, it is usually considered an interpreted language. As a language, python is a formal language that has certain requirements and structure called \"syntax.\" Formal languages are languages that are designed by people for specific applications. For example, the notation that mathematicians use is a formal language that is particularly good at denoting relationships among numbers and symbols. Chemists use a formal language to represent the chemical structure of molecules. Programming languages are formal languages that have been designed to express computations. Formal languages have strict rules about syntax. For example, 3+3=6 is a syntactically correct mathematical statement, but 3=+6& is not. Syntax rules come in two flavors, pertaining to tokens and structure . Tokens are the basic elements of the language, such as words, numbers, and chemical elements. One of the problems with 3=+6& is that & is not a legal token in mathematics (at least as far as we know). The second type of syntax rule pertains to the structure of a statement\u2014 that is, the way the tokens are arranged. The statement 3=+6& is structurally illegal (in mathematics) because you don\u2019t place a plus sign immediately after an equal sign (of course we will in python!). When you read a sentence in English or a statement in a formal language, you have to figure out what the structure of the sentence is; This process is called parsing . For example, when you hear the sentence, \u201cThe other shoe fell\u201d, you understand that the other shoe is the subject and fell is the verb. Once you have parsed a sentence, you can figure out what it means, or the semantics of the sentence. Assuming that you know what a shoe is and what it means to fall, you will understand the general implication of this sentence.","title":"Python"},{"location":"lesson0/lesson0/#good-resources","text":"Learn Python the Hard Way (Online Book) (https://learnpythonthehardway.org/book/) Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) (https://www.learnpython.org/) Short, interactive tutorial for those who just need a quick way to pick up Python syntax. How to Think Like a Computer Scientist (Interactive Book) (https://runestone.academy/runestone/books/published/thinkcspy/index.html) Interactive \"CS 101\" course taught in Python that really focuses on the art of problem solving. How to Learn Python for Data Science, The Self-Starter Way (https://elitedatascience.com/learn-python-for-data-science)","title":"Good Resources:"},{"location":"lesson0/lesson0/#programming-as-a-problem-solving-process","text":"The entire point of this course is to develop problem solving skills and begin using some tools (Statistics, Numerical Methods, Data Science, implemented as JupyterLab/Python programs). The scientific method (https://en.wikipedia.org/wiki/Scientific_method) is one example of an effective problem solving strategy. Stated as a protocol it goes something like: Observation: Formulation of a question Hypothesis: A conjecture that may explain observed behavior. Falsifiable by an experiment whose outcome conflicts with predictions deduced from the hypothesis Prediction: How the experiment should conclude if hypothesis is correct Testing: Experimental design, and conduct of the experiment. Analysis: Interpretation of experimental results This protocol can be directly adapted to CT/DS problems as: Define the problem (problem statement) Gather information (identify known and unknown values, and governing equations) Generate and evaluate potential solutions Refine and implement a solution Verify and test the solution. For actual computational methods the protocol becomes: Explicitly state the problem State: Input information Governing equations or principles, and The required output information. Work a sample problem by-hand for testing the general solution. Develop a general solution method (coding). Test the general solution against the by-hand example, then apply to the real problem. Oddly enough the first step is the most important and sometimes the most difficult. In a practical problem, step 2 is sometimes difficult because a skilled programmer is needed to translate the governing principles into an algorithm for the general solution (step 4).","title":"Programming as a problem solving process"},{"location":"lesson0/lesson0/#example-1-problem-solving-process","text":"Consider a need to compute an arithmetic mean, what would the process look like? Step 1. Develop script to compute the arithmetic mean of a stream of data of unknown length. Step 2. - Inputs: The data stream - Governing equation: \\bar x = \\frac{1}{N} \\sum_{i=1}^{N} x_i where N is the number of items in the data stream, and x_i is the value of the i-th element. - Outputs: The arithmetic mean \\bar x Step 3. Work a sample problem by-hand for testing the general solution. Data 23.43 37.43 34.91 28.37 30.62 The arithmetic mean requires us to count how many elements are in the data stream (in this case there are 5) and compute their sum (in this case 154.76), and finally divide the sum by the count and report this result as the arithmetic mean. \\bar x = \\frac{1}{5}(23.43+37.43+34.91+28.37+30.62)=\\frac{154.76}{5}=30.95 Step 4. Develop a general solution (code) The by-hand exercise helps identify the required steps in an \u201calgorithm\u201d or recipe to compute mean values. First we essentially capture or read the values then count how many there are (either as we go or as a separate step), then sum the values, then divide the values by the count, and finally report the result. In a flow-chart it would look like: Flowchart for Artihmetic Mean Algorithm Step 5. This step we would code the algorithm expressed in the figure and test it with the by-hand data and other small datasets until we are convinced it works correctly. In a simple JupyterLab script # Arithmetic Mean in Very Elementary and Primative Python xlist = [23.43,37.43,34.91,28.37,30.62] # list is a type of data structure howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + xlist[i] print(\"arithmetic mean = \",(accumulator/howlong)) arithmetic mean = 30.951999999999998 Step 6. This step we would refine the code to generalize the algorithm. In the example we want a way to supply the xlist from a file perhaps, and tidy the output by rounding to only two decimal places - rounding is relatively simple: # Arithmetic Mean in Very Elementary and Primative Python xlist = [23.43,37.43,34.91,28.37,30.62] # list is a type of data structure howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + xlist[i] print(\"arithmetic mean = \",round((accumulator/howlong),2)) arithmetic mean = 30.95 Reading from a file, is a bit more complicated. We need to create a connection to the file, then read the contents into our script, then put the contents into the xlist xlist=[] # list (null) is a type of data structure externalfile = open(\"data.txt\",'r') # create connection to file, set to read (r), file must exist how_many_lines = 0 for line in externalfile: # parse each line, append to xlist xlist.append(line) how_many_lines += 1 externalfile.close() # close the file connection howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + float(xlist[i]) print(\"arithmetic mean = \",round((accumulator/howlong),2)) arithmetic mean = 30.95 Finally, if we want to reuse the code a lot, it is convienent to make it into a function def average(inputlist): # inputlist should be a list of values howlong = len(inputlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + float(inputlist[i]) result = (accumulator/howlong) return(result) Put our file reading and compute mean code here xlist=[] # list (null) is a type of data structure externalfile = open(\"data.txt\",'r') # create connection to file, set to read (r), file must exist how_many_lines = 0 for line in externalfile: # parse each line, append to xlist xlist.append(line) how_many_lines += 1 externalfile.close() # close the file connection print(\"arithmetic mean = \",round(average(xlist),2)) arithmetic mean = 30.95 So the simple task of computing the mean of a collection of values, is a bit more complex when decomposed that it first appears, but illustrates a five step process (with a refinement step). Throughout the course this process is always in the background.","title":"Example 1 Problem Solving Process"},{"location":"lesson0/lesson0/#ccmr-approach","text":"A lot of the problems we will encounter from a CT/DS perspective have already been solved, or at least analogs have been solved. It is perfectly acceptable to use prior work for a new set of conditions as long as proper attribution is made. We call this process CCMR: Copy: Find a solution to your problem from some online example: SourceForge, StackOverflow, GeeksForGeeks, DigitalOcean, etc. Cite: Cite the original source. In general a citation will look like one of the references below, but a URL to the source is sufficient at first. Modify: Modify the original cited work for your specific needs. Note the changes in the code using comment statements. Run: Apply the modified code to the problem of interest. In cases where we use CCMR we are not so much programming and developing our own work as scaffolding parts (https://en.wikipedia.org/wiki/Scaffold_(programming)) - a legitimate and valuable engineering activity.","title":"CCMR Approach"},{"location":"lesson0/lesson0/#readings","text":"Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 1 https://www.inferentialthinking.com/chapters/01/what-is-data-science.html # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /home/sensei/1330-textbook-webroot/docs/lesson0 /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Readings"},{"location":"lesson1/lesson1/","text":"table {margin-left: 0 !important;} ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 19 January 2021 Lesson 1 Programming Fundamentals: iPython, tokens, and structure Data types (int, float, string, bool) Variables, operators, expressions, basic I/O String functions and operations Programming Fundamentals Computational thinking (CT) refers to the thought processes involved in expressing solutions as computational steps or algorithms that can be carried out by a computer. CT is a process for breaking down a problem into smaller parts, looking for patterns in the problems, identifying what kind of information is needed, developing a step-by-step solution, and implementing that solution. Recall the 5 fundamental CT concepts are: Decomposition: the process of taking a complex problem and breaking it into more manageable sub-problems. Decomposition often leaves a framework of sub-problems that later have to be assembled (system integration) to produce a desired solution. Pattern Recognition: finding similarities, or shared characteristics of problems. Allows a complex problem to become easier to solve. Allows use of same solution method ( automation ) for each occurrence of the pattern. Abstraction : Determine important characteristics of the problem and use these characteristics to create a representation of the problem. Algorithms : Step-by-step instructions of how to solve a problem (https://en.wikipedia.org/wiki/Algorithm). Identifies what is to be done, and the order in which they should be done. System Integration: the assembly of the parts above into the complete (integrated) solution. Integration combines parts into a program which is the realization of an algorithm using a syntax that the computer can understand. Programming is (generally) writing code in a specific programming language to address a certain problem. In the above list it is largely contained within the algorithms concept. iPython The programming language we will use is Python (actually iPython). Python is an example of a high-level language; there are also low-level languages, sometimes referred to as machine languages or assembly languages. Machine language is the encoding of instructions in binary so that they can be directly executed by the computer. Assembly language uses a slightly easier format to refer to the low level instructions. Loosely speaking, computers can only execute programs written in low-level languages. To be exact, computers can actually only execute programs written in machine language. Thus, programs written in a high-level language (and even those in assembly language) have to be processed before they can run. This extra processing takes some time, which is a small disadvantage of high-level languages. However, the advantages to high-level languages are enormous: First, it is much easier to program in a high-level language. Programs written in a high-level language take less time to write, they are shorter and easier to read, and they are more likely to be correct. Second, high-level languages are portable, meaning that they can run on different kinds of computers with just a few modifications. Low-level programs can run on only one kind of computer (chipset-specific for sure, in some cases hardware specific) and have to be rewritten to run on other processors. (e.g. x86-64 vs. arm7 vs. aarch64 vs. PowerPC ...) Due to these advantages, almost all programs are written in high-level languages. Low-level languages are used only for a few specialized applications. Two kinds of programs process high-level languages into low-level languages: interpreters and compilers. An interpreter reads a high-level program and executes it, meaning that it does what the program says. It processes the program a little at a time, alternately reading lines and performing computations. As a language, python is a formal language that has certain requirements and structure called \"syntax.\" Syntax rules come in two flavors, pertaining to tokens and structure . Tokens are the basic elements of the language, such as words, numbers, and chemical elements. The second type of syntax rule pertains to the structure of a statement specifically in the way the tokens are arranged. Tokens and Structure Consider the relativistic equation relating energy, mass, and the speed of light e = m \\cdot c^2 In this equation the tokens are e , m , c , = , \\cdot , and the structure is parsed from left to right as into the token named e place the result of the product of the contents of the tokens m and c^2 . Given that the speed of light is some universal constant, the only things that can change are the contents of m and the resulting change in e . In the above discourse, the tokens e , m , c are names for things that can have values -- we will call these variables (or constants as appropriate). The tokens = , \\cdot , and ~^2 are symbols for various arithmetic operations -- we will call these operators. The structure of the equation is specific -- we will call it a statement. When we attempt to write and execute python scripts - we will make various mistakes; these will generate warnings and errors, which we will repair to make a working program. Consider our equation: #clear all variables# Example Energy = Mass * SpeedOfLight**2 --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-4-1c1f1fa5363a> in <module> 1 #clear all variables# Example ----> 2 Energy = Mass * SpeedOfLight**2 NameError: name 'Mass' is not defined Notice how the interpreter tells us that Mass is undefined - so a simple fix is to define it and try again # Example Mass = 1000000 Energy = Mass * SpeedOfLight**2 --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-5-a4a52966e6df> in <module> 1 # Example 2 Mass = 1000000 ----> 3 Energy = Mass * SpeedOfLight**2 NameError: name 'SpeedOfLight' is not defined Notice how the interpreter now tells us that SpeedOfLight is undefined - so a simple fix is to define it and try again # Example Mass = 1000000 #kilograms SpeedOfLight = 299792458 #meters per second Energy = Mass * SpeedOfLight**2 Now the script ran without any reported errors, but we have not instructed the program on how to produce output. To keep the example simple we will just add a generic print statement. # Example Mass = 1000000 #kilograms SpeedOfLight = 299792458 #meters per second Energy = Mass * SpeedOfLight**2 print(\"Energy is:\", Energy, \"Newton meters\") Energy is: 89875517873681764000000 Newton meters Now lets examine our program. Identify the tokens that have values, Identify the tokens that are symbols of operations, identify the structure. Variables Variables are names given to data that we want to store and manipulate in programs. A variable has a name and a value. The value representation depends on what type of object the variable represents. The utility of variables comes in when we have a structure that is universal, but values of variables within the structure will change - otherwise it would be simple enough to just hardwire the arithmetic. Suppose we want to store the time of concentration for some hydrologic calculation. To do so, we can name a variable TimeOfConcentration , and then assign a value to the variable, for instance: TimeOfConcentration = 0.0 After this assignment statement the variable is created in the program and has a value of 0.0. The use of a decimal point in the initial assignment establishes the variable as a float (a real variable is called a floating point representation -- or just a float). Naming Rules Variable names in Python can only contain letters (a - z, A - Z), numerals (0 - 9), or underscores. The first character cannot be a number, otherwise there is considerable freedom in naming. The names can be reasonably long. runTime , run_Time , _run_Time2 , _2runTime are all valid names, but 2runTime is not valid, and will create an error when you try to use it. # Script to illustrate variable names runTime = 1 _2runTime = 2 # change to 2runTime = 2 and rerun script runTime2 = 2 print(runTime,_2runTime,runTime2) 1 2 2 There are some reserved words that cannot be used as variable names because they have preassigned meaning in Parseltongue. These words include print , input , if , while , and for . There are several more; the interpreter won't allow you to use these names as variables and will issue an error message when you attempt to run a program with such words used as variables. Operators The = sign used in the variable definition is called an assignment operator (or assignment sign). The symbol means that the expression to the right of the symbol is to be evaluated and the result placed into the variable on the left side of the symbol. The \"operation\" is assignment, the \"=\" symbol is the operator name. Consider the script below # Assignment Operator x = 5 y = 10 print (x,y) x=y # reverse order y=x and re-run, what happens? print (x,y) 5 10 10 10 So look at what happened. When we assigned values to the variables named x and y , they started life as 5 and 10. We then wrote those values to the console, and the program returned 5 and 10. Then we assigned y to x which took the value in y and replaced the value that was in x with this value. We then wrote the contents again, and both variables have the value 10. Arithmetic Operators In addition to assignment we can also perform arithmetic operations on variables. The fundamental arithmetic operators are: Symbol Meaning Example = Assignment x=3 Assigns value of 3 to x. + Addition x+y Adds values in x and y. - Subtraction x-y Subtracts values in y from x. * Multiplication x*y Multiplies values in x and y. / Division x/y Divides value in x by value in y. // Floor division x//y Divide x by y, truncate result to whole number. % Modulus x%y Returns remainder when x is divided by y. ** Exponentation x y Raises value in x by value in y. ( e.g. x y) += Additive assignment x+=2 Equivalent to x = x+2. -= Subtractive assignment x-=2 Equivalent to x = x-2. *= Multiplicative assignment x*=3 Equivalent to x = x*3. /= Divide assignment x/3 Equivalent to x = x/3. Run the script in the next cell for some illustrative results # Uniary Arithmetic Operators x = 10 y = 5 print(x, y) print(x+y) print(x-y) print(x*y) print(x/y) print((x+1)//y) print((x+1)%y) print(x**y) 10 5 15 5 50 2.0 2 1 100000 # Arithmetic assignment operators x = 1 x += 2 print(type(x),x) x = 1 x -= 2 print(type(x),x) x = 1 x *=3 print(type(x),x) x = 10 x /= 2 print(type(x),x) # Interesting what division does to variable type <class 'int'> 3 <class 'int'> -1 <class 'int'> 3 <class 'float'> 5.0 Data Type In the computer data are all binary digits (actually 0 and +5 volts). At a higher level of abstraction data are typed into integers, real, or alphanumeric representation. The type affects the kind of arithmetic operations that are allowed (as well as the kind of arithmetic - integer versus real arithmetic; lexicographical ordering of alphanumeric , etc.) In scientific programming, a common (and really difficult to detect) source of slight inaccuracies (that tend to snowball as the program runs) is mixed mode arithmetic required because two numeric values are of different types (integer and real). Learn more from the textbook https://www.inferentialthinking.com/chapters/04/Data_Types.html Here we present a quick summary Integer Integers are numbers without any fractional portion (nothing after the decimal point { which is not used in integers). Numbers like -3, -2, -1, 0, 1, 2, 200 are integers. A number like 1.1 is not an integer, and 1.0 is also not an integer (the presence of the decimal point makes the number a real). To declare an integer in Python, just assign the variable name to an integer for example MyPhoneNumber = 14158576309 Real (Float) A real or float is a number that has (or can have) a fractional portion - the number has decimal parts. The numbers 3.14159, -0.001, 11.11, 1., are all floats. The last one is especially tricky, if you don't notice the decimal point you might think it is an integer but the inclusion of the decimal point in Python tells the program that the value is to be treated as a float. To declare a float in Python, just assign the variable name to a float for example MyMassInKilos = 74.8427 String(Alphanumeric) A string is a data type that is treated as text elements. The usual letters are strings, but numbers can be included. The numbers in a string are simply characters and cannot be directly used in arithmetic. There are some kinds of arithmetic that can be performed on strings but generally we process string variables to capture the text nature of their contents. To declare a string in Python, just assign the variable name to a string value - the trick is the value is enclosed in quotes. The quotes are delimiters that tell the program that the characters between the quotes are characters and are to be treated as literal representation. For example MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" are all string variables. The last assignment is made a string on purpose. String variables can be combined using an operation called concatenation. The symbol for concatenation is the plus symbol + . Strings can also be converted to all upper case using the upper() function. The syntax for the upper() function is 'string to be upper case'.upper() . Notice the \"dot\" in the syntax. The operation passes everything to the left of the dot to the function which then operates on that content and returns the result all upper case (or an error if the input stream is not a string). # Variable Types Example MyPhoneNumber = 14158576309 MyMassInKilos = 74.8427 MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" print(\"All about me\") print(\"Name: \",MyName, \" Mass :\",MyMassInKilos,\"Kg\" ) print('Phone : ',MyPhoneNumber) print('My cat\\'s name :', MyCatName) # the \\ escape character is used to get the ' into the literal print(\"All about concatenation!\") print(\"A Silly String : \",MyCatName+MyName+DustyMassInKilos) print(\"A SILLY STRING : \", (MyCatName+MyName+DustyMassInKilos).upper()) All about me Name: Theodore Mass : 74.8427 Kg Phone : 14158576309 My cat's name : Dusty All about concatenation! A Silly String : DustyTheodore7.48427 A SILLY STRING : DUSTYTHEODORE7.48427 Strings can be formatted using the % operator or the format() function. The concepts will be introduced later on as needed in the workbook, you can Google search for examples of how to do such formatting. Changing Types A variable type can be changed. This activity is called type casting. Three functions allow type casting: int() , float() , and str() . The function names indicate the result of using the function, hence int() returns an integer, float() returns a oat, and str() returns a string. There is also the useful function type() which returns the type of variable. The easiest way to understand is to see an example. # Type Casting Examples MyInteger = 234 MyFloat = 876.543 MyString = 'What is your name?' print(MyInteger,MyFloat,MyString) print('Integer as float',float(MyInteger)) print('Float as integer',int(MyFloat)) print('Integer as string',str(MyInteger)) print('Integer as hexadecimal',hex(MyInteger)) print('Integer Type',type((MyInteger))) # insert the hex conversion and see what happens! 234 876.543 What is your name? Integer as float 234.0 Float as integer 876 Integer as string 234 Integer as hexadecimal 0xea Integer Type <class 'int'> Expressions Expressions are the \"algebraic\" constructions that are evaluated and then placed into a variable. Consider x1 = 7 + 3 * 6 / 2 - 1 The expression is evaluated from the left to right and in words is Into the object named x1 place the result of: integer 7 + (integer 6 divide by integer 2 = float 3 * integer 3 = float 9 - integer 1 = float 8) = float 15 The division operation by default produces a float result unless forced otherwise. The result is the variable x1 is a float with a value of 15.0 # Expressions Example x1 = 7 + 3 * 6 // 2 - 1 # Change / into // and see what happens! print(type(x1),x1) ## Simple I/O (Input/Output) <class 'int'> 15 Summary So far consider our story - a tool to help with problem solving is CT leading to an algorithm. The tool to implement the algorithm is the program and in our case JupyterLab running iPython interpreter for us. As a formal language we introduced: - tokens - structure From these two constructs we further introduced variables (a kind of token), data types (an abstraction, and arguably a decomposition), and expressions (a structure). We created simple scripts (with errors), examined the errors, corrected our script, and eventually got an answer. So we are well on our way in CT as it applies in Engineering. Programming as a problem solving process Recall the entire point of this course is to develop problem solving skills and begin using some tools (Statistics, Numerical Methods, Data Science, implemented as JupyterLab/Python programs). Recall our suggested problem solving protocol: Explicitly state the problem State: Input information Governing equations or principles, and The required output information. Work a sample problem by-hand for testing the general solution. Develop a general solution method (coding). Test the general solution against the by-hand example, then apply to the real problem. Refine general solution for deployment (frequent use) Another protocol with the same goal is at https://3.137.111.182/engr-1330-webroot/1-Lessons/Lesson02/OriginalPowerpoint/HowToBuildAProgram.html Notice the similarity! Example 2 Problem Solving Process Consider an engineering material problem where we wish to classify whether a material in loaded in the elastic or inelastic region as determined the stress (solid pressure) in a rod for some applied load. The yield stress is the classifier, and once the material yields (begins to fail) it will not carry any additional load (until ultimate failure, when it carries no load). Step 1. Compute the material stress under an applied load; determine if value exceedes yield stress, and report the loading condition Step 2. - Inputs: applied load, cross sectional area, yield stress - Governing equation: \\sigma = \\frac{P}{A} when \\frac{P}{A} is less than the yield stress, and is equal to the yield stress otherwise. - Outputs: The material stress \\sigma , and the classification elastic or inelastic. Step 3. Work a sample problem by-hand for testing the general solution. Assuming the yield stress is 1 million psi (units matter in an actual problem - kind of glossed over here) Applied Load (lbf) Cross Section Area (sq.in.) Stress (psi) Classification 10,000 1.0 10,000 Elastic 10,000 0.1 100,000 Elastic 100,000 0.1 1,000,000 Inelastic The stress requires us to read in the load value, read in the cross sectional area, divide the load by the area, and compare the result to the yield stress. If it exceeds the yield stress, then the actual stress is the yield stress, and the loading is inelastic, otherwise elastic \\sigma = \\frac{P}{A} If \\sigma >= \\text{Yield Stress Report Inelastic} Step 4. Develop a general solution (code) In a flow-chart it would look like: Flowchart for Artihmetic Mean Algorithm Step 5. This step we would code the algorithm expressed in the figure and test it with the by-hand data and other small datasets until we are convinced it works correctly. We have not yet learned prompts to get input we simply direct assign values as below (and the conditional execution is the subject of a later lesson) In a simple JupyterLab script # Example 2 Problem Solving Process yield_stress = 1e6 applied_load = 1e5 cross_section = 0.1 computed_stress = applied_load/cross_section if(computed_stress < yield_stress): print(\"Elastic Region: Stress = \",computed_stress) elif(computed_stress >= yield_stress): print(\"Inelastic Region: Stress = \",yield_stress) Inelastic Region: Stress = 1000000.0 Step 6. This step we would refine the code to generalize the algorithm. In the example we want a way to supply the inputs by user entry,and tidy the output by rounding to only two decimal places. A little CCMR from https://www.geeksforgeeks.org/taking-input-in-python/ gives us a way to deal with the inputs and typecasting. Some more CCMR from https://www.programiz.com/python-programming/methods/built-in/round gets us rounded out! # Example 2 Problem Solving Process yield_stress = float(input('Yield Stress (psi)')) applied_load = float(input('Applied Load (lbf)')) cross_section = float(input('Cross Section Area (sq.in.)')) computed_stress = applied_load/cross_section if(computed_stress < yield_stress): print(\"Elastic Region: Stress = \",round(computed_stress,2)) elif(computed_stress >= yield_stress): print(\"Inelastic Region: Stress = \",round(yield_stress,2)) Yield Stress (psi) 1000000 Applied Load (lbf) 100000 Cross Section Area (sq.in.) 1 Elastic Region: Stress = 100000.0 So the simple task of computing the stress, is a bit more complex when decomposed, that it first appears, but illustrates a five step process (with a refinement step). CCMR Approach A lot of the problems we will encounter from a CT/DS perspective have already been solved, or at least analogs have been solved. It is perfectly acceptable to use prior work for a new set of conditions as long as proper attribution is made. We call this process CCMR: Copy: Find a solution to your problem from some online example: SourceForge, StackOverflow, GeeksForGeeks, DigitalOcean, etc. Cite: Cite the original source. In general a citation will look like one of the references below, but a URL to the source is sufficient at first. Modify: Modify the original cited work for your specific needs. Note the changes in the code using comment statements. Run: Apply the modified code to the problem of interest. In cases where we use CCMR we are not so much programming and developing our own work as scaffolding parts (https://en.wikipedia.org/wiki/Scaffold_(programming)) - a legitimate and valuable engineering activity. Readings Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 3 https://www.inferentialthinking.com/chapters/03/programming-in-python.html Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 https://www.inferentialthinking.com/chapters/04/Data_Types.html Learn Python in One Day and Learn It Well. Python for Beginners with Hands-on Project. (Learn Coding Fast with Hands-On Project Book -- Kindle Edition by LCF Publishing (Author), Jamie Chan https://www.amazon.com/Python-2nd-Beginners-Hands-Project-ebook/dp/B071Z2Q6TQ/ref=sr_1_3?dchild=1&keywords=learn+python+in+a+day&qid=1611108340&sr=8-3 Learn Python the Hard Way (Online Book) (https://learnpythonthehardway.org/book/) Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) (https://www.learnpython.org/) Short, interactive tutorial for those who just need a quick way to pick up Python syntax. How to Think Like a Computer Scientist (Interactive Book) (https://runestone.academy/runestone/books/published/thinkcspy/index.html) Interactive \"CS 101\" course taught in Python that really focuses on the art of problem solving. How to Learn Python for Data Science, The Self-Starter Way (https://elitedatascience.com/learn-python-for-data-science) # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson02/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Lesson 1"},{"location":"lesson1/lesson1/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 19 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson1/lesson1/#lesson-1-programming-fundamentals","text":"iPython, tokens, and structure Data types (int, float, string, bool) Variables, operators, expressions, basic I/O String functions and operations","title":"Lesson 1 Programming Fundamentals:"},{"location":"lesson1/lesson1/#programming-fundamentals","text":"Computational thinking (CT) refers to the thought processes involved in expressing solutions as computational steps or algorithms that can be carried out by a computer. CT is a process for breaking down a problem into smaller parts, looking for patterns in the problems, identifying what kind of information is needed, developing a step-by-step solution, and implementing that solution. Recall the 5 fundamental CT concepts are: Decomposition: the process of taking a complex problem and breaking it into more manageable sub-problems. Decomposition often leaves a framework of sub-problems that later have to be assembled (system integration) to produce a desired solution. Pattern Recognition: finding similarities, or shared characteristics of problems. Allows a complex problem to become easier to solve. Allows use of same solution method ( automation ) for each occurrence of the pattern. Abstraction : Determine important characteristics of the problem and use these characteristics to create a representation of the problem. Algorithms : Step-by-step instructions of how to solve a problem (https://en.wikipedia.org/wiki/Algorithm). Identifies what is to be done, and the order in which they should be done. System Integration: the assembly of the parts above into the complete (integrated) solution. Integration combines parts into a program which is the realization of an algorithm using a syntax that the computer can understand. Programming is (generally) writing code in a specific programming language to address a certain problem. In the above list it is largely contained within the algorithms concept.","title":"Programming Fundamentals"},{"location":"lesson1/lesson1/#ipython","text":"The programming language we will use is Python (actually iPython). Python is an example of a high-level language; there are also low-level languages, sometimes referred to as machine languages or assembly languages. Machine language is the encoding of instructions in binary so that they can be directly executed by the computer. Assembly language uses a slightly easier format to refer to the low level instructions. Loosely speaking, computers can only execute programs written in low-level languages. To be exact, computers can actually only execute programs written in machine language. Thus, programs written in a high-level language (and even those in assembly language) have to be processed before they can run. This extra processing takes some time, which is a small disadvantage of high-level languages. However, the advantages to high-level languages are enormous: First, it is much easier to program in a high-level language. Programs written in a high-level language take less time to write, they are shorter and easier to read, and they are more likely to be correct. Second, high-level languages are portable, meaning that they can run on different kinds of computers with just a few modifications. Low-level programs can run on only one kind of computer (chipset-specific for sure, in some cases hardware specific) and have to be rewritten to run on other processors. (e.g. x86-64 vs. arm7 vs. aarch64 vs. PowerPC ...) Due to these advantages, almost all programs are written in high-level languages. Low-level languages are used only for a few specialized applications. Two kinds of programs process high-level languages into low-level languages: interpreters and compilers. An interpreter reads a high-level program and executes it, meaning that it does what the program says. It processes the program a little at a time, alternately reading lines and performing computations. As a language, python is a formal language that has certain requirements and structure called \"syntax.\" Syntax rules come in two flavors, pertaining to tokens and structure . Tokens are the basic elements of the language, such as words, numbers, and chemical elements. The second type of syntax rule pertains to the structure of a statement specifically in the way the tokens are arranged.","title":"iPython"},{"location":"lesson1/lesson1/#tokens-and-structure","text":"Consider the relativistic equation relating energy, mass, and the speed of light e = m \\cdot c^2 In this equation the tokens are e , m , c , = , \\cdot , and the structure is parsed from left to right as into the token named e place the result of the product of the contents of the tokens m and c^2 . Given that the speed of light is some universal constant, the only things that can change are the contents of m and the resulting change in e . In the above discourse, the tokens e , m , c are names for things that can have values -- we will call these variables (or constants as appropriate). The tokens = , \\cdot , and ~^2 are symbols for various arithmetic operations -- we will call these operators. The structure of the equation is specific -- we will call it a statement. When we attempt to write and execute python scripts - we will make various mistakes; these will generate warnings and errors, which we will repair to make a working program. Consider our equation: #clear all variables# Example Energy = Mass * SpeedOfLight**2 --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-4-1c1f1fa5363a> in <module> 1 #clear all variables# Example ----> 2 Energy = Mass * SpeedOfLight**2 NameError: name 'Mass' is not defined Notice how the interpreter tells us that Mass is undefined - so a simple fix is to define it and try again # Example Mass = 1000000 Energy = Mass * SpeedOfLight**2 --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-5-a4a52966e6df> in <module> 1 # Example 2 Mass = 1000000 ----> 3 Energy = Mass * SpeedOfLight**2 NameError: name 'SpeedOfLight' is not defined Notice how the interpreter now tells us that SpeedOfLight is undefined - so a simple fix is to define it and try again # Example Mass = 1000000 #kilograms SpeedOfLight = 299792458 #meters per second Energy = Mass * SpeedOfLight**2 Now the script ran without any reported errors, but we have not instructed the program on how to produce output. To keep the example simple we will just add a generic print statement. # Example Mass = 1000000 #kilograms SpeedOfLight = 299792458 #meters per second Energy = Mass * SpeedOfLight**2 print(\"Energy is:\", Energy, \"Newton meters\") Energy is: 89875517873681764000000 Newton meters Now lets examine our program. Identify the tokens that have values, Identify the tokens that are symbols of operations, identify the structure.","title":"Tokens and Structure"},{"location":"lesson1/lesson1/#variables","text":"Variables are names given to data that we want to store and manipulate in programs. A variable has a name and a value. The value representation depends on what type of object the variable represents. The utility of variables comes in when we have a structure that is universal, but values of variables within the structure will change - otherwise it would be simple enough to just hardwire the arithmetic. Suppose we want to store the time of concentration for some hydrologic calculation. To do so, we can name a variable TimeOfConcentration , and then assign a value to the variable, for instance: TimeOfConcentration = 0.0 After this assignment statement the variable is created in the program and has a value of 0.0. The use of a decimal point in the initial assignment establishes the variable as a float (a real variable is called a floating point representation -- or just a float).","title":"Variables"},{"location":"lesson1/lesson1/#naming-rules","text":"Variable names in Python can only contain letters (a - z, A - Z), numerals (0 - 9), or underscores. The first character cannot be a number, otherwise there is considerable freedom in naming. The names can be reasonably long. runTime , run_Time , _run_Time2 , _2runTime are all valid names, but 2runTime is not valid, and will create an error when you try to use it. # Script to illustrate variable names runTime = 1 _2runTime = 2 # change to 2runTime = 2 and rerun script runTime2 = 2 print(runTime,_2runTime,runTime2) 1 2 2 There are some reserved words that cannot be used as variable names because they have preassigned meaning in Parseltongue. These words include print , input , if , while , and for . There are several more; the interpreter won't allow you to use these names as variables and will issue an error message when you attempt to run a program with such words used as variables.","title":"Naming Rules"},{"location":"lesson1/lesson1/#operators","text":"The = sign used in the variable definition is called an assignment operator (or assignment sign). The symbol means that the expression to the right of the symbol is to be evaluated and the result placed into the variable on the left side of the symbol. The \"operation\" is assignment, the \"=\" symbol is the operator name. Consider the script below # Assignment Operator x = 5 y = 10 print (x,y) x=y # reverse order y=x and re-run, what happens? print (x,y) 5 10 10 10 So look at what happened. When we assigned values to the variables named x and y , they started life as 5 and 10. We then wrote those values to the console, and the program returned 5 and 10. Then we assigned y to x which took the value in y and replaced the value that was in x with this value. We then wrote the contents again, and both variables have the value 10.","title":"Operators"},{"location":"lesson1/lesson1/#arithmetic-operators","text":"In addition to assignment we can also perform arithmetic operations on variables. The fundamental arithmetic operators are: Symbol Meaning Example = Assignment x=3 Assigns value of 3 to x. + Addition x+y Adds values in x and y. - Subtraction x-y Subtracts values in y from x. * Multiplication x*y Multiplies values in x and y. / Division x/y Divides value in x by value in y. // Floor division x//y Divide x by y, truncate result to whole number. % Modulus x%y Returns remainder when x is divided by y. ** Exponentation x y Raises value in x by value in y. ( e.g. x y) += Additive assignment x+=2 Equivalent to x = x+2. -= Subtractive assignment x-=2 Equivalent to x = x-2. *= Multiplicative assignment x*=3 Equivalent to x = x*3. /= Divide assignment x/3 Equivalent to x = x/3. Run the script in the next cell for some illustrative results # Uniary Arithmetic Operators x = 10 y = 5 print(x, y) print(x+y) print(x-y) print(x*y) print(x/y) print((x+1)//y) print((x+1)%y) print(x**y) 10 5 15 5 50 2.0 2 1 100000 # Arithmetic assignment operators x = 1 x += 2 print(type(x),x) x = 1 x -= 2 print(type(x),x) x = 1 x *=3 print(type(x),x) x = 10 x /= 2 print(type(x),x) # Interesting what division does to variable type <class 'int'> 3 <class 'int'> -1 <class 'int'> 3 <class 'float'> 5.0","title":"Arithmetic Operators"},{"location":"lesson1/lesson1/#data-type","text":"In the computer data are all binary digits (actually 0 and +5 volts). At a higher level of abstraction data are typed into integers, real, or alphanumeric representation. The type affects the kind of arithmetic operations that are allowed (as well as the kind of arithmetic - integer versus real arithmetic; lexicographical ordering of alphanumeric , etc.) In scientific programming, a common (and really difficult to detect) source of slight inaccuracies (that tend to snowball as the program runs) is mixed mode arithmetic required because two numeric values are of different types (integer and real). Learn more from the textbook https://www.inferentialthinking.com/chapters/04/Data_Types.html Here we present a quick summary","title":"Data Type"},{"location":"lesson1/lesson1/#integer","text":"Integers are numbers without any fractional portion (nothing after the decimal point { which is not used in integers). Numbers like -3, -2, -1, 0, 1, 2, 200 are integers. A number like 1.1 is not an integer, and 1.0 is also not an integer (the presence of the decimal point makes the number a real). To declare an integer in Python, just assign the variable name to an integer for example MyPhoneNumber = 14158576309","title":"Integer"},{"location":"lesson1/lesson1/#real-float","text":"A real or float is a number that has (or can have) a fractional portion - the number has decimal parts. The numbers 3.14159, -0.001, 11.11, 1., are all floats. The last one is especially tricky, if you don't notice the decimal point you might think it is an integer but the inclusion of the decimal point in Python tells the program that the value is to be treated as a float. To declare a float in Python, just assign the variable name to a float for example MyMassInKilos = 74.8427","title":"Real (Float)"},{"location":"lesson1/lesson1/#stringalphanumeric","text":"A string is a data type that is treated as text elements. The usual letters are strings, but numbers can be included. The numbers in a string are simply characters and cannot be directly used in arithmetic. There are some kinds of arithmetic that can be performed on strings but generally we process string variables to capture the text nature of their contents. To declare a string in Python, just assign the variable name to a string value - the trick is the value is enclosed in quotes. The quotes are delimiters that tell the program that the characters between the quotes are characters and are to be treated as literal representation. For example MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" are all string variables. The last assignment is made a string on purpose. String variables can be combined using an operation called concatenation. The symbol for concatenation is the plus symbol + . Strings can also be converted to all upper case using the upper() function. The syntax for the upper() function is 'string to be upper case'.upper() . Notice the \"dot\" in the syntax. The operation passes everything to the left of the dot to the function which then operates on that content and returns the result all upper case (or an error if the input stream is not a string). # Variable Types Example MyPhoneNumber = 14158576309 MyMassInKilos = 74.8427 MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" print(\"All about me\") print(\"Name: \",MyName, \" Mass :\",MyMassInKilos,\"Kg\" ) print('Phone : ',MyPhoneNumber) print('My cat\\'s name :', MyCatName) # the \\ escape character is used to get the ' into the literal print(\"All about concatenation!\") print(\"A Silly String : \",MyCatName+MyName+DustyMassInKilos) print(\"A SILLY STRING : \", (MyCatName+MyName+DustyMassInKilos).upper()) All about me Name: Theodore Mass : 74.8427 Kg Phone : 14158576309 My cat's name : Dusty All about concatenation! A Silly String : DustyTheodore7.48427 A SILLY STRING : DUSTYTHEODORE7.48427 Strings can be formatted using the % operator or the format() function. The concepts will be introduced later on as needed in the workbook, you can Google search for examples of how to do such formatting.","title":"String(Alphanumeric)"},{"location":"lesson1/lesson1/#changing-types","text":"A variable type can be changed. This activity is called type casting. Three functions allow type casting: int() , float() , and str() . The function names indicate the result of using the function, hence int() returns an integer, float() returns a oat, and str() returns a string. There is also the useful function type() which returns the type of variable. The easiest way to understand is to see an example. # Type Casting Examples MyInteger = 234 MyFloat = 876.543 MyString = 'What is your name?' print(MyInteger,MyFloat,MyString) print('Integer as float',float(MyInteger)) print('Float as integer',int(MyFloat)) print('Integer as string',str(MyInteger)) print('Integer as hexadecimal',hex(MyInteger)) print('Integer Type',type((MyInteger))) # insert the hex conversion and see what happens! 234 876.543 What is your name? Integer as float 234.0 Float as integer 876 Integer as string 234 Integer as hexadecimal 0xea Integer Type <class 'int'>","title":"Changing Types"},{"location":"lesson1/lesson1/#expressions","text":"Expressions are the \"algebraic\" constructions that are evaluated and then placed into a variable. Consider x1 = 7 + 3 * 6 / 2 - 1 The expression is evaluated from the left to right and in words is Into the object named x1 place the result of: integer 7 + (integer 6 divide by integer 2 = float 3 * integer 3 = float 9 - integer 1 = float 8) = float 15 The division operation by default produces a float result unless forced otherwise. The result is the variable x1 is a float with a value of 15.0 # Expressions Example x1 = 7 + 3 * 6 // 2 - 1 # Change / into // and see what happens! print(type(x1),x1) ## Simple I/O (Input/Output) <class 'int'> 15","title":"Expressions"},{"location":"lesson1/lesson1/#summary","text":"So far consider our story - a tool to help with problem solving is CT leading to an algorithm. The tool to implement the algorithm is the program and in our case JupyterLab running iPython interpreter for us. As a formal language we introduced: - tokens - structure From these two constructs we further introduced variables (a kind of token), data types (an abstraction, and arguably a decomposition), and expressions (a structure). We created simple scripts (with errors), examined the errors, corrected our script, and eventually got an answer. So we are well on our way in CT as it applies in Engineering.","title":"Summary"},{"location":"lesson1/lesson1/#programming-as-a-problem-solving-process","text":"Recall the entire point of this course is to develop problem solving skills and begin using some tools (Statistics, Numerical Methods, Data Science, implemented as JupyterLab/Python programs). Recall our suggested problem solving protocol: Explicitly state the problem State: Input information Governing equations or principles, and The required output information. Work a sample problem by-hand for testing the general solution. Develop a general solution method (coding). Test the general solution against the by-hand example, then apply to the real problem. Refine general solution for deployment (frequent use) Another protocol with the same goal is at https://3.137.111.182/engr-1330-webroot/1-Lessons/Lesson02/OriginalPowerpoint/HowToBuildAProgram.html Notice the similarity!","title":"Programming as a problem solving process"},{"location":"lesson1/lesson1/#example-2-problem-solving-process","text":"Consider an engineering material problem where we wish to classify whether a material in loaded in the elastic or inelastic region as determined the stress (solid pressure) in a rod for some applied load. The yield stress is the classifier, and once the material yields (begins to fail) it will not carry any additional load (until ultimate failure, when it carries no load). Step 1. Compute the material stress under an applied load; determine if value exceedes yield stress, and report the loading condition Step 2. - Inputs: applied load, cross sectional area, yield stress - Governing equation: \\sigma = \\frac{P}{A} when \\frac{P}{A} is less than the yield stress, and is equal to the yield stress otherwise. - Outputs: The material stress \\sigma , and the classification elastic or inelastic. Step 3. Work a sample problem by-hand for testing the general solution. Assuming the yield stress is 1 million psi (units matter in an actual problem - kind of glossed over here) Applied Load (lbf) Cross Section Area (sq.in.) Stress (psi) Classification 10,000 1.0 10,000 Elastic 10,000 0.1 100,000 Elastic 100,000 0.1 1,000,000 Inelastic The stress requires us to read in the load value, read in the cross sectional area, divide the load by the area, and compare the result to the yield stress. If it exceeds the yield stress, then the actual stress is the yield stress, and the loading is inelastic, otherwise elastic \\sigma = \\frac{P}{A} If \\sigma >= \\text{Yield Stress Report Inelastic} Step 4. Develop a general solution (code) In a flow-chart it would look like: Flowchart for Artihmetic Mean Algorithm Step 5. This step we would code the algorithm expressed in the figure and test it with the by-hand data and other small datasets until we are convinced it works correctly. We have not yet learned prompts to get input we simply direct assign values as below (and the conditional execution is the subject of a later lesson) In a simple JupyterLab script # Example 2 Problem Solving Process yield_stress = 1e6 applied_load = 1e5 cross_section = 0.1 computed_stress = applied_load/cross_section if(computed_stress < yield_stress): print(\"Elastic Region: Stress = \",computed_stress) elif(computed_stress >= yield_stress): print(\"Inelastic Region: Stress = \",yield_stress) Inelastic Region: Stress = 1000000.0 Step 6. This step we would refine the code to generalize the algorithm. In the example we want a way to supply the inputs by user entry,and tidy the output by rounding to only two decimal places. A little CCMR from https://www.geeksforgeeks.org/taking-input-in-python/ gives us a way to deal with the inputs and typecasting. Some more CCMR from https://www.programiz.com/python-programming/methods/built-in/round gets us rounded out! # Example 2 Problem Solving Process yield_stress = float(input('Yield Stress (psi)')) applied_load = float(input('Applied Load (lbf)')) cross_section = float(input('Cross Section Area (sq.in.)')) computed_stress = applied_load/cross_section if(computed_stress < yield_stress): print(\"Elastic Region: Stress = \",round(computed_stress,2)) elif(computed_stress >= yield_stress): print(\"Inelastic Region: Stress = \",round(yield_stress,2)) Yield Stress (psi) 1000000 Applied Load (lbf) 100000 Cross Section Area (sq.in.) 1 Elastic Region: Stress = 100000.0 So the simple task of computing the stress, is a bit more complex when decomposed, that it first appears, but illustrates a five step process (with a refinement step).","title":"Example 2 Problem Solving Process"},{"location":"lesson1/lesson1/#ccmr-approach","text":"A lot of the problems we will encounter from a CT/DS perspective have already been solved, or at least analogs have been solved. It is perfectly acceptable to use prior work for a new set of conditions as long as proper attribution is made. We call this process CCMR: Copy: Find a solution to your problem from some online example: SourceForge, StackOverflow, GeeksForGeeks, DigitalOcean, etc. Cite: Cite the original source. In general a citation will look like one of the references below, but a URL to the source is sufficient at first. Modify: Modify the original cited work for your specific needs. Note the changes in the code using comment statements. Run: Apply the modified code to the problem of interest. In cases where we use CCMR we are not so much programming and developing our own work as scaffolding parts (https://en.wikipedia.org/wiki/Scaffold_(programming)) - a legitimate and valuable engineering activity.","title":"CCMR Approach"},{"location":"lesson1/lesson1/#readings","text":"Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 3 https://www.inferentialthinking.com/chapters/03/programming-in-python.html Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 https://www.inferentialthinking.com/chapters/04/Data_Types.html Learn Python in One Day and Learn It Well. Python for Beginners with Hands-on Project. (Learn Coding Fast with Hands-On Project Book -- Kindle Edition by LCF Publishing (Author), Jamie Chan https://www.amazon.com/Python-2nd-Beginners-Hands-Project-ebook/dp/B071Z2Q6TQ/ref=sr_1_3?dchild=1&keywords=learn+python+in+a+day&qid=1611108340&sr=8-3 Learn Python the Hard Way (Online Book) (https://learnpythonthehardway.org/book/) Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) (https://www.learnpython.org/) Short, interactive tutorial for those who just need a quick way to pick up Python syntax. How to Think Like a Computer Scientist (Interactive Book) (https://runestone.academy/runestone/books/published/thinkcspy/index.html) Interactive \"CS 101\" course taught in Python that really focuses on the art of problem solving. How to Learn Python for Data Science, The Self-Starter Way (https://elitedatascience.com/learn-python-for-data-science) # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson02/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Readings"},{"location":"lesson2/lesson2/","text":"%%html <!-- Script Block to set tables to left alignment --> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 25 January 2021 Lesson 2 Data Structures and Conditional Statements: Data structures; lists, arrays, tuples, sets, dictionaries Name, index, contents; keys Conditional structures; logical compares, block and in-line if Objectives 1) Develop awareness of data structures available in Python to store and manipulate data - Implement arrays (lists), dictionaries, and tuples - Address contents of lists , dictionaries, and tuples 2) Develop awareness of decision making in Python - Implement decision making in Python using using if-then ... conditional statements Data Structures and Conditional Statements Computational thinking (CT) concepts involved are: Decomposition : Data interpretation, manipulation, and analysis of NumPy arrays Abstraction : Data structures; Arrays, lists, tuples, sets, and dictionaries Algorithms : Conditional statements What is a data structure? Data Structures are a specialized means of organizing and storing data in computers in such a way that we can perform operations on the stored data more efficiently. In our iPython world the structures are illustrated in the figure below Lists A list is a collection of data that are somehow related. It is a convenient way to refer to a collection of similar things by a single name, and using an index (like a subscript in math) to identify a particular item. Consider the \"math-like\" variable x below: \\begin{gather} x_0= 7 \\\\ x_1= 11 \\\\ x_2= 5 \\\\ x_3= 9 \\\\ x_4= 13 \\\\ \\dots \\\\ x_N= 223 \\\\ \\end{gather} The variable name is x and the subscripts correspond to different values. Thus the value of the variable named x associated with subscript 3 is the number 9 . The figure below is a visual representation of a the concept that treats a variable as a collection of cells. In the figure, the variable name is MyList , the subscripts are replaced by an index which identifies which cell is being referenced. The value is the cell content at the particular index. So in the figure the value of MyList at Index = 3 is the number 9.' In engineering and data science we use lists a lot - we often call then vectors, arrays, matrices and such, but they are ultimately just lists. To declare a list you can write the list name and assign it values. The square brackets are used to identify that the variable is a list. Like: MyList = [7,11,5,9,13,66,99,223] One can also declare a null list and use the append() method to fill it as needed. MyOtherList = [ ] Python indices start at ZERO . A lot of other languages start at ONE. It's just the convention. The first element in a list has an index of 0, the second an index of 1, and so on. We access the contents of a list by referring to its name and index. For example MyList[3] has a value of the number 9. Arrays Arrays are lists that are used to store only elements of a specific data type - Ordered: Elements in an array can be indexed - Mutable: Elements in an array can be altered Data type that an array must hold is specified using the type code when it is created - \u2018f\u2019 for float - \u2018d\u2019 for double - \u2018i\u2019 for signed int - \u2018I\u2019 for unsigned int More types are listed below Type Code C Data Type Python Data Type Minimum Size in Bytes 'b' signed char int 1 'B' unsigned char int 1 'h' signed short int 2 'H' unsigned short int 2 'i' signed int int 2 'I' unsigned int int 2 'l' signed long int 4 'L' unsigned long int 4 'q' signed long long int 8 'Q' unsigned long long int 8 'f' float float 4 'd' double float 8 To use arrays, a library named \u2018array\u2019 must be imported import array Creating an array that contains signed integer numbers myarray = array.array('i', [1, 2, 4, 8, 16, 32]) myarray[0] #1-st element, 0-th position 1 import array as arr #import using an alias so the calls dont look so funny myarray = arr.array('i', [1, 2, 4, 8, 16, 32]) myarray[0] #1-st element, 0-th position 1 Lists: Can store elements of different data types; like arrays they are (arrays are lists, but lists are not quite arrays!) - Ordered: Elements in a list can be indexed - Mutable: Elements in a list can be altered - Mathematical operations must be applied to each element of the list Tuple - A special list A tuple is a special kind of list where the values cannot be changed after the list is created. Such a property is called immutable It is useful for list-like things that are static - like days in a week, or months of a year. You declare a tuple like a list, except use round brackets instead of square brackets. MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") Tuples are often created as output from packages and functions. Dictionary - A special list A dictionary is a special kind of list where the items are related data PAIRS . It is a lot like a relational database (it probably is one in fact) where the first item in the pair is called the key, and must be unique in a dictionary, and the second item in the pair is the data. The second item could itself be a list, so a dictionary would be a meaningful way to build a database in Python. To declare a dictionary using curly brackets MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} To declare a dictionary using the dict() method MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) Dictionary properties - Unordered: Elements in a dictionary cannot be - Mutable elements: Elements in a dictionary can be altered - Immutable keys: Keys in a dictionary cannot be altered Sets - A special list Sets: Are used to store elements of different data types - Unordered: Elements in a set cannot be indexed - Mutable: Elements in a set can be altered - Non-repetition: Elements in a set are unique Elements of a set are enclosed in curly brackets { } - Creating sets that contains different data types - Sets cannot be nested What's the difference between a set and dictionary? From https://stackoverflow.com/questions/34370599/difference-between-dict-and-set-python \"Well, a set is like a dict with keys but no values, and they're both implemented using a hash table. But yes, it's a little annoying that the {} notation denotes an empty dict rather than an empty set , but that's a historical artifact.\" Conditional Statements Decision making via conditional statements is an important step in algorithm design; they control the flow of execution of a program. Conditional statements in Python include: if statement if....else statements if....elif....else statements Conditional statements are logical expressions that evaluate as TRUE or FALSE and using these results to perform further operations based on these conditions. All flow control in a program depends on evaluating conditions. The program will proceed diferently based on the outcome of one or more conditions - really sophisticated AI programs are a collection of conditions and correlations. Expressed in a flowchart a block if statement looks like: As psuedo code: if(condition is true): do stuff Amazon knowing what you kind of want is based on correlations of your past behavior compared to other peoples similar, but more recent behavior, and then it uses conditional statements to decide what item to offer you in your recommendation items. It's spooky, but ultimately just a program running in the background trying to make your money theirs. Comparison The most common conditional operation is comparison. If we wish to compare whether two variables are the same we use the == (double equal sign). For example x == y means the program will ask whether x and y have the same value. If they do, the result is TRUE if not then the result is FALSE. Other comparison signs are != does NOT equal, < smaller than, > larger than, <= less than or equal, and >= greater than or equal. There are also three logical operators when we want to build multiple compares (multiple conditioning); these are and , or , and not . The and operator returns TRUE if (and only if) all conditions are TRUE. For instance 5 == 5 and 5 < 6 will return a TRUE because both conditions are true. The or operator returns TRUE if at least one condition is true. If all conditions are FALSE, then it will return a FALSE. For instance 4 > 3 or 17 > 20 or 3 == 2 will return TRUE because the first condition is true. The not operator returns TRUE if the condition after the not keyword is false. Think of it as a way to do a logic reversal. Block if statement The if statement is a common flow control statement. It allows the program to evaluate if a certain condition is satisfied and to perform a designed action based on the result of the evaluation. The structure of an if statement is if condition1 is met: do A elif condition 2 is met: do b elif condition 3 is met: do c else: do e The elif means \"else if\". The : colon is an important part of the structure it tells where the action begins. Also there are no scope delimiters like (), or {} . Instead Python uses indentation to isolate blocks of code. This convention is hugely important - many other coding environments use delimiters (called scoping delimiters), but Python does not. The indentation itself is the scoping delimiter. Inline if statement An inline if statement is a simpler form of an if statement and is more convenient if you only need to perform a simple conditional task. The syntax is: do TaskA `if` condition is true `else` do TaskB An example would be myInt = 3 num1 = 12 if myInt == 0 else 13 num1 An alternative way is to enclose the condition in brackets for some clarity like myInt = 3 num1 = 12 if (myInt == 0) else 13 num1 In either case the result is that num1 will have the value 13 (unless you set myInt to 0). One can also use if to construct extremely inefficient loops. Readings Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 Subpart 3 https://www.inferentialthinking.com/chapters/04/3/Comparison.html Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 https://www.inferentialthinking.com/chapters/04/Data_Types.html Learn Python the Hard Way (Online Book) (https://learnpythonthehardway.org/book/) Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) (https://www.learnpython.org/) Short, interactive tutorial for those who just need a quick way to pick up Python syntax. # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson03/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Lesson 2"},{"location":"lesson2/lesson2/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 25 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson2/lesson2/#lesson-2-data-structures-and-conditional-statements","text":"Data structures; lists, arrays, tuples, sets, dictionaries Name, index, contents; keys Conditional structures; logical compares, block and in-line if","title":"Lesson 2 Data Structures and Conditional Statements:"},{"location":"lesson2/lesson2/#objectives","text":"1) Develop awareness of data structures available in Python to store and manipulate data - Implement arrays (lists), dictionaries, and tuples - Address contents of lists , dictionaries, and tuples 2) Develop awareness of decision making in Python - Implement decision making in Python using using if-then ... conditional statements","title":"Objectives"},{"location":"lesson2/lesson2/#data-structures-and-conditional-statements","text":"Computational thinking (CT) concepts involved are: Decomposition : Data interpretation, manipulation, and analysis of NumPy arrays Abstraction : Data structures; Arrays, lists, tuples, sets, and dictionaries Algorithms : Conditional statements","title":"Data Structures and Conditional Statements"},{"location":"lesson2/lesson2/#what-is-a-data-structure","text":"Data Structures are a specialized means of organizing and storing data in computers in such a way that we can perform operations on the stored data more efficiently. In our iPython world the structures are illustrated in the figure below","title":"What is a data structure?"},{"location":"lesson2/lesson2/#lists","text":"A list is a collection of data that are somehow related. It is a convenient way to refer to a collection of similar things by a single name, and using an index (like a subscript in math) to identify a particular item. Consider the \"math-like\" variable x below: \\begin{gather} x_0= 7 \\\\ x_1= 11 \\\\ x_2= 5 \\\\ x_3= 9 \\\\ x_4= 13 \\\\ \\dots \\\\ x_N= 223 \\\\ \\end{gather} The variable name is x and the subscripts correspond to different values. Thus the value of the variable named x associated with subscript 3 is the number 9 . The figure below is a visual representation of a the concept that treats a variable as a collection of cells. In the figure, the variable name is MyList , the subscripts are replaced by an index which identifies which cell is being referenced. The value is the cell content at the particular index. So in the figure the value of MyList at Index = 3 is the number 9.' In engineering and data science we use lists a lot - we often call then vectors, arrays, matrices and such, but they are ultimately just lists. To declare a list you can write the list name and assign it values. The square brackets are used to identify that the variable is a list. Like: MyList = [7,11,5,9,13,66,99,223] One can also declare a null list and use the append() method to fill it as needed. MyOtherList = [ ] Python indices start at ZERO . A lot of other languages start at ONE. It's just the convention. The first element in a list has an index of 0, the second an index of 1, and so on. We access the contents of a list by referring to its name and index. For example MyList[3] has a value of the number 9.","title":"Lists"},{"location":"lesson2/lesson2/#arrays","text":"Arrays are lists that are used to store only elements of a specific data type - Ordered: Elements in an array can be indexed - Mutable: Elements in an array can be altered Data type that an array must hold is specified using the type code when it is created - \u2018f\u2019 for float - \u2018d\u2019 for double - \u2018i\u2019 for signed int - \u2018I\u2019 for unsigned int More types are listed below Type Code C Data Type Python Data Type Minimum Size in Bytes 'b' signed char int 1 'B' unsigned char int 1 'h' signed short int 2 'H' unsigned short int 2 'i' signed int int 2 'I' unsigned int int 2 'l' signed long int 4 'L' unsigned long int 4 'q' signed long long int 8 'Q' unsigned long long int 8 'f' float float 4 'd' double float 8 To use arrays, a library named \u2018array\u2019 must be imported import array Creating an array that contains signed integer numbers myarray = array.array('i', [1, 2, 4, 8, 16, 32]) myarray[0] #1-st element, 0-th position 1 import array as arr #import using an alias so the calls dont look so funny myarray = arr.array('i', [1, 2, 4, 8, 16, 32]) myarray[0] #1-st element, 0-th position 1 Lists: Can store elements of different data types; like arrays they are (arrays are lists, but lists are not quite arrays!) - Ordered: Elements in a list can be indexed - Mutable: Elements in a list can be altered - Mathematical operations must be applied to each element of the list","title":"Arrays"},{"location":"lesson2/lesson2/#tuple-a-special-list","text":"A tuple is a special kind of list where the values cannot be changed after the list is created. Such a property is called immutable It is useful for list-like things that are static - like days in a week, or months of a year. You declare a tuple like a list, except use round brackets instead of square brackets. MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") Tuples are often created as output from packages and functions.","title":"Tuple - A special list"},{"location":"lesson2/lesson2/#dictionary-a-special-list","text":"A dictionary is a special kind of list where the items are related data PAIRS . It is a lot like a relational database (it probably is one in fact) where the first item in the pair is called the key, and must be unique in a dictionary, and the second item in the pair is the data. The second item could itself be a list, so a dictionary would be a meaningful way to build a database in Python. To declare a dictionary using curly brackets MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} To declare a dictionary using the dict() method MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) Dictionary properties - Unordered: Elements in a dictionary cannot be - Mutable elements: Elements in a dictionary can be altered - Immutable keys: Keys in a dictionary cannot be altered","title":"Dictionary - A special list"},{"location":"lesson2/lesson2/#sets-a-special-list","text":"Sets: Are used to store elements of different data types - Unordered: Elements in a set cannot be indexed - Mutable: Elements in a set can be altered - Non-repetition: Elements in a set are unique Elements of a set are enclosed in curly brackets { } - Creating sets that contains different data types - Sets cannot be nested","title":"Sets - A special list"},{"location":"lesson2/lesson2/#whats-the-difference-between-a-set-and-dictionary","text":"From https://stackoverflow.com/questions/34370599/difference-between-dict-and-set-python \"Well, a set is like a dict with keys but no values, and they're both implemented using a hash table. But yes, it's a little annoying that the {} notation denotes an empty dict rather than an empty set , but that's a historical artifact.\"","title":"What's the difference between a set and dictionary?"},{"location":"lesson2/lesson2/#conditional-statements","text":"Decision making via conditional statements is an important step in algorithm design; they control the flow of execution of a program. Conditional statements in Python include: if statement if....else statements if....elif....else statements Conditional statements are logical expressions that evaluate as TRUE or FALSE and using these results to perform further operations based on these conditions. All flow control in a program depends on evaluating conditions. The program will proceed diferently based on the outcome of one or more conditions - really sophisticated AI programs are a collection of conditions and correlations. Expressed in a flowchart a block if statement looks like: As psuedo code: if(condition is true): do stuff Amazon knowing what you kind of want is based on correlations of your past behavior compared to other peoples similar, but more recent behavior, and then it uses conditional statements to decide what item to offer you in your recommendation items. It's spooky, but ultimately just a program running in the background trying to make your money theirs.","title":"Conditional Statements"},{"location":"lesson2/lesson2/#comparison","text":"The most common conditional operation is comparison. If we wish to compare whether two variables are the same we use the == (double equal sign). For example x == y means the program will ask whether x and y have the same value. If they do, the result is TRUE if not then the result is FALSE. Other comparison signs are != does NOT equal, < smaller than, > larger than, <= less than or equal, and >= greater than or equal. There are also three logical operators when we want to build multiple compares (multiple conditioning); these are and , or , and not . The and operator returns TRUE if (and only if) all conditions are TRUE. For instance 5 == 5 and 5 < 6 will return a TRUE because both conditions are true. The or operator returns TRUE if at least one condition is true. If all conditions are FALSE, then it will return a FALSE. For instance 4 > 3 or 17 > 20 or 3 == 2 will return TRUE because the first condition is true. The not operator returns TRUE if the condition after the not keyword is false. Think of it as a way to do a logic reversal.","title":"Comparison"},{"location":"lesson2/lesson2/#block-if-statement","text":"The if statement is a common flow control statement. It allows the program to evaluate if a certain condition is satisfied and to perform a designed action based on the result of the evaluation. The structure of an if statement is if condition1 is met: do A elif condition 2 is met: do b elif condition 3 is met: do c else: do e The elif means \"else if\". The : colon is an important part of the structure it tells where the action begins. Also there are no scope delimiters like (), or {} . Instead Python uses indentation to isolate blocks of code. This convention is hugely important - many other coding environments use delimiters (called scoping delimiters), but Python does not. The indentation itself is the scoping delimiter.","title":"Block if statement"},{"location":"lesson2/lesson2/#inline-if-statement","text":"An inline if statement is a simpler form of an if statement and is more convenient if you only need to perform a simple conditional task. The syntax is: do TaskA `if` condition is true `else` do TaskB An example would be myInt = 3 num1 = 12 if myInt == 0 else 13 num1 An alternative way is to enclose the condition in brackets for some clarity like myInt = 3 num1 = 12 if (myInt == 0) else 13 num1 In either case the result is that num1 will have the value 13 (unless you set myInt to 0). One can also use if to construct extremely inefficient loops.","title":"Inline if statement"},{"location":"lesson2/lesson2/#readings","text":"Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 Subpart 3 https://www.inferentialthinking.com/chapters/04/3/Comparison.html Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 https://www.inferentialthinking.com/chapters/04/Data_Types.html Learn Python the Hard Way (Online Book) (https://learnpythonthehardway.org/book/) Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) (https://www.learnpython.org/) Short, interactive tutorial for those who just need a quick way to pick up Python syntax. # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson03/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Readings"},{"location":"lesson6/lesson6/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 31 January 2021 Lesson 6 Classes, Objects, and File Handling: Classes and Objects Files Create (new), Open (existing) Read from .... Write to ... Close (save) Delete Special Script Blocks %%html <!--Script block to left align Markdown Tables--> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} Objectives To understand the use of classes and objects to do effective coding in Python To understand the basic idea of how to manipulate the data in a file using file handling options in Python Classes and Objects In object-oriented programming, a class is an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods). In many languages, the class name is used as the name for the class (the template itself), the name for the default constructor of the class (a subroutine that creates objects), and as the type of objects generated by instantiating the class; these distinct concepts are easily conflated. When an object is created by a constructor of the class, the resulting object is called an instance of the class, and the member variables specific to the object are called instance variables, to contrast with the class variables shared across the class. Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. Each class instance can have attributes attached to it for maintaining its state. Class instances can also have methods (defined by its class) for modifying its state. Class definitions, like function definitions (def statements) must be executed before they have any effect. (You could conceivably place a class definition in a branch of an if statement, or inside a function.) In practice, the statements inside a class definition will usually be function definitions, but other statements are allowed, and sometimes useful \u2014 we\u2019ll come back to this later. The function definitions inside a class normally have a peculiar form of argument list, dictated by the calling conventions for methods \u2014 again, this is explained later. When a class definition is entered, a new namespace is created, and used as the local scope \u2014 thus, all assignments to local variables go into this new namespace. In particular, function definitions bind the name of the new function here. When a class definition is left normally (via the end), a class object is created. This is basically a wrapper around the contents of the namespace created by the class definition; we\u2019ll learn more about class objects in the next section. The original local scope (the one in effect just before the class definition was entered) is reinstated, and the class object is bound here to the class name given in the class definition header (ClassName in the example). What is an object? An object is simply a collection of data (variables) and methods (functions) that act on those data. Similarly, a class is a blueprint for that object. We can think of class as a sketch (prototype) of a house. It contains all the details about the floors, doors, windows etc. Based on these descriptions we build the house. House is the object. As many houses can be made from a house's blueprint, we can create many objects from a class. An object is also called an instance of a class and the process of creating this object is called instantiation Learn more at 1. https://docs.python.org/3/tutorial/classes.html 2. https://en.wikipedia.org/wiki/Class_(computer_programming) An Example: Write a class named ' Tax ' to calculate the state tax (in dollars) of Employees at Texas Tech University based on their annual salary. The state tax is 16% if the annual salary is below 80,000 dollars and 22% if the salary is more than 80,000 dollars. Employee Annual salary (dollars) Bob 150,000 Mary 78,000 John 55,000 Danny 175,000 Notes: Use docstrings to describe the purpose of the class. Use if....else conditional statements within the method of the class to choose the relevant tax % based on the annual salary. Create an object for employee and display the output as shown below. Bob's tax amount (in dollars): AMOUNT Mary's tax amount (in dollars): AMOUNT John's tax amount (in dollars): AMOUNT Danny's tax amount (in dollars): AMOUNT class Tax: \"\"\"This class calculates the tax amount based on the annual salary and the state tax %\"\"\" def __init__(self, salary): # here is the instantiation constructor self.salary = salary def taxamount(self): # here is a method (function) that can operate on the class once created if self.salary < 80000: return self.salary*(16/100) else: return self.salary*(22/100) bob = Tax(150000) dir(bob) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'salary', 'taxamount'] bob = Tax(150000) # objects constructed using Tax class mary = Tax(78000) john = Tax(55000) danny = Tax(175000) dir(Tax) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'taxamount'] dir(mary) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'salary', 'taxamount'] print(\"bobz salary \", bob.salary ) print(\"Bob's tax amount (in dollars):\", bob.taxamount() ) print(\"Mary's tax amount (in dollars):\", mary.taxamount()) print(\"John's tax amount (in dollars):\", john.taxamount()) print(\"Danny's tax amount (in dollars):\", danny.taxamount()) bobz salary 150000 Bob's tax amount (in dollars): 33000.0 Mary's tax amount (in dollars): 12480.0 John's tax amount (in dollars): 8800.0 Danny's tax amount (in dollars): 38500.0 Numbers, strings, lists, and dictionaries are all objects that are instances of a parent class print(type(0)) <class 'int'> print(type(\"\")) <class 'str'> print(type([1, 2, 3, 4])) <class 'list'> To get more information about the built-in classes and objects, use dir( ) and help( ) functions print(dir(int)) print(help(\"\")) User-defined classes: Defining docstrings class Dog: \"\"\"This class enables the dog to say its name and age in dog years\"\"\" def __init__(self, name, years): \"\"\"This function contains all the necessary attributes\"\"\" self.name = name self.years = years self.dog_age = years*9 def sound(self): \"\"\"This function enables the dog to speak\"\"\" print(\"woof! I am {} and I am {} dog years old! woof!\".format(self.name, self.dog_age)) fudge = Dog(\"Fudge\", 2) maple = Dog(\"Maple\", 1.5) fudge.sound() maple.sound() woof! I am Fudge and I am 18 dog years old! woof! woof! I am Maple and I am 13.5 dog years old! woof! help(Dog) Help on class Dog in module __main__: class Dog(builtins.object) | Dog(name, years) | | This class enables the dog to say its name and age in dog years | | Methods defined here: | | __init__(self, name, years) | This function contains all the necessary attributes | | sound(self) | This function enables the dog to speak | | ---------------------------------------------------------------------- | Data descriptors defined here: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined) Files and Filesystems Background A computer file is a computer resource for recording data discretely (not in the secretive context, but specifically somewhere on a piece of hardware) in a computer storage device. Just as words can be written to paper, so can information be written to a computer file. Files can be edited and transferred through the internet on that particular computer system. There are different types of computer files, designed for different purposes. A file may be designed to store a picture, a written message, a video, a computer program, or a wide variety of other kinds of data. Some types of files can store several types of information at once. By using computer programs, a person can open, read, change, save, and close a computer file. Computer files may be reopened, modified, and copied an arbitrary number of times. Typically, files are organised in a file system, which keeps track of where the files are located on disk and enables user access. File system In computing, a file system or filesystem, controls how data is stored and retrieved. Without a file system, data placed in a storage medium would be one large body of data with no way to tell where one piece of data stops and the next begins. By separating the data into pieces and giving each piece a name, the data is isolated and identified. Taking its name from the way paper-based data management system is named, each group of data is called a \u201cfile\u201d. The structure and logic rules used to manage the groups of data and their names is called a \u201cfile system\u201d. Path A path, the general form of the name of a file or directory, specifies a unique location in a file system. A path points to a file system location by following the directory tree hierarchy expressed in a string of characters in which path components, separated by a delimiting character, represent each directory. The delimiting character is most commonly the slash (\u201d/\u201d), the backslash character (\u201d\\\u201d), or colon (\u201d:\u201d), though some operating systems may use a different delimiter. Paths are used extensively in computer science to represent the directory/file relationships common in modern operating systems, and are essential in the construction of Uniform Resource Locators (URLs). Resources can be represented by either absolute or relative paths. As an example consider the following two files: /Users/theodore/MyGit/@atomickitty/hurri-sensors/.git/Guest.conf /etc/apache2/users/Guest.conf They both have the same file name, but are located on different paths. Failure to provide the path when addressing the file can be a problem. Another way to interpret is that the two unique files actually have different names, and only part of those names is common (Guest.conf) The two names above (including the path) are called fully qualified filenames (or absolute names), a relative path (usually relative to the file or program of interest depends on where in the directory structure the file lives. If we are currently in the .git directory (the first file) the path to the file is just the filename. We have experienced path issues with dependencies on .png files - in general your JupyterLab notebooks on CoCalc can only look at the local directory which is why we have to copy files into the directory for things to work. File Types Text Files. Text files are regular files that contain information readable by the user. This information is stored in ASCII. You can display and print these files. The lines of a text file must not contain NULL characters, and none can exceed a prescribed (by architecture) length, including the new-line character. The term text file does not prevent the inclusion of control or other nonprintable characters (other than NUL). Therefore, standard utilities that list text files as inputs or outputs are either able to process the special characters gracefully or they explicitly describe their limitations within their individual sections. Binary Files. Binary files are regular files that contain information readable by the computer. Binary files may be executable files that instruct the system to accomplish a job. Commands and programs are stored in executable, binary files. Special compiling programs translate ASCII text into binary code. The only difference between text and binary files is that text files have lines of less than some length, with no NULL characters, each terminated by a new-line character. Directory Files. Directory files contain information the system needs to access all types of files, but they do not contain the actual file data. As a result, directories occupy less space than a regular file and give the file system structure flexibility and depth. Each directory entry represents either a file or a subdirectory. Each entry contains the name of the file and the file's index node reference number (i-node). The i-node points to the unique index node assigned to the file. The i-node describes the location of the data associated with the file. Directories are created and controlled by a separate set of commands. File Manipulation For this lesson we examine just a handfull of file manipulations which are quite useful. Files can be \"created\",\"read\",\"updated\", or \"deleted\" (CRUD). Example: Create a file, write to it. Below is an example of creating a file that does not yet exist. The script is a bit pendandic on purpose. First will use some system commands to view the contents of the local directory import sys # on a Mac/Linux ! rm -rf myfirstfile.txt # delete file if it exists ! pwd # list name of working directory, note it includes path, so it is an absolute path # on Winderz #! del myfirstfile.txt # delete file if it exists #! %pwd # list name of working directory, note it includes path, so it is an absolute path /home/sensei/1330-textbook-webroot/docs/lesson6 # on a Mac/Linux ! ls -l # list contents of working directory # on Winderz #! dir # list contents of working directory total 752 -rw-rw-r-- 1 sensei sensei 9353 Feb 17 17:31 ClassObjects_FileHandling_LabSession.ipynb -rw-rw-r-- 1 sensei sensei 38589 Feb 17 17:31 ClassObjects_FileHandling_LectureSession.ipynb -rw-rw-r-- 1 sensei sensei 627474 Feb 17 17:31 ENGR-1330-Lesson6-Dev.html -rw-rw-r-- 1 sensei sensei 36134 Feb 17 17:31 ENGR-1330-Lesson6-Dev.ipynb -rw-rw-r-- 1 sensei sensei 524 Feb 17 17:31 ReadingFile.txt -rw-rw-r-- 1 sensei sensei 36342 Feb 17 17:34 lesson6.ipynb -rw-rw-r-- 1 sensei sensei 153 Feb 17 17:31 sample-Copy1.txt -rw-rw-r-- 1 sensei sensei 111 Feb 17 17:31 sample.txt # create file example externalfile = open(\"myfirstfile.txt\",'w') # create connection to file, set to write (w), file does not need to exist mymessage = 'message in a bottle' #some object to write, in this case a string externalfile.write(mymessage)# write the contents of mymessage to the file externalfile.close() # close the file connection At this point our new file should exist, lets list the directory and see if that is so # on a Mac/Linux ! ls -l # list contents of working directory # on Winderz #! dir # list contents of working directory total 756 -rw-rw-r-- 1 sensei sensei 9353 Feb 17 17:31 ClassObjects_FileHandling_LabSession.ipynb -rw-rw-r-- 1 sensei sensei 38589 Feb 17 17:31 ClassObjects_FileHandling_LectureSession.ipynb -rw-rw-r-- 1 sensei sensei 627474 Feb 17 17:31 ENGR-1330-Lesson6-Dev.html -rw-rw-r-- 1 sensei sensei 36134 Feb 17 17:31 ENGR-1330-Lesson6-Dev.ipynb -rw-rw-r-- 1 sensei sensei 524 Feb 17 17:31 ReadingFile.txt -rw-rw-r-- 1 sensei sensei 36342 Feb 17 17:34 lesson6.ipynb -rw-rw-r-- 1 sensei sensei 19 Feb 17 17:35 myfirstfile.txt -rw-rw-r-- 1 sensei sensei 153 Feb 17 17:31 sample-Copy1.txt -rw-rw-r-- 1 sensei sensei 111 Feb 17 17:31 sample.txt Sure enough, its there, we will use a bash command cat to look at the contents of the file. ! cat myfirstfile.txt # Mac/Linux # ! type myfirstfile.txt # Winderz message in a bottle Example: Read from an existing file. We will continue using the file we just made, and read from it the example is below # read file example externalfile = open(\"myfirstfile.txt\",'r') # create connection to file, set to read (r), file must exist silly_string = externalfile.read() # read the contents externalfile.close() # close the file connection print(silly_string) message in a bottle Example: Update a file. This example continues with our same file, but we will now add contents without destroying existing contents. The keyword is append externalfile = open(\"myfirstfile.txt\",'a') # create connection to file, set to append (a), file does not need to exist externalfile.write('\\n') # adds a newline character what_to_add = 'I love rock-and-roll, put another dime in the jukebox baby ... \\n' externalfile.write(what_to_add) # add a string including the linefeed what_to_add = '... the waiting is the hardest part \\n' externalfile.write(what_to_add) # add a string including the linefeed mylist = [1,2,3,4,5] # a list of numbers what_to_add = ','.join(map(repr, mylist)) + \"\\n\" # one way to write the list externalfile.write(what_to_add) what_to_add = ','.join(map(repr, mylist[0:len(mylist)])) + \"\\n\" # another way to write the list externalfile.write(what_to_add) externalfile.close() As before we can examine the contents using a shell command sent from the notebook. ! cat myfirstfile.txt # ! type myfirstfile.txt # Winderz message in a bottle I love rock-and-roll, put another dime in the jukebox baby ... ... the waiting is the hardest part 1,2,3,4,5 1,2,3,4,5 Example: Delete a file Delete can be done by a system call as we did above to clear the local directory In a JupyterLab notebook, we can either use import sys ! rm -rf myfirstfile.txt # delete file if it exists or import os os.remove(\"myfirstfile.txt\") they both have same effect, both equally dangerous to your filesystem. Learn more about CRUD with text files at https://www.guru99.com/reading-and-writing-files-in-python.html Learn more about file delete at https://www.dummies.com/programming/python/how-to-delete-a-file-in-python/ import os file2kill = \"myfirstfile.txt\" try: os.remove(file2kill) # file must exist or will generate an exception except: pass # example of using pass to improve readability print(file2kill, \" missing or deleted !\") myfirstfile.txt missing or deleted ! A little discussion on the part where we wrote numbers what_to_add = ','.join(map(repr, mylist[0:len(mylist)])) + \"\\n\" Here are descriptions of the two functions map and repr map(function, iterable, ...) Apply function to every item of iterable and return a list of the results. If additional iterable arguments are passed, function must take that many arguments and is applied to the items from all iterables in parallel. If one iterable is shorter than another it is assumed to be extended with None items. If function is None, the identity function is assumed; if there are multiple arguments, map() returns a list consisting of tuples containing the corresponding items from all iterables (a kind of transpose operation). The iterable arguments may be a sequence or any iterable object; the result is always a list. repr(object) Return a string containing a printable representation of an object. This is the same value yielded by conversions (reverse quotes). It is sometimes useful to be able to access this operation as an ordinary function. For many types, this function makes an attempt to return a string that would yield an object with the same value when passed to eval() , otherwise the representation is a string enclosed in angle brackets that contains the name of the type of the object together with additional information often including the name and address of the object. A class can control what this function returns for its instances by defining a repr() method. What they do in this script is important. The statement: what_to_add = \u2019,\u2019.join(map(repr, mylist[0:len(mylist)])) + \"\\n\" is building a string that will be comprised of elements of mylist[0:len(mylist)]. The repr() function gets these elements as they are represented in the computer, the delimiter a comma is added using the join method in Python, and because everything is now a string the ... + \"\\n\" puts a linefeed character at the end of the string so the output will start a new line the next time something is written. Example create a text file, name it \"MyFavoriteQuotation\" . Write your favorite quotation in the file. Read the file. Add this string to it in a new line : \"And that's something I wish I had said...\" Show the final outcome. # create the \"My Favorite Quotation\" file: externalfile = open(\"MyFavoriteQuotation.txt\",'w') # create connection to file, set to write (w) myquotation = 'The path of the righteous man is beset on all sides by the inequities of the selfish and the tyranny of evil men. Blessed is he who, in the name of charity and good will, shepherds the weak through the valley of darkness. For he is truly his brother\u2019s keeper and the finder of lost children. And I will strike down upon thee with great vengeance and furious anger those who attempt to poison and destroy my brothers. And you will know my name is the Lord when I lay my vengeance upon you.' #My choice: quotation from Pulp Fiction externalfile.write(myquotation)# write the contents of mymessage to the file externalfile.close() # close the file connection #Let's read the file ! cat MyFavoriteQuotation.txt # Let's add the string externalfile = open(\"MyFavoriteQuotation.txt\",'a') #create connection to file, set to append (a) externalfile.write('\\n') # adds a newline character what_to_add = \"And that's something I wish I had said ... \\n\" externalfile.write(what_to_add) externalfile.close() #Let's read the file one last time ! cat MyFavoriteQuotation.txt # ! type MyFavoriteQuotation # Winderz The path of the righteous man is beset on all sides by the inequities of the selfish and the tyranny of evil men. Blessed is he who, in the name of charity and good will, shepherds the weak through the valley of darkness. For he is truly his brother\u2019s keeper and the finder of lost children. And I will strike down upon thee with great vengeance and furious anger those who attempt to poison and destroy my brothers. And you will know my name is the Lord when I lay my vengeance upon you.The path of the righteous man is beset on all sides by the inequities of the selfish and the tyranny of evil men. Blessed is he who, in the name of charity and good will, shepherds the weak through the valley of darkness. For he is truly his brother\u2019s keeper and the finder of lost children. And I will strike down upon thee with great vengeance and furious anger those who attempt to poison and destroy my brothers. And you will know my name is the Lord when I lay my vengeance upon you. And that's something I wish I had said ... References Overland, B. (2018). Python Without Fear. Addison-Wesley ISBN 978-0-13-468747-6. Grus, Joel (2015). Data Science from Scratch: First Principles with Python O\u2019Reilly Media. Kindle Edition. Precord, C. (2010) wxPython 2.8 Application Development Cookbook Packt Publishing Ltd. Birmingham , B27 6PA, UK ISBN 978-1-849511-78-0. # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty compthink /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Lesson 6"},{"location":"lesson6/lesson6/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 31 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson6/lesson6/#lesson-6-classes-objects-and-file-handling","text":"Classes and Objects Files Create (new), Open (existing) Read from .... Write to ... Close (save) Delete","title":"Lesson 6 Classes, Objects, and File Handling:"},{"location":"lesson6/lesson6/#special-script-blocks","text":"%%html <!--Script block to left align Markdown Tables--> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;}","title":"Special Script Blocks"},{"location":"lesson6/lesson6/#objectives","text":"To understand the use of classes and objects to do effective coding in Python To understand the basic idea of how to manipulate the data in a file using file handling options in Python","title":"Objectives"},{"location":"lesson6/lesson6/#classes-and-objects","text":"In object-oriented programming, a class is an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods). In many languages, the class name is used as the name for the class (the template itself), the name for the default constructor of the class (a subroutine that creates objects), and as the type of objects generated by instantiating the class; these distinct concepts are easily conflated. When an object is created by a constructor of the class, the resulting object is called an instance of the class, and the member variables specific to the object are called instance variables, to contrast with the class variables shared across the class. Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. Each class instance can have attributes attached to it for maintaining its state. Class instances can also have methods (defined by its class) for modifying its state. Class definitions, like function definitions (def statements) must be executed before they have any effect. (You could conceivably place a class definition in a branch of an if statement, or inside a function.) In practice, the statements inside a class definition will usually be function definitions, but other statements are allowed, and sometimes useful \u2014 we\u2019ll come back to this later. The function definitions inside a class normally have a peculiar form of argument list, dictated by the calling conventions for methods \u2014 again, this is explained later. When a class definition is entered, a new namespace is created, and used as the local scope \u2014 thus, all assignments to local variables go into this new namespace. In particular, function definitions bind the name of the new function here. When a class definition is left normally (via the end), a class object is created. This is basically a wrapper around the contents of the namespace created by the class definition; we\u2019ll learn more about class objects in the next section. The original local scope (the one in effect just before the class definition was entered) is reinstated, and the class object is bound here to the class name given in the class definition header (ClassName in the example).","title":"Classes and Objects"},{"location":"lesson6/lesson6/#what-is-an-object","text":"An object is simply a collection of data (variables) and methods (functions) that act on those data. Similarly, a class is a blueprint for that object. We can think of class as a sketch (prototype) of a house. It contains all the details about the floors, doors, windows etc. Based on these descriptions we build the house. House is the object. As many houses can be made from a house's blueprint, we can create many objects from a class. An object is also called an instance of a class and the process of creating this object is called instantiation Learn more at 1. https://docs.python.org/3/tutorial/classes.html 2. https://en.wikipedia.org/wiki/Class_(computer_programming)","title":"What is an object?"},{"location":"lesson6/lesson6/#an-example","text":"Write a class named ' Tax ' to calculate the state tax (in dollars) of Employees at Texas Tech University based on their annual salary. The state tax is 16% if the annual salary is below 80,000 dollars and 22% if the salary is more than 80,000 dollars. Employee Annual salary (dollars) Bob 150,000 Mary 78,000 John 55,000 Danny 175,000","title":"An Example:"},{"location":"lesson6/lesson6/#notes","text":"Use docstrings to describe the purpose of the class. Use if....else conditional statements within the method of the class to choose the relevant tax % based on the annual salary. Create an object for employee and display the output as shown below. Bob's tax amount (in dollars): AMOUNT Mary's tax amount (in dollars): AMOUNT John's tax amount (in dollars): AMOUNT Danny's tax amount (in dollars): AMOUNT class Tax: \"\"\"This class calculates the tax amount based on the annual salary and the state tax %\"\"\" def __init__(self, salary): # here is the instantiation constructor self.salary = salary def taxamount(self): # here is a method (function) that can operate on the class once created if self.salary < 80000: return self.salary*(16/100) else: return self.salary*(22/100) bob = Tax(150000) dir(bob) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'salary', 'taxamount'] bob = Tax(150000) # objects constructed using Tax class mary = Tax(78000) john = Tax(55000) danny = Tax(175000) dir(Tax) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'taxamount'] dir(mary) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'salary', 'taxamount'] print(\"bobz salary \", bob.salary ) print(\"Bob's tax amount (in dollars):\", bob.taxamount() ) print(\"Mary's tax amount (in dollars):\", mary.taxamount()) print(\"John's tax amount (in dollars):\", john.taxamount()) print(\"Danny's tax amount (in dollars):\", danny.taxamount()) bobz salary 150000 Bob's tax amount (in dollars): 33000.0 Mary's tax amount (in dollars): 12480.0 John's tax amount (in dollars): 8800.0 Danny's tax amount (in dollars): 38500.0 Numbers, strings, lists, and dictionaries are all objects that are instances of a parent class print(type(0)) <class 'int'> print(type(\"\")) <class 'str'> print(type([1, 2, 3, 4])) <class 'list'> To get more information about the built-in classes and objects, use dir( ) and help( ) functions print(dir(int)) print(help(\"\")) User-defined classes: Defining docstrings class Dog: \"\"\"This class enables the dog to say its name and age in dog years\"\"\" def __init__(self, name, years): \"\"\"This function contains all the necessary attributes\"\"\" self.name = name self.years = years self.dog_age = years*9 def sound(self): \"\"\"This function enables the dog to speak\"\"\" print(\"woof! I am {} and I am {} dog years old! woof!\".format(self.name, self.dog_age)) fudge = Dog(\"Fudge\", 2) maple = Dog(\"Maple\", 1.5) fudge.sound() maple.sound() woof! I am Fudge and I am 18 dog years old! woof! woof! I am Maple and I am 13.5 dog years old! woof! help(Dog) Help on class Dog in module __main__: class Dog(builtins.object) | Dog(name, years) | | This class enables the dog to say its name and age in dog years | | Methods defined here: | | __init__(self, name, years) | This function contains all the necessary attributes | | sound(self) | This function enables the dog to speak | | ---------------------------------------------------------------------- | Data descriptors defined here: | | __dict__ | dictionary for instance variables (if defined) | | __weakref__ | list of weak references to the object (if defined)","title":"Notes:"},{"location":"lesson6/lesson6/#files-and-filesystems","text":"","title":"Files and Filesystems"},{"location":"lesson6/lesson6/#background","text":"A computer file is a computer resource for recording data discretely (not in the secretive context, but specifically somewhere on a piece of hardware) in a computer storage device. Just as words can be written to paper, so can information be written to a computer file. Files can be edited and transferred through the internet on that particular computer system. There are different types of computer files, designed for different purposes. A file may be designed to store a picture, a written message, a video, a computer program, or a wide variety of other kinds of data. Some types of files can store several types of information at once. By using computer programs, a person can open, read, change, save, and close a computer file. Computer files may be reopened, modified, and copied an arbitrary number of times. Typically, files are organised in a file system, which keeps track of where the files are located on disk and enables user access.","title":"Background"},{"location":"lesson6/lesson6/#file-system","text":"In computing, a file system or filesystem, controls how data is stored and retrieved. Without a file system, data placed in a storage medium would be one large body of data with no way to tell where one piece of data stops and the next begins. By separating the data into pieces and giving each piece a name, the data is isolated and identified. Taking its name from the way paper-based data management system is named, each group of data is called a \u201cfile\u201d. The structure and logic rules used to manage the groups of data and their names is called a \u201cfile system\u201d.","title":"File system"},{"location":"lesson6/lesson6/#path","text":"A path, the general form of the name of a file or directory, specifies a unique location in a file system. A path points to a file system location by following the directory tree hierarchy expressed in a string of characters in which path components, separated by a delimiting character, represent each directory. The delimiting character is most commonly the slash (\u201d/\u201d), the backslash character (\u201d\\\u201d), or colon (\u201d:\u201d), though some operating systems may use a different delimiter. Paths are used extensively in computer science to represent the directory/file relationships common in modern operating systems, and are essential in the construction of Uniform Resource Locators (URLs). Resources can be represented by either absolute or relative paths. As an example consider the following two files: /Users/theodore/MyGit/@atomickitty/hurri-sensors/.git/Guest.conf /etc/apache2/users/Guest.conf They both have the same file name, but are located on different paths. Failure to provide the path when addressing the file can be a problem. Another way to interpret is that the two unique files actually have different names, and only part of those names is common (Guest.conf) The two names above (including the path) are called fully qualified filenames (or absolute names), a relative path (usually relative to the file or program of interest depends on where in the directory structure the file lives. If we are currently in the .git directory (the first file) the path to the file is just the filename. We have experienced path issues with dependencies on .png files - in general your JupyterLab notebooks on CoCalc can only look at the local directory which is why we have to copy files into the directory for things to work.","title":"Path"},{"location":"lesson6/lesson6/#file-types","text":"Text Files. Text files are regular files that contain information readable by the user. This information is stored in ASCII. You can display and print these files. The lines of a text file must not contain NULL characters, and none can exceed a prescribed (by architecture) length, including the new-line character. The term text file does not prevent the inclusion of control or other nonprintable characters (other than NUL). Therefore, standard utilities that list text files as inputs or outputs are either able to process the special characters gracefully or they explicitly describe their limitations within their individual sections. Binary Files. Binary files are regular files that contain information readable by the computer. Binary files may be executable files that instruct the system to accomplish a job. Commands and programs are stored in executable, binary files. Special compiling programs translate ASCII text into binary code. The only difference between text and binary files is that text files have lines of less than some length, with no NULL characters, each terminated by a new-line character. Directory Files. Directory files contain information the system needs to access all types of files, but they do not contain the actual file data. As a result, directories occupy less space than a regular file and give the file system structure flexibility and depth. Each directory entry represents either a file or a subdirectory. Each entry contains the name of the file and the file's index node reference number (i-node). The i-node points to the unique index node assigned to the file. The i-node describes the location of the data associated with the file. Directories are created and controlled by a separate set of commands.","title":"File Types"},{"location":"lesson6/lesson6/#file-manipulation","text":"For this lesson we examine just a handfull of file manipulations which are quite useful. Files can be \"created\",\"read\",\"updated\", or \"deleted\" (CRUD).","title":"File Manipulation"},{"location":"lesson6/lesson6/#example-create-a-file-write-to-it","text":"Below is an example of creating a file that does not yet exist. The script is a bit pendandic on purpose. First will use some system commands to view the contents of the local directory import sys # on a Mac/Linux ! rm -rf myfirstfile.txt # delete file if it exists ! pwd # list name of working directory, note it includes path, so it is an absolute path # on Winderz #! del myfirstfile.txt # delete file if it exists #! %pwd # list name of working directory, note it includes path, so it is an absolute path /home/sensei/1330-textbook-webroot/docs/lesson6 # on a Mac/Linux ! ls -l # list contents of working directory # on Winderz #! dir # list contents of working directory total 752 -rw-rw-r-- 1 sensei sensei 9353 Feb 17 17:31 ClassObjects_FileHandling_LabSession.ipynb -rw-rw-r-- 1 sensei sensei 38589 Feb 17 17:31 ClassObjects_FileHandling_LectureSession.ipynb -rw-rw-r-- 1 sensei sensei 627474 Feb 17 17:31 ENGR-1330-Lesson6-Dev.html -rw-rw-r-- 1 sensei sensei 36134 Feb 17 17:31 ENGR-1330-Lesson6-Dev.ipynb -rw-rw-r-- 1 sensei sensei 524 Feb 17 17:31 ReadingFile.txt -rw-rw-r-- 1 sensei sensei 36342 Feb 17 17:34 lesson6.ipynb -rw-rw-r-- 1 sensei sensei 153 Feb 17 17:31 sample-Copy1.txt -rw-rw-r-- 1 sensei sensei 111 Feb 17 17:31 sample.txt # create file example externalfile = open(\"myfirstfile.txt\",'w') # create connection to file, set to write (w), file does not need to exist mymessage = 'message in a bottle' #some object to write, in this case a string externalfile.write(mymessage)# write the contents of mymessage to the file externalfile.close() # close the file connection At this point our new file should exist, lets list the directory and see if that is so # on a Mac/Linux ! ls -l # list contents of working directory # on Winderz #! dir # list contents of working directory total 756 -rw-rw-r-- 1 sensei sensei 9353 Feb 17 17:31 ClassObjects_FileHandling_LabSession.ipynb -rw-rw-r-- 1 sensei sensei 38589 Feb 17 17:31 ClassObjects_FileHandling_LectureSession.ipynb -rw-rw-r-- 1 sensei sensei 627474 Feb 17 17:31 ENGR-1330-Lesson6-Dev.html -rw-rw-r-- 1 sensei sensei 36134 Feb 17 17:31 ENGR-1330-Lesson6-Dev.ipynb -rw-rw-r-- 1 sensei sensei 524 Feb 17 17:31 ReadingFile.txt -rw-rw-r-- 1 sensei sensei 36342 Feb 17 17:34 lesson6.ipynb -rw-rw-r-- 1 sensei sensei 19 Feb 17 17:35 myfirstfile.txt -rw-rw-r-- 1 sensei sensei 153 Feb 17 17:31 sample-Copy1.txt -rw-rw-r-- 1 sensei sensei 111 Feb 17 17:31 sample.txt Sure enough, its there, we will use a bash command cat to look at the contents of the file. ! cat myfirstfile.txt # Mac/Linux # ! type myfirstfile.txt # Winderz message in a bottle","title":"Example: Create a file, write to it."},{"location":"lesson6/lesson6/#example-read-from-an-existing-file","text":"We will continue using the file we just made, and read from it the example is below # read file example externalfile = open(\"myfirstfile.txt\",'r') # create connection to file, set to read (r), file must exist silly_string = externalfile.read() # read the contents externalfile.close() # close the file connection print(silly_string) message in a bottle","title":"Example: Read from an existing file."},{"location":"lesson6/lesson6/#example-update-a-file","text":"This example continues with our same file, but we will now add contents without destroying existing contents. The keyword is append externalfile = open(\"myfirstfile.txt\",'a') # create connection to file, set to append (a), file does not need to exist externalfile.write('\\n') # adds a newline character what_to_add = 'I love rock-and-roll, put another dime in the jukebox baby ... \\n' externalfile.write(what_to_add) # add a string including the linefeed what_to_add = '... the waiting is the hardest part \\n' externalfile.write(what_to_add) # add a string including the linefeed mylist = [1,2,3,4,5] # a list of numbers what_to_add = ','.join(map(repr, mylist)) + \"\\n\" # one way to write the list externalfile.write(what_to_add) what_to_add = ','.join(map(repr, mylist[0:len(mylist)])) + \"\\n\" # another way to write the list externalfile.write(what_to_add) externalfile.close() As before we can examine the contents using a shell command sent from the notebook. ! cat myfirstfile.txt # ! type myfirstfile.txt # Winderz message in a bottle I love rock-and-roll, put another dime in the jukebox baby ... ... the waiting is the hardest part 1,2,3,4,5 1,2,3,4,5","title":"Example: Update a file."},{"location":"lesson6/lesson6/#example-delete-a-file","text":"Delete can be done by a system call as we did above to clear the local directory In a JupyterLab notebook, we can either use import sys ! rm -rf myfirstfile.txt # delete file if it exists or import os os.remove(\"myfirstfile.txt\") they both have same effect, both equally dangerous to your filesystem. Learn more about CRUD with text files at https://www.guru99.com/reading-and-writing-files-in-python.html Learn more about file delete at https://www.dummies.com/programming/python/how-to-delete-a-file-in-python/ import os file2kill = \"myfirstfile.txt\" try: os.remove(file2kill) # file must exist or will generate an exception except: pass # example of using pass to improve readability print(file2kill, \" missing or deleted !\") myfirstfile.txt missing or deleted ! A little discussion on the part where we wrote numbers what_to_add = ','.join(map(repr, mylist[0:len(mylist)])) + \"\\n\" Here are descriptions of the two functions map and repr map(function, iterable, ...) Apply function to every item of iterable and return a list of the results. If additional iterable arguments are passed, function must take that many arguments and is applied to the items from all iterables in parallel. If one iterable is shorter than another it is assumed to be extended with None items. If function is None, the identity function is assumed; if there are multiple arguments, map() returns a list consisting of tuples containing the corresponding items from all iterables (a kind of transpose operation). The iterable arguments may be a sequence or any iterable object; the result is always a list. repr(object) Return a string containing a printable representation of an object. This is the same value yielded by conversions (reverse quotes). It is sometimes useful to be able to access this operation as an ordinary function. For many types, this function makes an attempt to return a string that would yield an object with the same value when passed to eval() , otherwise the representation is a string enclosed in angle brackets that contains the name of the type of the object together with additional information often including the name and address of the object. A class can control what this function returns for its instances by defining a repr() method. What they do in this script is important. The statement: what_to_add = \u2019,\u2019.join(map(repr, mylist[0:len(mylist)])) + \"\\n\" is building a string that will be comprised of elements of mylist[0:len(mylist)]. The repr() function gets these elements as they are represented in the computer, the delimiter a comma is added using the join method in Python, and because everything is now a string the ... + \"\\n\" puts a linefeed character at the end of the string so the output will start a new line the next time something is written.","title":"Example: Delete a file"},{"location":"lesson6/lesson6/#example","text":"create a text file, name it \"MyFavoriteQuotation\" . Write your favorite quotation in the file. Read the file. Add this string to it in a new line : \"And that's something I wish I had said...\" Show the final outcome. # create the \"My Favorite Quotation\" file: externalfile = open(\"MyFavoriteQuotation.txt\",'w') # create connection to file, set to write (w) myquotation = 'The path of the righteous man is beset on all sides by the inequities of the selfish and the tyranny of evil men. Blessed is he who, in the name of charity and good will, shepherds the weak through the valley of darkness. For he is truly his brother\u2019s keeper and the finder of lost children. And I will strike down upon thee with great vengeance and furious anger those who attempt to poison and destroy my brothers. And you will know my name is the Lord when I lay my vengeance upon you.' #My choice: quotation from Pulp Fiction externalfile.write(myquotation)# write the contents of mymessage to the file externalfile.close() # close the file connection #Let's read the file ! cat MyFavoriteQuotation.txt # Let's add the string externalfile = open(\"MyFavoriteQuotation.txt\",'a') #create connection to file, set to append (a) externalfile.write('\\n') # adds a newline character what_to_add = \"And that's something I wish I had said ... \\n\" externalfile.write(what_to_add) externalfile.close() #Let's read the file one last time ! cat MyFavoriteQuotation.txt # ! type MyFavoriteQuotation # Winderz The path of the righteous man is beset on all sides by the inequities of the selfish and the tyranny of evil men. Blessed is he who, in the name of charity and good will, shepherds the weak through the valley of darkness. For he is truly his brother\u2019s keeper and the finder of lost children. And I will strike down upon thee with great vengeance and furious anger those who attempt to poison and destroy my brothers. And you will know my name is the Lord when I lay my vengeance upon you.The path of the righteous man is beset on all sides by the inequities of the selfish and the tyranny of evil men. Blessed is he who, in the name of charity and good will, shepherds the weak through the valley of darkness. For he is truly his brother\u2019s keeper and the finder of lost children. And I will strike down upon thee with great vengeance and furious anger those who attempt to poison and destroy my brothers. And you will know my name is the Lord when I lay my vengeance upon you. And that's something I wish I had said ...","title":"Example"},{"location":"lesson6/lesson6/#references","text":"Overland, B. (2018). Python Without Fear. Addison-Wesley ISBN 978-0-13-468747-6. Grus, Joel (2015). Data Science from Scratch: First Principles with Python O\u2019Reilly Media. Kindle Edition. Precord, C. (2010) wxPython 2.8 Application Development Cookbook Packt Publishing Ltd. Birmingham , B27 6PA, UK ISBN 978-1-849511-78-0. # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty compthink /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"References"},{"location":"lesson7/lesson7/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 14 February 2021 Lesson 7 The Pandas module About Pandas How to install Anaconda JupyterHub/Lab (on Linux) JupyterHub/Lab (on MacOS) JupyterHub/Lab (on Windoze) The Dataframe Primatives Using Pandas Create, Modify, Delete datagrames Slice Dataframes Conditional Selection Synthetic Programming (Symbolic Function Application) Files Access Files from a remote Web Server Get file contents Get the actual file Adaptations for encrypted servers (future semester) Special Script Blocks %%html <!--Script block to left align Markdown Tables--> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} Objectives To understand the dataframe abstraction as implemented in the Pandas library(module). To be able to access and manipulate data within a dataframe To be able to obtain basic statistical measures of data within a dataframe Read/Write from/to files MS Excel-type files (.xls,.xlsx,.csv) (LibreOffice files use the MS .xml standard) Ordinary ASCII (.txt) files Access files directly from a URL (advanced concept) Using a wget-type function Using a curl-type function Using API keys (future versions) Pandas: Pandas is the core library for dataframe manipulation in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays. The library\u2019s name is derived from the term \u2018Panel Data\u2019. If you are curious about Pandas, this cheat sheet is recommended: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf Data Structure The Primary data structure is called a dataframe. It is an abstraction where data are represented as a 2-dimensional mutable and heterogenous tabular data structure; much like a Worksheet in MS Excel. The structure itself is popular among statisticians and data scientists and business executives. According to the marketing department \"Pandas Provides rich data structures and functions designed to make working with data fast, easy, and expressive. It is useful in data manipulation, cleaning, and analysis; Pandas excels in performance and productivity \" The Dataframe A data table is called a DataFrame in pandas (and other programming environments too). The figure below from https://pandas.pydata.org/docs/getting_started/index.html illustrates a dataframe model: Each column and each row in a dataframe is called a series, the header row, and index column are special. Like MS Excel we can query the dataframe to find the contents of a particular cell using its row name and column name , or operate on entire rows and columns To use pandas, we need to import the module. Computational Thinking Concepts The CT concepts expressed within Pandas include: Decomposition : Data interpretation, manipulation, and analysis of Pandas dataframes is an act of decomposition -- although the dataframes can be quite complex. Abstraction : The dataframe is a data representation abstraction that allows for placeholder operations, later substituted with specific contents for a problem; enhances reuse and readability. We leverage the principle of algebraic replacement using these abstractions. Algorithms : Data interpretation, manipulation, and analysis of dataframes are generally implemented as part of a supervisory algorithm. Module Set-Up In principle, Pandas should be available in a default Anaconda install - You should not have to do any extra installation steps to install the library in Python - You do have to import the library in your scripts How to check - Simply open a code cell and run import pandas if the notebook does not protest (i.e. pink block of error), the youis good to go. import pandas If you do get an error, that means that you will have to install using conda or pip ; you are on-your-own here! On the content server the process is: Open a new terminal from the launcher Change to root user su then enter the root password sudo -H /opt/jupyterhib/bin/python3 -m pip install pandas Wait until the install is complete; for security, user compthink is not in the sudo group Verify the install by trying to execute import pandas as above. The process above will be similar on a Macintosh, or Windows if you did not use an Anaconda distribution. Best is to have a sucessful anaconda install, or go to the GoodJobUntilMyOrgansGetHarvested . If you have to do this kind of install, you will have to do some reading, some references I find useful are: 1. https://jupyterlab.readthedocs.io/en/stable/user/extensions.html 2. https://www.pugetsystems.com/labs/hpc/Note-How-To-Install-JupyterHub-on-a-Local-Server-1673/#InstallJupyterHub 3. https://jupyterhub.readthedocs.io/en/stable/installation-guide-hard.html (This is the approach on the content server which has a functioning JupyterHub) Dataframe-type Structure using primative python First lets construct a dataframe like object using python primatives. We will construct 3 lists, one for row names, one for column names, and one for the content. import numpy mytabular = numpy.random.randint(1,100,(5,4)) myrowname = ['A','B','C','D','E'] mycolname = ['W','X','Y','Z'] mytable = [['' for jcol in range(len(mycolname)+1)] for irow in range(len(myrowname)+1)] #non-null destination matrix, note the implied loop construction The above builds a placeholder named mytable for the psuedo-dataframe. Next we populate the table, using a for loop to write the column names in the first row, row names in the first column, and the table fill for the rest of the table. for irow in range(1,len(myrowname)+1): # write the row names mytable[irow][0]=myrowname[irow-1] for jcol in range(1,len(mycolname)+1): # write the column names mytable[0][jcol]=mycolname[jcol-1] for irow in range(1,len(myrowname)+1): # fill the table (note the nested loop) for jcol in range(1,len(mycolname)+1): mytable[irow][jcol]=mytabular[irow-1][jcol-1] Now lets print the table out by row and we see we have a very dataframe-like structure for irow in range(0,len(myrowname)+1): print(mytable[irow][0:len(mycolname)+1]) ['', 'W', 'X', 'Y', 'Z'] ['A', 19, 21, 22, 81] ['B', 94, 75, 66, 44] ['C', 70, 56, 47, 63] ['D', 56, 80, 39, 39] ['E', 66, 78, 39, 15] We can also query by row print(mytable[3][0:len(mycolname)+1]) ['C', 70, 56, 47, 63] Or by column for irow in range(0,len(myrowname)+1): #cannot use implied loop in a column slice print(mytable[irow][2]) X 21 75 56 80 78 Or by row+column index; sort of looks like a spreadsheet syntax. print(' ',mytable[0][3]) print(mytable[3][0],mytable[3][3]) Y C 47 Now we shall create a proper dataframe We will now do the same using pandas mydf = pandas.DataFrame(numpy.random.randint(1,100,(5,4)), ['A','B','C','D','E'], ['W','X','Y','Z']) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 C 75 67 52 82 D 92 83 90 28 E 80 67 4 24 We can also turn our table into a dataframe, notice how the constructor adds header row and index column mydf1 = pandas.DataFrame(mytable) mydf1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 0 W X Y Z 1 A 19 21 22 81 2 B 94 75 66 44 3 C 70 56 47 63 4 D 56 80 39 39 5 E 66 78 39 15 To get proper behavior, we can just reuse our original objects mydf2 = pandas.DataFrame(mytabular,myrowname,mycolname) mydf2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 19 21 22 81 B 94 75 66 44 C 70 56 47 63 D 56 80 39 39 E 66 78 39 15 Why are mydf and mydf2 different? Getting the shape of dataframes The shape method, which is available after the dataframe is constructed, will return the row and column rank (count) of a dataframe. mydf.shape (5, 4) mydf1.shape (6, 5) mydf2.shape (5, 4) Appending new columns To append a column simply assign a value to a new column name to the dataframe mydf['new']= 'NA' mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 97 20 61 35 NA B 74 8 7 99 NA C 75 67 52 82 NA D 92 83 90 28 NA E 80 67 4 24 NA Appending new rows This is sometimes a bit trickier but here is one way: - create a copy of a row, give it a new name. - concatenate it back into the dataframe. newrow = mydf.loc[['E']].rename(index={\"E\": \"X\"}) # create a single row, rename the index newtable = pandas.concat([mydf,newrow]) # concatenate the row to bottom of df - note the syntax newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 97 20 61 35 NA B 74 8 7 99 NA C 75 67 52 82 NA D 92 83 90 28 NA E 80 67 4 24 NA X 80 67 4 24 NA Removing Rows and Columns To remove a column is straightforward, we use the drop method newtable.drop('new', axis=1, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 C 75 67 52 82 D 92 83 90 28 E 80 67 4 24 X 80 67 4 24 To remove a row, you really got to want to, easiest is probablty to create a new dataframe with the row removed newtable = newtable.loc[['A','B','D','E','X']] # select all rows except C newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 D 92 83 90 28 E 80 67 4 24 X 80 67 4 24 # or just use drop with axis specify newtable.drop('X', axis=0, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 D 92 83 90 28 E 80 67 4 24 Indexing We have already been indexing, but a few examples follow: newtable['X'] #Selecing a single column A 20 B 8 D 83 E 67 Name: X, dtype: int64 newtable[['X','W']] #Selecing a multiple columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X W A 20 97 B 8 74 D 83 92 E 67 80 newtable.loc['E'] #Selecing rows based on label via loc[ ] indexer W 80 X 67 Y 4 Z 24 Name: E, dtype: int64 newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 D 92 83 90 28 E 80 67 4 24 newtable.loc[['E','D','B']] #Selecing multiple rows based on label via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z E 80 67 4 24 D 92 83 90 28 B 74 8 7 99 newtable.loc[['B','E','D'],['X','Y']] #Selecting elements via both rows and columns via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X Y B 8 7 E 67 4 D 83 90 Conditional Selection mydf = pandas.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach #What fruit corresponds to the number 555 in \u2018col2\u2019? mydf[mydf['col2']==555]['col3'] 1 apple Name: col3, dtype: object #What fruit corresponds to the minimum number in \u2018col2\u2019? mydf[mydf['col2']==mydf['col2'].min()]['col3'] 5 watermelon Name: col3, dtype: object Descriptor Functions #Creating a dataframe from a dictionary mydf = pandas.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach head method Returns the first few rows, useful to infer structure #Returns only the first five rows mydf.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit info method Returns the data model (data column count, names, data types) #Info about the dataframe mydf.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 8 entries, 0 to 7 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 col1 8 non-null int64 1 col2 8 non-null int64 2 col3 8 non-null object dtypes: int64(2), object(1) memory usage: 320.0+ bytes describe method Returns summary statistics of each numeric column. Also returns the minimum and maximum value in each column, and the IQR (Interquartile Range). Again useful to understand structure of the columns. #Statistics of the dataframe mydf.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 count 8.00000 8.0000 mean 4.50000 416.2500 std 2.44949 211.8576 min 1.00000 111.0000 25% 2.75000 222.0000 50% 4.50000 444.0000 75% 6.25000 582.7500 max 8.00000 666.0000 Counting and Sum methods There are also methods for counts and sums by specific columns mydf['col2'].sum() #Sum of a specified column 3330 The unique method returns a list of unique values (filters out duplicates in the list, underlying dataframe is preserved) mydf['col2'].unique() #Returns the list of unique values along the indexed column array([444, 555, 666, 111, 222]) The nunique method returns a count of unique values mydf['col2'].nunique() #Returns the total number of unique values along the indexed column 5 The value_counts() method returns the count of each unique value (kind of like a histogram, but each value is the bin) mydf['col2'].value_counts() #Returns the number of occurences of each unique value 222 2 444 2 666 2 111 1 555 1 Name: col2, dtype: int64 Using functions in dataframes - symbolic apply The power of Pandas is an ability to apply a function to each element of a dataframe series (or a whole frame) by a technique called symbolic (or synthetic programming) application of the function. This employs principles of pattern matching , abstraction , and algorithm development ; a holy trinity of Computational Thinning. It's somewhat complicated but quite handy, best shown by an example: def times2(x): # A prototype function to scalar multiply an object x by 2 return(x*2) print(mydf) print('Apply the times2 function to col2') mydf['col2'].apply(times2) #Symbolic apply the function to each element of column col2, result is another dataframe col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach Apply the times2 function to col2 0 888 1 1110 2 1332 3 888 4 1332 5 222 6 444 7 444 Name: col2, dtype: int64 Sorts mydf.sort_values('col2', ascending = True) #Sorting based on columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 5 6 111 watermelon 6 7 222 banana 7 8 222 peach 0 1 444 orange 3 4 444 mango 1 2 555 apple 2 3 666 grape 4 5 666 jackfruit mydf.sort_values('col3', ascending = True) #Lexiographic sort .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 1 2 555 apple 6 7 222 banana 2 3 666 grape 4 5 666 jackfruit 3 4 444 mango 0 1 444 orange 7 8 222 peach 5 6 111 watermelon Aggregating (Grouping Values) dataframe contents #Creating a dataframe from a dictionary data = { 'key' : ['A', 'B', 'C', 'A', 'B', 'C'], 'data1' : [1, 2, 3, 4, 5, 6], 'data2' : [10, 11, 12, 13, 14, 15], 'data3' : [20, 21, 22, 13, 24, 25] } mydf1 = pandas.DataFrame(data) mydf1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 data3 0 A 1 10 20 1 B 2 11 21 2 C 3 12 22 3 A 4 13 13 4 B 5 14 24 5 C 6 15 25 # Grouping and summing values in all the columns based on the column 'key' mydf1.groupby('key').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 data3 key A 5 23 33 B 7 25 45 C 9 27 47 # Grouping and summing values in the selected columns based on the column 'key' mydf1.groupby('key')[['data1', 'data2']].sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key A 5 23 B 7 25 C 9 27 Filtering out missing values Filtering and cleaning are often used to describe the process where data that does not support a narrative is removed ;typically for maintenance of profit applications, if the data are actually missing that is common situation where cleaning is justified. #Creating a dataframe from a dictionary df = pandas.DataFrame({'col1':[1,2,3,4,None,6,7,None], 'col2':[444,555,None,444,666,111,None,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 NaN grape 3 4.0 444.0 mango 4 NaN 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 NaN banana 7 NaN 222.0 peach Below we drop any row that contains a NaN code. df_dropped = df.dropna() df_dropped .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 3 4.0 444.0 mango 5 6.0 111.0 watermelon Below we replace NaN codes with some value, in this case 0 df_filled1 = df.fillna(0) df_filled1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 0.0 grape 3 4.0 444.0 mango 4 0.0 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 0.0 banana 7 0.0 222.0 peach Below we replace NaN codes with some value, in this case the mean value of of the column in which the missing value code resides. df_filled2 = df.fillna(df.mean()) df_filled2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.000000 444.0 orange 1 2.000000 555.0 apple 2 3.000000 407.0 grape 3 4.000000 444.0 mango 4 3.833333 666.0 jackfruit 5 6.000000 111.0 watermelon 6 7.000000 407.0 banana 7 3.833333 222.0 peach Reading a File into a Dataframe Pandas has methods to read common file types, such as csv , xlsx , and json . Ordinary text files are also quite manageable. On a machine you control you can write script to retrieve files from the internet and process them. readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') #Reading a .csv file print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 Similar to reading and writing .csv files, you can also read and write .xslx files as below (useful to know this) # xlsx reads deprecated here is a hack using openpyxl readfileexcel = pandas.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') #Reading a .xlsx file print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 Writing a dataframe to file #Creating and writing to a .csv file readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile1.csv') readfilecsv = pandas.read_csv('CSV_WritingFile1.csv') print(readfilecsv) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 #Creating and writing to a .csv file by excluding row labels readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile2.csv', index = False) readfilecsv = pandas.read_csv('CSV_WritingFile2.csv') print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 #Creating and writing to a .xlsx file readfileexcel = pandas.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') readfileexcel.to_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', index = False, engine='openpyxl') readfileexcel = pandas.read_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', engine='openpyxl') print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 Downloading files from websites (optional) This section shows how to get files from a remote computer. There are several ways to get the files, most importantly you need the FQDN to the file. Method 1: Get data from a file on a remote server (unencrypted) This section shows how to obtain data files from public URLs. Prerequesites: You know the FQDN to the file it will be in structure of \"http://server-name/.../filename.ext\" The server is running ordinary (unencrypted) web services, i.e. http://... Web Developer Notes If you want to distribute files (web developers) the files need to be in the server webroot, but can be deep into the heirarchial structure. Here we will do an example with a file that contains topographic data in XYZ format, without header information. The first few lines of the remote file look like: 74.90959724 93.21251922 0 75.17907367 64.40278759 0 94.9935575 93.07951286 0 95.26234119 64.60091165 0 54.04976655 64.21159095 0 54.52914363 35.06934342 0 75.44993558 34.93079513 0 75.09317373 5.462959114 0 74.87357468 10.43130083 0 74.86249082 15.72938748 0 And importantly it is tab delimited. The module to manipulate url in python is called urllib Google search to learn more, here we are using only a small component without exception trapping. #Step 1: import needed modules to interact with the internet from urllib.request import urlopen # import a method that will connect to a url and read file contents import pandas #import pandas This next code fragment sets a string called remote_url ; it is just a variable, name can be anything that honors python naming rules. Then the urllib function urlopen with read and decode methods is employed, the result is stored in an object named elevationXYZ #Step 2: make the connection to the remote file (actually its implementing \"bash curl -O http://fqdn/path ...\") remote_url = 'http://www.rtfmps.com/share_files/pip-corner-sumps.txt' # elevationXYZ = urlopen(remote_url).read().decode().split() # Gets the file contents as a single vector, comma delimited, file is not retained locally At this point the object exists as a single vector with hundreds of elements. We now need to structure the content. Here using python primatives, and knowing how the data are supposed to look, we prepare variables to recieve the structured results #Step 3 Python primatives to structure the data, or use fancy modules (probably easy in numpy) howmany = len(elevationXYZ) # how long is the vector? nrow = int(howmany/3) xyz = [[0 for j in range(3)] for j in range(nrow)] # null space to receive data define columnX Now that everything is ready, we can extract from the object the values we want into xyz #Step4 Now will build xyz as a matrix with 3 columns index = 0 for irow in range(0,nrow): xyz[irow][0]=float(elevationXYZ[index]) xyz[irow][1]=float(elevationXYZ[index+1]) xyz[irow][2]=float(elevationXYZ[index+2]) index += 3 #increment the index xyz is now a 3-column float array and can now probably be treated as a data frame. Here we use a pandas method to build the dataframe. df = pandas.DataFrame(xyz) Get some info, yep three columns (ordered triples to be precise!) df.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 774 entries, 0 to 773 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 0 774 non-null float64 1 1 774 non-null float64 2 2 774 non-null float64 dtypes: float64(3) memory usage: 18.3 KB And some summary statistics (meaningless for these data), but now have taken data from the internet and prepared it for analysis. df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 count 774.000000 774.000000 774.000000 mean 52.064621 48.770060 2.364341 std 30.883400 32.886277 1.497413 min -2.113554 -11.360960 0.000000 25% 25.640786 21.809579 2.000000 50% 55.795821 49.059950 2.000000 75% 76.752290 75.015933 4.000000 max 111.726727 115.123931 4.000000 And lets look at the first few rows df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 74.909597 93.212519 0.0 1 75.179074 64.402788 0.0 2 94.993557 93.079513 0.0 3 95.262341 64.600912 0.0 4 54.049767 64.211591 0.0 Method 2: Get the actual file from a remote web server (unencrypted) You know the FQDN to the file it will be in structure of \"http://server-name/.../filename.ext\" The server is running ordinary (unencrypted) web services, i.e. http://... We will need a module to interface with the remote server, in this example lets use something different than urllib . Here we will use requests , so first we load the module import requests # Module to process http/https requests Now we will generate a GET request to the remote http server. I chose to do so using a variable to store the remote URL so I can reuse code in future projects. The GET request (an http/https method) is generated with the requests method get and assigned to an object named rget -- the name is arbitrary. Next we extract the file from the rget object and write it to a local file with the name of the remote file - esentially automating the download process. Then we import the pandas module. remote_url=\"http://54.243.252.9/engr-1330-psuedo-course/MyJupyterNotebooks/42-DataScience-EvaporationAnalysis/all_quads_gross_evaporation.csv\" # set the url rget = requests.get(remote_url, allow_redirects=True) # get the remote resource, follow imbedded links open('all_quads_gross_evaporation.csv','wb').write(rget.content) # extract from the remote the contents, assign to a local file same name import pandas as pd # Module to process dataframes (not absolutely needed but somewhat easier than using primatives, and gives graphing tools) # verify file exists ! pwd ! ls -la /home/sensei/1330-textbook-webroot/docs/lesson7 total 1412 drwxrwxr-x 3 sensei sensei 4096 Feb 16 20:57 . drwxr-xr-x 10 sensei sensei 4096 Feb 16 20:30 .. drwxrwxr-x 2 sensei sensei 4096 Feb 16 20:53 .ipynb_checkpoints -rw-rw-r-- 1 sensei sensei 21150 Feb 15 15:58 01-table-dataframe.png -rw-rw-r-- 1 sensei sensei 51 Feb 15 15:58 CSV_ReadingFile.csv -rw-rw-r-- 1 sensei sensei 55 Feb 16 20:59 CSV_WritingFile1.csv -rw-rw-r-- 1 sensei sensei 46 Feb 16 20:59 CSV_WritingFile2.csv -rw-rw-r-- 1 sensei sensei 693687 Feb 15 15:58 ENGR-1330-Lesson8-Dev.html -rw-rw-r-- 1 sensei sensei 166938 Feb 15 15:58 ENGR-1330-Lesson8-Dev.ipynb -rw-rw-r-- 1 sensei sensei 5508 Feb 15 15:58 Excel_ReadingFile.xlsx -rw-rw-r-- 1 sensei sensei 5041 Feb 16 20:59 Excel_WritingFile.xlsx -rw-rw-r-- 1 sensei sensei 363498 Feb 16 20:59 all_quads_gross_evaporation.csv -rw-rw-r-- 1 sensei sensei 108222 Feb 16 20:57 lesson7.ipynb -rw-rw-r-- 1 sensei sensei 40566 Feb 15 15:58 output_126_1.png Now we can read the file contents and check its structure, before proceeding. evapdf = pd.read_csv(\"all_quads_gross_evaporation.csv\",parse_dates=[\"YYYY-MM\"]) # Read the file as a .CSV assign to a dataframe evapdf evapdf.head() # check structure .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } YYYY-MM 104 105 106 107 108 204 205 206 207 ... 911 912 1008 1009 1010 1011 1108 1109 1110 1210 0 1954-01-01 1.80 1.80 2.02 2.24 2.24 2.34 1.89 1.80 1.99 ... 1.42 1.30 2.50 2.42 1.94 1.29 2.59 2.49 2.22 2.27 1 1954-02-01 4.27 4.27 4.13 3.98 3.90 4.18 4.26 4.27 4.26 ... 2.59 2.51 4.71 4.30 3.84 2.50 5.07 4.62 4.05 4.18 2 1954-03-01 4.98 4.98 4.62 4.25 4.20 5.01 4.98 4.98 4.68 ... 3.21 3.21 6.21 6.06 5.02 3.21 6.32 6.20 5.68 5.70 3 1954-04-01 6.09 5.94 5.94 6.07 5.27 6.31 5.98 5.89 5.72 ... 3.83 3.54 6.45 6.25 4.92 3.54 6.59 6.44 5.88 5.95 4 1954-05-01 5.41 5.09 5.14 4.40 3.61 5.57 4.56 4.47 4.18 ... 3.48 3.97 7.92 8.13 6.31 3.99 7.75 7.98 7.40 7.40 5 rows \u00d7 93 columns Structure looks like a spreadsheet as expected; lets plot the time series for cell '911' evapdf.plot.line(x='YYYY-MM',y='911') # Plot quadrant 911 evaporation time series <AxesSubplot:xlabel='YYYY-MM'> Method 3: Get the actual file from an encrypted server This section is saved for future semesters References Overland, B. (2018). Python Without Fear. Addison-Wesley ISBN 978-0-13-468747-6. Grus, Joel (2015). Data Science from Scratch: First Principles with Python O\u2019Reilly Media. Kindle Edition. Precord, C. (2010) wxPython 2.8 Application Development Cookbook Packt Publishing Ltd. Birmingham , B27 6PA, UK ISBN 978-1-849511-78-0. # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Lesson 7"},{"location":"lesson7/lesson7/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 14 February 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson7/lesson7/#lesson-7-the-pandas-module","text":"About Pandas How to install Anaconda JupyterHub/Lab (on Linux) JupyterHub/Lab (on MacOS) JupyterHub/Lab (on Windoze) The Dataframe Primatives Using Pandas Create, Modify, Delete datagrames Slice Dataframes Conditional Selection Synthetic Programming (Symbolic Function Application) Files Access Files from a remote Web Server Get file contents Get the actual file Adaptations for encrypted servers (future semester)","title":"Lesson 7 The Pandas module"},{"location":"lesson7/lesson7/#special-script-blocks","text":"%%html <!--Script block to left align Markdown Tables--> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;}","title":"Special Script Blocks"},{"location":"lesson7/lesson7/#objectives","text":"To understand the dataframe abstraction as implemented in the Pandas library(module). To be able to access and manipulate data within a dataframe To be able to obtain basic statistical measures of data within a dataframe Read/Write from/to files MS Excel-type files (.xls,.xlsx,.csv) (LibreOffice files use the MS .xml standard) Ordinary ASCII (.txt) files Access files directly from a URL (advanced concept) Using a wget-type function Using a curl-type function Using API keys (future versions)","title":"Objectives"},{"location":"lesson7/lesson7/#pandas","text":"Pandas is the core library for dataframe manipulation in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays. The library\u2019s name is derived from the term \u2018Panel Data\u2019. If you are curious about Pandas, this cheat sheet is recommended: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf","title":"Pandas:"},{"location":"lesson7/lesson7/#data-structure","text":"The Primary data structure is called a dataframe. It is an abstraction where data are represented as a 2-dimensional mutable and heterogenous tabular data structure; much like a Worksheet in MS Excel. The structure itself is popular among statisticians and data scientists and business executives. According to the marketing department \"Pandas Provides rich data structures and functions designed to make working with data fast, easy, and expressive. It is useful in data manipulation, cleaning, and analysis; Pandas excels in performance and productivity \"","title":"Data Structure"},{"location":"lesson7/lesson7/#the-dataframe","text":"A data table is called a DataFrame in pandas (and other programming environments too). The figure below from https://pandas.pydata.org/docs/getting_started/index.html illustrates a dataframe model: Each column and each row in a dataframe is called a series, the header row, and index column are special. Like MS Excel we can query the dataframe to find the contents of a particular cell using its row name and column name , or operate on entire rows and columns To use pandas, we need to import the module.","title":"The Dataframe"},{"location":"lesson7/lesson7/#computational-thinking-concepts","text":"The CT concepts expressed within Pandas include: Decomposition : Data interpretation, manipulation, and analysis of Pandas dataframes is an act of decomposition -- although the dataframes can be quite complex. Abstraction : The dataframe is a data representation abstraction that allows for placeholder operations, later substituted with specific contents for a problem; enhances reuse and readability. We leverage the principle of algebraic replacement using these abstractions. Algorithms : Data interpretation, manipulation, and analysis of dataframes are generally implemented as part of a supervisory algorithm.","title":"Computational Thinking Concepts"},{"location":"lesson7/lesson7/#module-set-up","text":"In principle, Pandas should be available in a default Anaconda install - You should not have to do any extra installation steps to install the library in Python - You do have to import the library in your scripts How to check - Simply open a code cell and run import pandas if the notebook does not protest (i.e. pink block of error), the youis good to go. import pandas If you do get an error, that means that you will have to install using conda or pip ; you are on-your-own here! On the content server the process is: Open a new terminal from the launcher Change to root user su then enter the root password sudo -H /opt/jupyterhib/bin/python3 -m pip install pandas Wait until the install is complete; for security, user compthink is not in the sudo group Verify the install by trying to execute import pandas as above. The process above will be similar on a Macintosh, or Windows if you did not use an Anaconda distribution. Best is to have a sucessful anaconda install, or go to the GoodJobUntilMyOrgansGetHarvested . If you have to do this kind of install, you will have to do some reading, some references I find useful are: 1. https://jupyterlab.readthedocs.io/en/stable/user/extensions.html 2. https://www.pugetsystems.com/labs/hpc/Note-How-To-Install-JupyterHub-on-a-Local-Server-1673/#InstallJupyterHub 3. https://jupyterhub.readthedocs.io/en/stable/installation-guide-hard.html (This is the approach on the content server which has a functioning JupyterHub)","title":"Module Set-Up"},{"location":"lesson7/lesson7/#dataframe-type-structure-using-primative-python","text":"First lets construct a dataframe like object using python primatives. We will construct 3 lists, one for row names, one for column names, and one for the content. import numpy mytabular = numpy.random.randint(1,100,(5,4)) myrowname = ['A','B','C','D','E'] mycolname = ['W','X','Y','Z'] mytable = [['' for jcol in range(len(mycolname)+1)] for irow in range(len(myrowname)+1)] #non-null destination matrix, note the implied loop construction The above builds a placeholder named mytable for the psuedo-dataframe. Next we populate the table, using a for loop to write the column names in the first row, row names in the first column, and the table fill for the rest of the table. for irow in range(1,len(myrowname)+1): # write the row names mytable[irow][0]=myrowname[irow-1] for jcol in range(1,len(mycolname)+1): # write the column names mytable[0][jcol]=mycolname[jcol-1] for irow in range(1,len(myrowname)+1): # fill the table (note the nested loop) for jcol in range(1,len(mycolname)+1): mytable[irow][jcol]=mytabular[irow-1][jcol-1] Now lets print the table out by row and we see we have a very dataframe-like structure for irow in range(0,len(myrowname)+1): print(mytable[irow][0:len(mycolname)+1]) ['', 'W', 'X', 'Y', 'Z'] ['A', 19, 21, 22, 81] ['B', 94, 75, 66, 44] ['C', 70, 56, 47, 63] ['D', 56, 80, 39, 39] ['E', 66, 78, 39, 15] We can also query by row print(mytable[3][0:len(mycolname)+1]) ['C', 70, 56, 47, 63] Or by column for irow in range(0,len(myrowname)+1): #cannot use implied loop in a column slice print(mytable[irow][2]) X 21 75 56 80 78 Or by row+column index; sort of looks like a spreadsheet syntax. print(' ',mytable[0][3]) print(mytable[3][0],mytable[3][3]) Y C 47","title":"Dataframe-type Structure using primative python"},{"location":"lesson7/lesson7/#now-we-shall-create-a-proper-dataframe","text":"We will now do the same using pandas mydf = pandas.DataFrame(numpy.random.randint(1,100,(5,4)), ['A','B','C','D','E'], ['W','X','Y','Z']) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 C 75 67 52 82 D 92 83 90 28 E 80 67 4 24 We can also turn our table into a dataframe, notice how the constructor adds header row and index column mydf1 = pandas.DataFrame(mytable) mydf1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 0 W X Y Z 1 A 19 21 22 81 2 B 94 75 66 44 3 C 70 56 47 63 4 D 56 80 39 39 5 E 66 78 39 15 To get proper behavior, we can just reuse our original objects mydf2 = pandas.DataFrame(mytabular,myrowname,mycolname) mydf2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 19 21 22 81 B 94 75 66 44 C 70 56 47 63 D 56 80 39 39 E 66 78 39 15 Why are mydf and mydf2 different?","title":"Now we shall create a proper dataframe"},{"location":"lesson7/lesson7/#getting-the-shape-of-dataframes","text":"The shape method, which is available after the dataframe is constructed, will return the row and column rank (count) of a dataframe. mydf.shape (5, 4) mydf1.shape (6, 5) mydf2.shape (5, 4)","title":"Getting the shape of dataframes"},{"location":"lesson7/lesson7/#appending-new-columns","text":"To append a column simply assign a value to a new column name to the dataframe mydf['new']= 'NA' mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 97 20 61 35 NA B 74 8 7 99 NA C 75 67 52 82 NA D 92 83 90 28 NA E 80 67 4 24 NA","title":"Appending new columns"},{"location":"lesson7/lesson7/#appending-new-rows","text":"This is sometimes a bit trickier but here is one way: - create a copy of a row, give it a new name. - concatenate it back into the dataframe. newrow = mydf.loc[['E']].rename(index={\"E\": \"X\"}) # create a single row, rename the index newtable = pandas.concat([mydf,newrow]) # concatenate the row to bottom of df - note the syntax newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 97 20 61 35 NA B 74 8 7 99 NA C 75 67 52 82 NA D 92 83 90 28 NA E 80 67 4 24 NA X 80 67 4 24 NA","title":"Appending new rows"},{"location":"lesson7/lesson7/#removing-rows-and-columns","text":"To remove a column is straightforward, we use the drop method newtable.drop('new', axis=1, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 C 75 67 52 82 D 92 83 90 28 E 80 67 4 24 X 80 67 4 24 To remove a row, you really got to want to, easiest is probablty to create a new dataframe with the row removed newtable = newtable.loc[['A','B','D','E','X']] # select all rows except C newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 D 92 83 90 28 E 80 67 4 24 X 80 67 4 24 # or just use drop with axis specify newtable.drop('X', axis=0, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 D 92 83 90 28 E 80 67 4 24","title":"Removing Rows and Columns"},{"location":"lesson7/lesson7/#indexing","text":"We have already been indexing, but a few examples follow: newtable['X'] #Selecing a single column A 20 B 8 D 83 E 67 Name: X, dtype: int64 newtable[['X','W']] #Selecing a multiple columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X W A 20 97 B 8 74 D 83 92 E 67 80 newtable.loc['E'] #Selecing rows based on label via loc[ ] indexer W 80 X 67 Y 4 Z 24 Name: E, dtype: int64 newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 97 20 61 35 B 74 8 7 99 D 92 83 90 28 E 80 67 4 24 newtable.loc[['E','D','B']] #Selecing multiple rows based on label via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z E 80 67 4 24 D 92 83 90 28 B 74 8 7 99 newtable.loc[['B','E','D'],['X','Y']] #Selecting elements via both rows and columns via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X Y B 8 7 E 67 4 D 83 90","title":"Indexing"},{"location":"lesson7/lesson7/#conditional-selection","text":"mydf = pandas.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach #What fruit corresponds to the number 555 in \u2018col2\u2019? mydf[mydf['col2']==555]['col3'] 1 apple Name: col3, dtype: object #What fruit corresponds to the minimum number in \u2018col2\u2019? mydf[mydf['col2']==mydf['col2'].min()]['col3'] 5 watermelon Name: col3, dtype: object","title":"Conditional Selection"},{"location":"lesson7/lesson7/#descriptor-functions","text":"#Creating a dataframe from a dictionary mydf = pandas.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach","title":"Descriptor Functions"},{"location":"lesson7/lesson7/#head-method","text":"Returns the first few rows, useful to infer structure #Returns only the first five rows mydf.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit","title":"head method"},{"location":"lesson7/lesson7/#info-method","text":"Returns the data model (data column count, names, data types) #Info about the dataframe mydf.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 8 entries, 0 to 7 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 col1 8 non-null int64 1 col2 8 non-null int64 2 col3 8 non-null object dtypes: int64(2), object(1) memory usage: 320.0+ bytes","title":"info method"},{"location":"lesson7/lesson7/#describe-method","text":"Returns summary statistics of each numeric column. Also returns the minimum and maximum value in each column, and the IQR (Interquartile Range). Again useful to understand structure of the columns. #Statistics of the dataframe mydf.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 count 8.00000 8.0000 mean 4.50000 416.2500 std 2.44949 211.8576 min 1.00000 111.0000 25% 2.75000 222.0000 50% 4.50000 444.0000 75% 6.25000 582.7500 max 8.00000 666.0000","title":"describe method"},{"location":"lesson7/lesson7/#counting-and-sum-methods","text":"There are also methods for counts and sums by specific columns mydf['col2'].sum() #Sum of a specified column 3330 The unique method returns a list of unique values (filters out duplicates in the list, underlying dataframe is preserved) mydf['col2'].unique() #Returns the list of unique values along the indexed column array([444, 555, 666, 111, 222]) The nunique method returns a count of unique values mydf['col2'].nunique() #Returns the total number of unique values along the indexed column 5 The value_counts() method returns the count of each unique value (kind of like a histogram, but each value is the bin) mydf['col2'].value_counts() #Returns the number of occurences of each unique value 222 2 444 2 666 2 111 1 555 1 Name: col2, dtype: int64","title":"Counting and Sum methods"},{"location":"lesson7/lesson7/#using-functions-in-dataframes-symbolic-apply","text":"The power of Pandas is an ability to apply a function to each element of a dataframe series (or a whole frame) by a technique called symbolic (or synthetic programming) application of the function. This employs principles of pattern matching , abstraction , and algorithm development ; a holy trinity of Computational Thinning. It's somewhat complicated but quite handy, best shown by an example: def times2(x): # A prototype function to scalar multiply an object x by 2 return(x*2) print(mydf) print('Apply the times2 function to col2') mydf['col2'].apply(times2) #Symbolic apply the function to each element of column col2, result is another dataframe col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach Apply the times2 function to col2 0 888 1 1110 2 1332 3 888 4 1332 5 222 6 444 7 444 Name: col2, dtype: int64","title":"Using functions in dataframes - symbolic apply"},{"location":"lesson7/lesson7/#sorts","text":"mydf.sort_values('col2', ascending = True) #Sorting based on columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 5 6 111 watermelon 6 7 222 banana 7 8 222 peach 0 1 444 orange 3 4 444 mango 1 2 555 apple 2 3 666 grape 4 5 666 jackfruit mydf.sort_values('col3', ascending = True) #Lexiographic sort .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 1 2 555 apple 6 7 222 banana 2 3 666 grape 4 5 666 jackfruit 3 4 444 mango 0 1 444 orange 7 8 222 peach 5 6 111 watermelon","title":"Sorts"},{"location":"lesson7/lesson7/#aggregating-grouping-values-dataframe-contents","text":"#Creating a dataframe from a dictionary data = { 'key' : ['A', 'B', 'C', 'A', 'B', 'C'], 'data1' : [1, 2, 3, 4, 5, 6], 'data2' : [10, 11, 12, 13, 14, 15], 'data3' : [20, 21, 22, 13, 24, 25] } mydf1 = pandas.DataFrame(data) mydf1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 data3 0 A 1 10 20 1 B 2 11 21 2 C 3 12 22 3 A 4 13 13 4 B 5 14 24 5 C 6 15 25 # Grouping and summing values in all the columns based on the column 'key' mydf1.groupby('key').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 data3 key A 5 23 33 B 7 25 45 C 9 27 47 # Grouping and summing values in the selected columns based on the column 'key' mydf1.groupby('key')[['data1', 'data2']].sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key A 5 23 B 7 25 C 9 27","title":"Aggregating (Grouping Values) dataframe contents"},{"location":"lesson7/lesson7/#filtering-out-missing-values","text":"Filtering and cleaning are often used to describe the process where data that does not support a narrative is removed ;typically for maintenance of profit applications, if the data are actually missing that is common situation where cleaning is justified. #Creating a dataframe from a dictionary df = pandas.DataFrame({'col1':[1,2,3,4,None,6,7,None], 'col2':[444,555,None,444,666,111,None,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 NaN grape 3 4.0 444.0 mango 4 NaN 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 NaN banana 7 NaN 222.0 peach Below we drop any row that contains a NaN code. df_dropped = df.dropna() df_dropped .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 3 4.0 444.0 mango 5 6.0 111.0 watermelon Below we replace NaN codes with some value, in this case 0 df_filled1 = df.fillna(0) df_filled1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 0.0 grape 3 4.0 444.0 mango 4 0.0 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 0.0 banana 7 0.0 222.0 peach Below we replace NaN codes with some value, in this case the mean value of of the column in which the missing value code resides. df_filled2 = df.fillna(df.mean()) df_filled2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.000000 444.0 orange 1 2.000000 555.0 apple 2 3.000000 407.0 grape 3 4.000000 444.0 mango 4 3.833333 666.0 jackfruit 5 6.000000 111.0 watermelon 6 7.000000 407.0 banana 7 3.833333 222.0 peach","title":"Filtering out missing values"},{"location":"lesson7/lesson7/#reading-a-file-into-a-dataframe","text":"Pandas has methods to read common file types, such as csv , xlsx , and json . Ordinary text files are also quite manageable. On a machine you control you can write script to retrieve files from the internet and process them. readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') #Reading a .csv file print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 Similar to reading and writing .csv files, you can also read and write .xslx files as below (useful to know this) # xlsx reads deprecated here is a hack using openpyxl readfileexcel = pandas.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') #Reading a .xlsx file print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15","title":"Reading a File into a Dataframe"},{"location":"lesson7/lesson7/#writing-a-dataframe-to-file","text":"#Creating and writing to a .csv file readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile1.csv') readfilecsv = pandas.read_csv('CSV_WritingFile1.csv') print(readfilecsv) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 #Creating and writing to a .csv file by excluding row labels readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile2.csv', index = False) readfilecsv = pandas.read_csv('CSV_WritingFile2.csv') print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 #Creating and writing to a .xlsx file readfileexcel = pandas.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') readfileexcel.to_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', index = False, engine='openpyxl') readfileexcel = pandas.read_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', engine='openpyxl') print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15","title":"Writing a dataframe to file"},{"location":"lesson7/lesson7/#downloading-files-from-websites-optional","text":"This section shows how to get files from a remote computer. There are several ways to get the files, most importantly you need the FQDN to the file.","title":"Downloading files from websites (optional)"},{"location":"lesson7/lesson7/#method-1-get-data-from-a-file-on-a-remote-server-unencrypted","text":"This section shows how to obtain data files from public URLs. Prerequesites: You know the FQDN to the file it will be in structure of \"http://server-name/.../filename.ext\" The server is running ordinary (unencrypted) web services, i.e. http://...","title":"Method 1: Get data from a file on a remote server (unencrypted)"},{"location":"lesson7/lesson7/#web-developer-notes","text":"If you want to distribute files (web developers) the files need to be in the server webroot, but can be deep into the heirarchial structure. Here we will do an example with a file that contains topographic data in XYZ format, without header information. The first few lines of the remote file look like: 74.90959724 93.21251922 0 75.17907367 64.40278759 0 94.9935575 93.07951286 0 95.26234119 64.60091165 0 54.04976655 64.21159095 0 54.52914363 35.06934342 0 75.44993558 34.93079513 0 75.09317373 5.462959114 0 74.87357468 10.43130083 0 74.86249082 15.72938748 0 And importantly it is tab delimited. The module to manipulate url in python is called urllib Google search to learn more, here we are using only a small component without exception trapping. #Step 1: import needed modules to interact with the internet from urllib.request import urlopen # import a method that will connect to a url and read file contents import pandas #import pandas This next code fragment sets a string called remote_url ; it is just a variable, name can be anything that honors python naming rules. Then the urllib function urlopen with read and decode methods is employed, the result is stored in an object named elevationXYZ #Step 2: make the connection to the remote file (actually its implementing \"bash curl -O http://fqdn/path ...\") remote_url = 'http://www.rtfmps.com/share_files/pip-corner-sumps.txt' # elevationXYZ = urlopen(remote_url).read().decode().split() # Gets the file contents as a single vector, comma delimited, file is not retained locally At this point the object exists as a single vector with hundreds of elements. We now need to structure the content. Here using python primatives, and knowing how the data are supposed to look, we prepare variables to recieve the structured results #Step 3 Python primatives to structure the data, or use fancy modules (probably easy in numpy) howmany = len(elevationXYZ) # how long is the vector? nrow = int(howmany/3) xyz = [[0 for j in range(3)] for j in range(nrow)] # null space to receive data define columnX Now that everything is ready, we can extract from the object the values we want into xyz #Step4 Now will build xyz as a matrix with 3 columns index = 0 for irow in range(0,nrow): xyz[irow][0]=float(elevationXYZ[index]) xyz[irow][1]=float(elevationXYZ[index+1]) xyz[irow][2]=float(elevationXYZ[index+2]) index += 3 #increment the index xyz is now a 3-column float array and can now probably be treated as a data frame. Here we use a pandas method to build the dataframe. df = pandas.DataFrame(xyz) Get some info, yep three columns (ordered triples to be precise!) df.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 774 entries, 0 to 773 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 0 774 non-null float64 1 1 774 non-null float64 2 2 774 non-null float64 dtypes: float64(3) memory usage: 18.3 KB And some summary statistics (meaningless for these data), but now have taken data from the internet and prepared it for analysis. df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 count 774.000000 774.000000 774.000000 mean 52.064621 48.770060 2.364341 std 30.883400 32.886277 1.497413 min -2.113554 -11.360960 0.000000 25% 25.640786 21.809579 2.000000 50% 55.795821 49.059950 2.000000 75% 76.752290 75.015933 4.000000 max 111.726727 115.123931 4.000000 And lets look at the first few rows df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 74.909597 93.212519 0.0 1 75.179074 64.402788 0.0 2 94.993557 93.079513 0.0 3 95.262341 64.600912 0.0 4 54.049767 64.211591 0.0","title":"Web Developer Notes"},{"location":"lesson7/lesson7/#method-2-get-the-actual-file-from-a-remote-web-server-unencrypted","text":"You know the FQDN to the file it will be in structure of \"http://server-name/.../filename.ext\" The server is running ordinary (unencrypted) web services, i.e. http://... We will need a module to interface with the remote server, in this example lets use something different than urllib . Here we will use requests , so first we load the module import requests # Module to process http/https requests Now we will generate a GET request to the remote http server. I chose to do so using a variable to store the remote URL so I can reuse code in future projects. The GET request (an http/https method) is generated with the requests method get and assigned to an object named rget -- the name is arbitrary. Next we extract the file from the rget object and write it to a local file with the name of the remote file - esentially automating the download process. Then we import the pandas module. remote_url=\"http://54.243.252.9/engr-1330-psuedo-course/MyJupyterNotebooks/42-DataScience-EvaporationAnalysis/all_quads_gross_evaporation.csv\" # set the url rget = requests.get(remote_url, allow_redirects=True) # get the remote resource, follow imbedded links open('all_quads_gross_evaporation.csv','wb').write(rget.content) # extract from the remote the contents, assign to a local file same name import pandas as pd # Module to process dataframes (not absolutely needed but somewhat easier than using primatives, and gives graphing tools) # verify file exists ! pwd ! ls -la /home/sensei/1330-textbook-webroot/docs/lesson7 total 1412 drwxrwxr-x 3 sensei sensei 4096 Feb 16 20:57 . drwxr-xr-x 10 sensei sensei 4096 Feb 16 20:30 .. drwxrwxr-x 2 sensei sensei 4096 Feb 16 20:53 .ipynb_checkpoints -rw-rw-r-- 1 sensei sensei 21150 Feb 15 15:58 01-table-dataframe.png -rw-rw-r-- 1 sensei sensei 51 Feb 15 15:58 CSV_ReadingFile.csv -rw-rw-r-- 1 sensei sensei 55 Feb 16 20:59 CSV_WritingFile1.csv -rw-rw-r-- 1 sensei sensei 46 Feb 16 20:59 CSV_WritingFile2.csv -rw-rw-r-- 1 sensei sensei 693687 Feb 15 15:58 ENGR-1330-Lesson8-Dev.html -rw-rw-r-- 1 sensei sensei 166938 Feb 15 15:58 ENGR-1330-Lesson8-Dev.ipynb -rw-rw-r-- 1 sensei sensei 5508 Feb 15 15:58 Excel_ReadingFile.xlsx -rw-rw-r-- 1 sensei sensei 5041 Feb 16 20:59 Excel_WritingFile.xlsx -rw-rw-r-- 1 sensei sensei 363498 Feb 16 20:59 all_quads_gross_evaporation.csv -rw-rw-r-- 1 sensei sensei 108222 Feb 16 20:57 lesson7.ipynb -rw-rw-r-- 1 sensei sensei 40566 Feb 15 15:58 output_126_1.png Now we can read the file contents and check its structure, before proceeding. evapdf = pd.read_csv(\"all_quads_gross_evaporation.csv\",parse_dates=[\"YYYY-MM\"]) # Read the file as a .CSV assign to a dataframe evapdf evapdf.head() # check structure .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } YYYY-MM 104 105 106 107 108 204 205 206 207 ... 911 912 1008 1009 1010 1011 1108 1109 1110 1210 0 1954-01-01 1.80 1.80 2.02 2.24 2.24 2.34 1.89 1.80 1.99 ... 1.42 1.30 2.50 2.42 1.94 1.29 2.59 2.49 2.22 2.27 1 1954-02-01 4.27 4.27 4.13 3.98 3.90 4.18 4.26 4.27 4.26 ... 2.59 2.51 4.71 4.30 3.84 2.50 5.07 4.62 4.05 4.18 2 1954-03-01 4.98 4.98 4.62 4.25 4.20 5.01 4.98 4.98 4.68 ... 3.21 3.21 6.21 6.06 5.02 3.21 6.32 6.20 5.68 5.70 3 1954-04-01 6.09 5.94 5.94 6.07 5.27 6.31 5.98 5.89 5.72 ... 3.83 3.54 6.45 6.25 4.92 3.54 6.59 6.44 5.88 5.95 4 1954-05-01 5.41 5.09 5.14 4.40 3.61 5.57 4.56 4.47 4.18 ... 3.48 3.97 7.92 8.13 6.31 3.99 7.75 7.98 7.40 7.40 5 rows \u00d7 93 columns Structure looks like a spreadsheet as expected; lets plot the time series for cell '911' evapdf.plot.line(x='YYYY-MM',y='911') # Plot quadrant 911 evaporation time series <AxesSubplot:xlabel='YYYY-MM'>","title":"Method 2: Get the actual file from a remote web server (unencrypted)"},{"location":"lesson7/lesson7/#method-3-get-the-actual-file-from-an-encrypted-server","text":"This section is saved for future semesters","title":"Method 3: Get the actual file from an encrypted server"},{"location":"lesson7/lesson7/#references","text":"Overland, B. (2018). Python Without Fear. Addison-Wesley ISBN 978-0-13-468747-6. Grus, Joel (2015). Data Science from Scratch: First Principles with Python O\u2019Reilly Media. Kindle Edition. Precord, C. (2010) wxPython 2.8 Application Development Cookbook Packt Publishing Ltd. Birmingham , B27 6PA, UK ISBN 978-1-849511-78-0. # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"References"},{"location":"lesson8/lesson8/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 18 February 2021 Lesson 8 Visual Display of Data This lesson will introduce the matplotlib external module package, and examine how to construct line charts, scatter plots, bar charts, box plot, and histograms using methods in matplotlib and pandas The theory of histograms will appear in later lessons, here we only show how to construct one using matplotlib Graphic Standards for Plots Parts of a Plot Building Plots using matplotlib external package Objectives Define the ordinate, abscissa, independent and dependent variables Identify the parts of a proper plot Define how to plot experimental data and theoretical data About matplotlib Quoting from: https://matplotlib.org/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py matplotlib.pyplot is a collection of functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc. In matplotlib.pyplot various states are preserved across function calls, so that it keeps track of things like the current figure and plotting area, and the plotting functions are directed to the current axes (please note that \"axes\" here and in most places in the documentation refers to the axes part of a figure and not the strict mathematical term for more than one axis). Computational thinking (CT) concepts involved are: Decomposition : Break a problem down into smaller pieces; separating plotting from other parts of analysis simplifies maintenace of scripts Abstraction : Pulling out specific differences to make one solution work for multiple problems; wrappers around generic plot calls enhances reuse Algorithms : A list of steps that you can follow to finish a task; Often the last step and most important to make professional graphics to justify the expense (of paying you to do engineering) to the client. Graphics Conventions for Plots Terminology: Ordinate, Abscissa, Dependent and Independent Variables A few terms are used in describing plots: - Abscissa \u2013 the horizontal axis on a plot (the left-right axis) - Ordinate \u2013 the vertical axis on a plot (the up-down axis) A few terms in describing data models - Independent Variable (Explainatory, Predictor, Feature, ...) \u2013 a variable that can be controlled/manipulated in an experiment or theoretical analysis - Dependent Variable (Response, Prediction, ...) \u2013 the variable that measured/observed as a function of the independent variable Plotting convention in most cases assigns explainatory variables to the horizontal axis (e.g. Independent variable is plotted on the Abscissa) and the response variable(s) to the vertical axis (e.g. Dependent Variable is plotted on the Ordinate) Conventions for Proper Plots Include a title OR a caption with a brief description of the plot Label both axes clearly Include the variable name, the variable, and the unit in each label If possible, select increments for both the x and y axes that provide for easy interpolation Include gridlines Show experimental measurements as symbols Show model (theoretical) relationships as lines Use portrait orientation when making your plot Make the plot large enough to be easily read If more than one experimental dataset is plotted Use different shapes for each dataset Use different colors for each dataset Include a legend defining the datasets Background Data are not always numerical. Data can be music (audio files), or places on a map (georeferenced attributes files), images (various imge files, e.g. .png, jpeg) and other types. Categorical data is a type where you can place individual components into a category: For example visualize a freezer where a business stores ice cream, the product is categorized by flavor, each carton is a component. - The individual components are cartons of ice-cream, and the category is the flavor in the carton Bar Graphs Bar charts (graphs) are useful tools to graphically represent categorical information. The bars are evenly spaced and of constant width. The height/length of each bar is proportional to the relative frequency of the corresponding category. Relative frequency is the ratio of how many things in the category to how many things in the whole collection. The example below uses matplotlib to create a box plot for the ice cream analogy, the example is adapted from an example at https://www.geeksforgeeks.org/bar-plot-in-matplotlib/ ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! type(flavors) list myfigure = matplotlib.pyplot.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio <Figure size 720x360 with 0 Axes> # Built the plot matplotlib.pyplot.bar(flavors, cartons, color ='magenta', width = 0.4) matplotlib.pyplot.xlabel(\"Flavors\") matplotlib.pyplot.ylabel(\"No. of Cartons in Stock\") matplotlib.pyplot.title(\"Current Ice Cream in Storage\") matplotlib.pyplot.show() Lets tidy up the script so it is more understandable, a small change in the import statement makes a simpler to read (for humans) script - also changed the bar colors just 'cause! ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot plt.bar(flavors, cartons, color ='green', width = 0.4) plt.xlabel(\"Flavors\") plt.ylabel(\"No. of Cartons in Stock\") plt.title(\"Current Ice Cream in Storage\") plt.show() Now lets deconstruct the script a bit: ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! This part of the code creates a dictionary object, keys are the flavors, values are the carton counts (not the best way, but good for our learning needs). Next we import the python plotting library from matplotlib and name it plt to keep the script a bit easier to read. Next we use the list method to create two lists from the dictionary, flavors and cartons . Keep this in mind plotting is usually done on lists, so we need to prepare the structures properly. The next statement myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio Uses the figure class in pyplot from matplotlib to make a figure object named myfigure, the plot is built into this object. Every call to a method in plt adds content to myfigure until we send the instruction to render the plot ( plt.show() ) The next portion of the script builds the plot: plt.bar(flavors, cartons, color ='orange', width = 0.4) # Build a bar chart, plot series flavor on x-axis, plot series carton on y-axis. Make the bars orange, set bar width (units unspecified) plt.xlabel(\"Flavors\") # Label the x-axis as Flavors plt.ylabel(\"No. of Cartons in Stock\") # Label the x-axis as Flavors plt.title(\"Current Ice Cream in Storage\") # Title for the whole plot This last statement renders the plot to the graphics device (probably localhost in the web browser) plt.show() Now lets add another set of categories to the plot and see what happens ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model eaters = {'Cats':6, 'Dogs':5, 'Ferrets':19} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! animals = list(eaters.keys()) beastcount = list(eaters.values()) myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot plt.bar(flavors, cartons, color ='gray', width = 0.4) plt.bar(animals, beastcount, color ='brown', width = 0.4) plt.xlabel(\"Flavors\") plt.ylabel(\"Counts: Cartons and Beasts\") plt.title(\"Current Ice Cream in Storage\") plt.show() Now suppose we want horizontal bars we can search pyplot for such a thing. If one types horizontal bar chart into the pyplot search engine there is a link that leads to: Which has the right look! If we examine the script there is a method called barh so lets try that. ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model eaters = {'Cats':6, 'Dogs':5, 'Ferrets':19} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! animals = list(eaters.keys()) beasts = list(eaters.values()) myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot plt.barh(flavors, cartons, color ='orange') plt.barh(animals, beasts, color ='green') plt.xlabel(\"Flavors\") plt.ylabel(\"Counts: Cartons and Beasts\") plt.title(\"Current Ice Cream in Storage\") plt.show() Now using pandas, we can build bar charts a bit easier. import pandas as pd my_data = { \"Flavor\": ['Chocolate', 'Strawberry', 'Vanilla'], \"Number of Cartons\": [16, 5, 9] } df = pd.DataFrame(my_data) df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Flavor Number of Cartons 0 Chocolate 16 1 Strawberry 5 2 Vanilla 9 df.plot.bar(x='Flavor', y='Number of Cartons', color='magenta' ) <AxesSubplot:xlabel='Flavor'> df.plot.barh(x='Flavor', y='Number of Cartons', color=\"red\") # rotate the category labels <AxesSubplot:ylabel='Flavor'> import numpy as np import matplotlib.pyplot as plt # creating the dataset data = {'C':20, 'C++':15, 'Java':30, 'Python':35} courses = list(data.keys()) values = list(data.values()) fig = plt.figure(figsize = (10, 5)) # creating the bar plot plt.bar(courses, values, color ='maroon', width = 0.4) plt.xlabel(\"Courses offered\") plt.ylabel(\"No. of students enrolled\") plt.title(\"Students enrolled in different courses\") plt.show() Line Charts A line chart or line plot or line graph or curve chart is a type of chart which displays information as a series of data points called 'markers' connected by straight line segments. It is a basic type of chart common in many fields. It is similar to a scatter plot (below) except that the measurement points are ordered (typically by their x-axis value) and joined with straight line segments. A line chart is often used to visualize a trend in data over intervals of time \u2013 a time series \u2013 thus the line is often drawn chronologically. The x-axis spacing is sometimes tricky, hence line charts can unintentionally decieve - so be careful that it is the appropriate chart for your application. Example Consider the experimental data below Elapsed Time (s) Speed (m/s) 0 0 1.0 3 2.0 7 3.0 12 4.0 20 5.0 30 6.0 45.6 Show the relationship between time and speed. Is the relationship indicating acceleration? How much? # Create two lists; time and speed. time = [0,1.0,2.0,3.0,4.0,5.0,6.0] speed = [0,3,7,12,20,30,45.6] # Create a line chart of speed on y axis and time on x axis mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='v',linewidth=1) # basic line plot plt.show() time = [0,1.0,4.0,5.0,6.0,2.0,3.0] speed = [0,3,20,30,45.6,7,12] # Create a line chart of speed on y axis and time on x axis mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='green', marker='o',linewidth=1) # basic line plot plt.show() # Estimate acceleration (naive) dvdt = (max(speed) - min(speed))/(max(time)-min(time)) plottitle = 'Average acceleration %.3f' % (dvdt) + ' m/sec/sec' seriesnames = ['Data','Model'] modely = [min(speed),max(speed)] modelx = [min(time),max(time)] mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='v',linewidth=0) # basic line plot plt.plot(modelx, modely, c='blue',linewidth=1) # basic line plot plt.xlabel('Time (sec)') plt.ylabel('Speed (m/sec)') plt.legend(seriesnames) plt.title(plottitle) plt.show() Scatter Plots A scatter plot (also called a scatterplot, scatter graph, scatter chart, scattergram, or scatter diagram) is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. If the points are coded (color/shape/size), one additional variable can be displayed. The data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis. A scatter plot can be used either when one continuous variable that is under the control of the experimenter and the other depends on it or when both continuous variables are independent. If a parameter exists that is systematically incremented and/or decremented by the other, it is called the control parameter or independent variable and is customarily plotted along the horizontal axis. The measured or dependent variable is customarily plotted along the vertical axis. If no dependent variable exists, either type of variable can be plotted on either axis and a scatter plot will illustrate only the degree of correlation (not causation) between two variables. A scatter plot can suggest various kinds of correlations between variables with a certain confidence interval. For example, weight and height, weight would be on y axis and height would be on the x axis. Correlations may be positive (rising), negative (falling), or null (uncorrelated). If the pattern of dots slopes from lower left to upper right, it indicates a positive correlation between the variables being studied. If the pattern of dots slopes from upper left to lower right, it indicates a negative correlation. A line of best fit (alternatively called 'trendline') can be drawn in order to study the relationship between the variables. An equation for the correlation between the variables can be determined by established best-fit procedures. For a linear correlation, the best-fit procedure is known as linear regression and is guaranteed to generate a correct solution in a finite time. No universal best-fit procedure is guaranteed to generate a solution for arbitrary relationships. A scatter plot is also very useful when we wish to see how two comparable data sets agree and to show nonlinear relationships between variables. Furthermore, if the data are represented by a mixture model of simple relationships, these relationships will be visually evident as superimposed patterns. Scatter charts can be built in the form of bubble, marker, or/and line charts. Much of the above is verbatim/adapted from: https://en.wikipedia.org/wiki/Scatter_plot # Example 1. A data file containing heights of fathers, mothers, and sons is to be examined df = pd.read_csv('galton_subset.csv') df['child']= df['son'] ; df.drop('son', axis=1, inplace = True) # rename son to child - got to imagine there are some daughters df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } father mother child 0 78.5 67.0 73.2 1 75.5 66.5 73.5 2 75.0 64.0 71.0 3 75.0 64.0 70.5 4 75.0 58.5 72.0 # build some lists daddy = df['father'] ; mommy = df['mother'] ; baby = df['child'] myfamily = plt.figure(figsize = (10, 10)) # build a square drawing canvass from figure class plt.scatter(baby, daddy, c='red') # basic scatter plot plt.show() # Looks lousy, needs some labels myfamily = plt.figure(figsize = (10, 10)) # build a square drawing canvass from figure class plt.scatter(baby, daddy, c='red' , label='Father') # one plot series plt.scatter(baby, mommy, c='blue', label='Mother') # two plot series plt.xlabel(\"Child's height\") plt.ylabel(\"Parents' height\") plt.legend() plt.show() # render the two plots # Repeat in pandas - The dataframe already is built df.plot.scatter(x=\"child\", y=\"father\") <AxesSubplot:xlabel='child', ylabel='father'> ax = df.plot.scatter(x=\"child\", y=\"father\", c=\"red\", label='Father') df.plot.scatter(x=\"child\", y=\"mother\", c=\"blue\", label='Mother', ax=ax) ax.set_xlabel(\"Child's height\") ax.set_ylabel(\"Parents' Height\") Text(0, 0.5, \"Parents' Height\") df.plot.scatter(x=\"child\", y=\"father\") <AxesSubplot:xlabel='child', ylabel='father'> Histograms Quilting from https://en.wikipedia.org/wiki/Histogram \"A histogram is an approximate representation of the distribution of numerical data. It was first introduced by Karl Pearson. To construct a histogram, the first step is to \"bin\" (or \"bucket\") the range of values\u2014that is, divide the entire range of values into a series of intervals\u2014and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) must be adjacent, and are often (but not required to be) of equal size. If the bins are of equal size, a rectangle is erected over the bin with height proportional to the frequency\u2014the number of cases in each bin. A histogram may also be normalized to display \"relative\" frequencies. It then shows the proportion of cases that fall into each of several categories, with the sum of the heights equaling 1. However, bins need not be of equal width; in that case, the erected rectangle is defined to have its area proportional to the frequency of cases in the bin. The vertical axis is then not the frequency but frequency density\u2014the number of cases per unit of the variable on the horizontal axis. As the adjacent bins leave no gaps, the rectangles of a histogram touch each other to indicate that the original variable is continuous. Histograms give a rough sense of the density of the underlying distribution of the data, and often for density estimation: estimating the probability density function of the underlying variable. The total area of a histogram used for probability density is always normalized to 1. If the length of the intervals on the x-axis are all 1, then a histogram is identical to a relative frequency plot. A histogram can be thought of as a simplistic kernel density estimation, which uses a kernel to smooth frequencies over the bins. This yields a smoother probability density function, which will in general more accurately reflect distribution of the underlying variable. The density estimate could be plotted as an alternative to the histogram, and is usually drawn as a curve rather than a set of boxes. Histograms are nevertheless preferred in applications, when their statistical properties need to be modeled. The correlated variation of a kernel density estimate is very difficult to describe mathematically, while it is simple for a histogram where each bin varies independently. An alternative to kernel density estimation is the average shifted histogram, which is fast to compute and gives a smooth curve estimate of the density without using kernels. The histogram is one of the seven basic tools of quality control. Histograms are sometimes confused with bar charts. A histogram is used for continuous data, where the bins represent ranges of data, while a bar chart is a plot of categorical variables. Some authors recommend that bar charts have gaps between the rectangles to clarify the distinction.\" import pandas as pd df = pd.read_csv('top_movies.csv') df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Title Studio Gross Gross (Adjusted) Year 0 Star Wars: The Force Awakens Buena Vista (Disney) 906723418 906723400 2015 1 Avatar Fox 760507625 846120800 2009 2 Titanic Paramount 658672302 1178627900 1997 3 Jurassic World Universal 652270625 687728000 2015 4 Marvel's The Avengers Buena Vista (Disney) 623357910 668866600 2012 df[[\"Gross\"]].hist() array([[<AxesSubplot:title={'center':'Gross'}>]], dtype=object) df[[\"Gross\"]].hist(bins=100) array([[<AxesSubplot:title={'center':'Gross'}>]], dtype=object) df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Gross Gross (Adjusted) Year count 2.000000e+02 2.000000e+02 200.000000 mean 2.216196e+08 5.041983e+08 1986.620000 std 1.441574e+08 2.159814e+08 20.493548 min 9.183673e+06 3.222619e+08 1921.000000 25% 1.087824e+08 3.677804e+08 1973.000000 50% 2.001273e+08 4.388570e+08 1990.000000 75% 3.069535e+08 5.512131e+08 2003.250000 max 9.067234e+08 1.757788e+09 2015.000000 References Constructing Horizontal Bar Charts (matplotlib.org documentation) https://matplotlib.org/gallery/lines_bars_and_markers/horizontal_barchart_distribution.html?highlight=horizontal%20bar%20chart How to make a bar chart https://www.geeksforgeeks.org/bar-plot-in-matplotlib/","title":"Lesson 8"},{"location":"lesson8/lesson8/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 18 February 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson8/lesson8/#lesson-8-visual-display-of-data","text":"This lesson will introduce the matplotlib external module package, and examine how to construct line charts, scatter plots, bar charts, box plot, and histograms using methods in matplotlib and pandas The theory of histograms will appear in later lessons, here we only show how to construct one using matplotlib Graphic Standards for Plots Parts of a Plot Building Plots using matplotlib external package","title":"Lesson 8 Visual Display of Data"},{"location":"lesson8/lesson8/#objectives","text":"Define the ordinate, abscissa, independent and dependent variables Identify the parts of a proper plot Define how to plot experimental data and theoretical data","title":"Objectives"},{"location":"lesson8/lesson8/#about-matplotlib","text":"Quoting from: https://matplotlib.org/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py matplotlib.pyplot is a collection of functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc. In matplotlib.pyplot various states are preserved across function calls, so that it keeps track of things like the current figure and plotting area, and the plotting functions are directed to the current axes (please note that \"axes\" here and in most places in the documentation refers to the axes part of a figure and not the strict mathematical term for more than one axis). Computational thinking (CT) concepts involved are: Decomposition : Break a problem down into smaller pieces; separating plotting from other parts of analysis simplifies maintenace of scripts Abstraction : Pulling out specific differences to make one solution work for multiple problems; wrappers around generic plot calls enhances reuse Algorithms : A list of steps that you can follow to finish a task; Often the last step and most important to make professional graphics to justify the expense (of paying you to do engineering) to the client.","title":"About matplotlib"},{"location":"lesson8/lesson8/#graphics-conventions-for-plots","text":"","title":"Graphics Conventions for Plots"},{"location":"lesson8/lesson8/#terminology-ordinate-abscissa-dependent-and-independent-variables","text":"A few terms are used in describing plots: - Abscissa \u2013 the horizontal axis on a plot (the left-right axis) - Ordinate \u2013 the vertical axis on a plot (the up-down axis) A few terms in describing data models - Independent Variable (Explainatory, Predictor, Feature, ...) \u2013 a variable that can be controlled/manipulated in an experiment or theoretical analysis - Dependent Variable (Response, Prediction, ...) \u2013 the variable that measured/observed as a function of the independent variable Plotting convention in most cases assigns explainatory variables to the horizontal axis (e.g. Independent variable is plotted on the Abscissa) and the response variable(s) to the vertical axis (e.g. Dependent Variable is plotted on the Ordinate)","title":"Terminology: Ordinate, Abscissa, Dependent and Independent Variables"},{"location":"lesson8/lesson8/#conventions-for-proper-plots","text":"Include a title OR a caption with a brief description of the plot Label both axes clearly Include the variable name, the variable, and the unit in each label If possible, select increments for both the x and y axes that provide for easy interpolation Include gridlines Show experimental measurements as symbols Show model (theoretical) relationships as lines Use portrait orientation when making your plot Make the plot large enough to be easily read If more than one experimental dataset is plotted Use different shapes for each dataset Use different colors for each dataset Include a legend defining the datasets","title":"Conventions for Proper Plots"},{"location":"lesson8/lesson8/#background","text":"Data are not always numerical. Data can be music (audio files), or places on a map (georeferenced attributes files), images (various imge files, e.g. .png, jpeg) and other types. Categorical data is a type where you can place individual components into a category: For example visualize a freezer where a business stores ice cream, the product is categorized by flavor, each carton is a component. - The individual components are cartons of ice-cream, and the category is the flavor in the carton","title":"Background"},{"location":"lesson8/lesson8/#bar-graphs","text":"Bar charts (graphs) are useful tools to graphically represent categorical information. The bars are evenly spaced and of constant width. The height/length of each bar is proportional to the relative frequency of the corresponding category. Relative frequency is the ratio of how many things in the category to how many things in the whole collection. The example below uses matplotlib to create a box plot for the ice cream analogy, the example is adapted from an example at https://www.geeksforgeeks.org/bar-plot-in-matplotlib/ ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! type(flavors) list myfigure = matplotlib.pyplot.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio <Figure size 720x360 with 0 Axes> # Built the plot matplotlib.pyplot.bar(flavors, cartons, color ='magenta', width = 0.4) matplotlib.pyplot.xlabel(\"Flavors\") matplotlib.pyplot.ylabel(\"No. of Cartons in Stock\") matplotlib.pyplot.title(\"Current Ice Cream in Storage\") matplotlib.pyplot.show() Lets tidy up the script so it is more understandable, a small change in the import statement makes a simpler to read (for humans) script - also changed the bar colors just 'cause! ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot plt.bar(flavors, cartons, color ='green', width = 0.4) plt.xlabel(\"Flavors\") plt.ylabel(\"No. of Cartons in Stock\") plt.title(\"Current Ice Cream in Storage\") plt.show() Now lets deconstruct the script a bit: ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! This part of the code creates a dictionary object, keys are the flavors, values are the carton counts (not the best way, but good for our learning needs). Next we import the python plotting library from matplotlib and name it plt to keep the script a bit easier to read. Next we use the list method to create two lists from the dictionary, flavors and cartons . Keep this in mind plotting is usually done on lists, so we need to prepare the structures properly. The next statement myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio Uses the figure class in pyplot from matplotlib to make a figure object named myfigure, the plot is built into this object. Every call to a method in plt adds content to myfigure until we send the instruction to render the plot ( plt.show() ) The next portion of the script builds the plot: plt.bar(flavors, cartons, color ='orange', width = 0.4) # Build a bar chart, plot series flavor on x-axis, plot series carton on y-axis. Make the bars orange, set bar width (units unspecified) plt.xlabel(\"Flavors\") # Label the x-axis as Flavors plt.ylabel(\"No. of Cartons in Stock\") # Label the x-axis as Flavors plt.title(\"Current Ice Cream in Storage\") # Title for the whole plot This last statement renders the plot to the graphics device (probably localhost in the web browser) plt.show() Now lets add another set of categories to the plot and see what happens ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model eaters = {'Cats':6, 'Dogs':5, 'Ferrets':19} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! animals = list(eaters.keys()) beastcount = list(eaters.values()) myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot plt.bar(flavors, cartons, color ='gray', width = 0.4) plt.bar(animals, beastcount, color ='brown', width = 0.4) plt.xlabel(\"Flavors\") plt.ylabel(\"Counts: Cartons and Beasts\") plt.title(\"Current Ice Cream in Storage\") plt.show() Now suppose we want horizontal bars we can search pyplot for such a thing. If one types horizontal bar chart into the pyplot search engine there is a link that leads to: Which has the right look! If we examine the script there is a method called barh so lets try that. ice_cream = {'Chocolate':16, 'Strawberry':5, 'Vanilla':9} # build a data model eaters = {'Cats':6, 'Dogs':5, 'Ferrets':19} # build a data model import matplotlib.pyplot as plt # the python plotting library flavors = list(ice_cream.keys()) # make a list object based on flavors cartons = list(ice_cream.values()) # make a list object based on carton count -- assumes 1:1 association! animals = list(eaters.keys()) beasts = list(eaters.values()) myfigure = plt.figure(figsize = (10,5)) # generate a object from the figure class, set aspect ratio # Built the plot plt.barh(flavors, cartons, color ='orange') plt.barh(animals, beasts, color ='green') plt.xlabel(\"Flavors\") plt.ylabel(\"Counts: Cartons and Beasts\") plt.title(\"Current Ice Cream in Storage\") plt.show() Now using pandas, we can build bar charts a bit easier. import pandas as pd my_data = { \"Flavor\": ['Chocolate', 'Strawberry', 'Vanilla'], \"Number of Cartons\": [16, 5, 9] } df = pd.DataFrame(my_data) df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Flavor Number of Cartons 0 Chocolate 16 1 Strawberry 5 2 Vanilla 9 df.plot.bar(x='Flavor', y='Number of Cartons', color='magenta' ) <AxesSubplot:xlabel='Flavor'> df.plot.barh(x='Flavor', y='Number of Cartons', color=\"red\") # rotate the category labels <AxesSubplot:ylabel='Flavor'> import numpy as np import matplotlib.pyplot as plt # creating the dataset data = {'C':20, 'C++':15, 'Java':30, 'Python':35} courses = list(data.keys()) values = list(data.values()) fig = plt.figure(figsize = (10, 5)) # creating the bar plot plt.bar(courses, values, color ='maroon', width = 0.4) plt.xlabel(\"Courses offered\") plt.ylabel(\"No. of students enrolled\") plt.title(\"Students enrolled in different courses\") plt.show()","title":"Bar Graphs"},{"location":"lesson8/lesson8/#line-charts","text":"A line chart or line plot or line graph or curve chart is a type of chart which displays information as a series of data points called 'markers' connected by straight line segments. It is a basic type of chart common in many fields. It is similar to a scatter plot (below) except that the measurement points are ordered (typically by their x-axis value) and joined with straight line segments. A line chart is often used to visualize a trend in data over intervals of time \u2013 a time series \u2013 thus the line is often drawn chronologically. The x-axis spacing is sometimes tricky, hence line charts can unintentionally decieve - so be careful that it is the appropriate chart for your application. Example Consider the experimental data below Elapsed Time (s) Speed (m/s) 0 0 1.0 3 2.0 7 3.0 12 4.0 20 5.0 30 6.0 45.6 Show the relationship between time and speed. Is the relationship indicating acceleration? How much? # Create two lists; time and speed. time = [0,1.0,2.0,3.0,4.0,5.0,6.0] speed = [0,3,7,12,20,30,45.6] # Create a line chart of speed on y axis and time on x axis mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='v',linewidth=1) # basic line plot plt.show() time = [0,1.0,4.0,5.0,6.0,2.0,3.0] speed = [0,3,20,30,45.6,7,12] # Create a line chart of speed on y axis and time on x axis mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='green', marker='o',linewidth=1) # basic line plot plt.show() # Estimate acceleration (naive) dvdt = (max(speed) - min(speed))/(max(time)-min(time)) plottitle = 'Average acceleration %.3f' % (dvdt) + ' m/sec/sec' seriesnames = ['Data','Model'] modely = [min(speed),max(speed)] modelx = [min(time),max(time)] mydata = plt.figure(figsize = (10,5)) # build a square drawing canvass from figure class plt.plot(time, speed, c='red', marker='v',linewidth=0) # basic line plot plt.plot(modelx, modely, c='blue',linewidth=1) # basic line plot plt.xlabel('Time (sec)') plt.ylabel('Speed (m/sec)') plt.legend(seriesnames) plt.title(plottitle) plt.show()","title":"Line Charts"},{"location":"lesson8/lesson8/#scatter-plots","text":"A scatter plot (also called a scatterplot, scatter graph, scatter chart, scattergram, or scatter diagram) is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. If the points are coded (color/shape/size), one additional variable can be displayed. The data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis. A scatter plot can be used either when one continuous variable that is under the control of the experimenter and the other depends on it or when both continuous variables are independent. If a parameter exists that is systematically incremented and/or decremented by the other, it is called the control parameter or independent variable and is customarily plotted along the horizontal axis. The measured or dependent variable is customarily plotted along the vertical axis. If no dependent variable exists, either type of variable can be plotted on either axis and a scatter plot will illustrate only the degree of correlation (not causation) between two variables. A scatter plot can suggest various kinds of correlations between variables with a certain confidence interval. For example, weight and height, weight would be on y axis and height would be on the x axis. Correlations may be positive (rising), negative (falling), or null (uncorrelated). If the pattern of dots slopes from lower left to upper right, it indicates a positive correlation between the variables being studied. If the pattern of dots slopes from upper left to lower right, it indicates a negative correlation. A line of best fit (alternatively called 'trendline') can be drawn in order to study the relationship between the variables. An equation for the correlation between the variables can be determined by established best-fit procedures. For a linear correlation, the best-fit procedure is known as linear regression and is guaranteed to generate a correct solution in a finite time. No universal best-fit procedure is guaranteed to generate a solution for arbitrary relationships. A scatter plot is also very useful when we wish to see how two comparable data sets agree and to show nonlinear relationships between variables. Furthermore, if the data are represented by a mixture model of simple relationships, these relationships will be visually evident as superimposed patterns. Scatter charts can be built in the form of bubble, marker, or/and line charts. Much of the above is verbatim/adapted from: https://en.wikipedia.org/wiki/Scatter_plot # Example 1. A data file containing heights of fathers, mothers, and sons is to be examined df = pd.read_csv('galton_subset.csv') df['child']= df['son'] ; df.drop('son', axis=1, inplace = True) # rename son to child - got to imagine there are some daughters df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } father mother child 0 78.5 67.0 73.2 1 75.5 66.5 73.5 2 75.0 64.0 71.0 3 75.0 64.0 70.5 4 75.0 58.5 72.0 # build some lists daddy = df['father'] ; mommy = df['mother'] ; baby = df['child'] myfamily = plt.figure(figsize = (10, 10)) # build a square drawing canvass from figure class plt.scatter(baby, daddy, c='red') # basic scatter plot plt.show() # Looks lousy, needs some labels myfamily = plt.figure(figsize = (10, 10)) # build a square drawing canvass from figure class plt.scatter(baby, daddy, c='red' , label='Father') # one plot series plt.scatter(baby, mommy, c='blue', label='Mother') # two plot series plt.xlabel(\"Child's height\") plt.ylabel(\"Parents' height\") plt.legend() plt.show() # render the two plots # Repeat in pandas - The dataframe already is built df.plot.scatter(x=\"child\", y=\"father\") <AxesSubplot:xlabel='child', ylabel='father'> ax = df.plot.scatter(x=\"child\", y=\"father\", c=\"red\", label='Father') df.plot.scatter(x=\"child\", y=\"mother\", c=\"blue\", label='Mother', ax=ax) ax.set_xlabel(\"Child's height\") ax.set_ylabel(\"Parents' Height\") Text(0, 0.5, \"Parents' Height\") df.plot.scatter(x=\"child\", y=\"father\") <AxesSubplot:xlabel='child', ylabel='father'>","title":"Scatter Plots"},{"location":"lesson8/lesson8/#histograms","text":"Quilting from https://en.wikipedia.org/wiki/Histogram \"A histogram is an approximate representation of the distribution of numerical data. It was first introduced by Karl Pearson. To construct a histogram, the first step is to \"bin\" (or \"bucket\") the range of values\u2014that is, divide the entire range of values into a series of intervals\u2014and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) must be adjacent, and are often (but not required to be) of equal size. If the bins are of equal size, a rectangle is erected over the bin with height proportional to the frequency\u2014the number of cases in each bin. A histogram may also be normalized to display \"relative\" frequencies. It then shows the proportion of cases that fall into each of several categories, with the sum of the heights equaling 1. However, bins need not be of equal width; in that case, the erected rectangle is defined to have its area proportional to the frequency of cases in the bin. The vertical axis is then not the frequency but frequency density\u2014the number of cases per unit of the variable on the horizontal axis. As the adjacent bins leave no gaps, the rectangles of a histogram touch each other to indicate that the original variable is continuous. Histograms give a rough sense of the density of the underlying distribution of the data, and often for density estimation: estimating the probability density function of the underlying variable. The total area of a histogram used for probability density is always normalized to 1. If the length of the intervals on the x-axis are all 1, then a histogram is identical to a relative frequency plot. A histogram can be thought of as a simplistic kernel density estimation, which uses a kernel to smooth frequencies over the bins. This yields a smoother probability density function, which will in general more accurately reflect distribution of the underlying variable. The density estimate could be plotted as an alternative to the histogram, and is usually drawn as a curve rather than a set of boxes. Histograms are nevertheless preferred in applications, when their statistical properties need to be modeled. The correlated variation of a kernel density estimate is very difficult to describe mathematically, while it is simple for a histogram where each bin varies independently. An alternative to kernel density estimation is the average shifted histogram, which is fast to compute and gives a smooth curve estimate of the density without using kernels. The histogram is one of the seven basic tools of quality control. Histograms are sometimes confused with bar charts. A histogram is used for continuous data, where the bins represent ranges of data, while a bar chart is a plot of categorical variables. Some authors recommend that bar charts have gaps between the rectangles to clarify the distinction.\" import pandas as pd df = pd.read_csv('top_movies.csv') df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Title Studio Gross Gross (Adjusted) Year 0 Star Wars: The Force Awakens Buena Vista (Disney) 906723418 906723400 2015 1 Avatar Fox 760507625 846120800 2009 2 Titanic Paramount 658672302 1178627900 1997 3 Jurassic World Universal 652270625 687728000 2015 4 Marvel's The Avengers Buena Vista (Disney) 623357910 668866600 2012 df[[\"Gross\"]].hist() array([[<AxesSubplot:title={'center':'Gross'}>]], dtype=object) df[[\"Gross\"]].hist(bins=100) array([[<AxesSubplot:title={'center':'Gross'}>]], dtype=object) df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Gross Gross (Adjusted) Year count 2.000000e+02 2.000000e+02 200.000000 mean 2.216196e+08 5.041983e+08 1986.620000 std 1.441574e+08 2.159814e+08 20.493548 min 9.183673e+06 3.222619e+08 1921.000000 25% 1.087824e+08 3.677804e+08 1973.000000 50% 2.001273e+08 4.388570e+08 1990.000000 75% 3.069535e+08 5.512131e+08 2003.250000 max 9.067234e+08 1.757788e+09 2015.000000","title":"Histograms"},{"location":"lesson8/lesson8/#references","text":"Constructing Horizontal Bar Charts (matplotlib.org documentation) https://matplotlib.org/gallery/lines_bars_and_markers/horizontal_barchart_distribution.html?highlight=horizontal%20bar%20chart How to make a bar chart https://www.geeksforgeeks.org/bar-plot-in-matplotlib/","title":"References"},{"location":"lesson9/lesson9/","text":"%%html <!--Script block to left align Markdown Tables--> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 18 February 2021 Lesson 9 Data Modeling: Statistical Approach This lesson covers concepts related to modeling data - it is the start of several lessons on the subject. The ultimate goal is to explain observed behavior with a model (like \\textbf{F} = m\\textbf{a} ) so that the model can be used to predict behavior. If we are predicting between existing observations, that's interpolation and is relatively straightforward. If we are predicting beyond existing observations, that's called extrapolation and is less straightforward. To get started we will examine the concepts of causality (cause => effect) and correlation, and the use of simulation to generate probability estimates. Objectives To understand the fundamental concepts involved in causality; and the difference between cause and correlation. To understand the fundamental concepts involved in iteration. To understand the fundamental concepts involved in simulation Computational Thinking Concepts The CT concepts include: Algorithm Design => Causality, Iteration, Simulation System Integration => Iteration, Simulation Correlation and Causality What is causality? (A long winded psuedo definition!) Causality is the relationship between causes and effects. The notion of causality does not have a uniform definition in the sciences, and is studied using philosophy and statistics. From the perspective of physics, it is generally believed that causality cannot occur between an effect and an event that is not in the back (past) light cone of said effect. Similarly, a cause could not have an effect outside its front (future) light cone. Here are some recent articles regarding Closed Time Loops, that explains causal consistency. The second paper is by an undergraduate student! https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.125.040605 https://iopscience.iop.org/article/10.1088/1361-6382/aba4bc Both to some extent theoretically support our popular notion of time travel (aka Dr. Who) without pesky paradoxes; someone with creative writing juices, could have a good science fiction career using these papers as a starting thesis! In classical physics, an effect cannot occur before its cause. In Einstein's theory of special relativity, causality means that an effect can not occur from a cause that is not in the back (past) light cone of that event. Similarly, a cause cannot have an effect outside its front (future) light cone. These restrictions are consistent with the assumption that causal influences cannot travel faster than the speed of light and/or backwards in time. In quantum field theory, observables of events with a spacelike relationship, \"elsewhere\", have to commute, so the order of observations or measurements of such observables do not impact each other. Causality in this context should not be confused with Newton's second law, which is related to the conservation of momentum, and is a consequence of the spatial homogeneity of physical laws. The word causality in this context means that all effects must have specific causes. Another requirement, at least valid at the level of human experience, is that cause and effect be mediated across space and time (requirement of contiguity). This requirement has been very influential in the past, in the first place as a result of direct observation of causal processes (like pushing a cart), in the second place as a problematic aspect of Newton's theory of gravitation (attraction of the earth by the sun by means of action at a distance) replacing mechanistic proposals like Descartes' vortex theory; in the third place as an incentive to develop dynamic field theories (e.g., Maxwell's electrodynamics and Einstein's general theory of relativity) restoring contiguity in the transmission of influences in a more successful way than in Descartes' theory. Yada yada bla bla bla ... Correlation (Causality's mimic!) The literary (as in writing!) formulation of causality is a \"why?, because ...\" structure (sort of like if=>then) The answer to a because question, should be the \"cause.\" Many authors use \"since\" to imply cause, but it is incorrect grammar - since answers the question of when? Think \"CAUSE\" => \"EFFECT\" Correlation doesn\u2019t mean cause (although it is a really good predictor of the crap we all buy - its why Amazon is sucessfull) Consider the chart below The correlation between money spent on pets and the number of lawyers is quite good (nearly perfect), so does having pets cause lawyers? Of course not, the general social economic conditions that improve general wealth, and create sufficient disposable income to have pets (here we mean companion animals, not food on the hoof) also creates conditions for laywers to proliferate, hence a good correlation. Nice video : Correlation and Causation https://www.youtube.com/watch?v=1Sa2v7kVEc0 Quoting from http://water.usgs.gov/pubs/twri/twri4a3/ Concentrations of atrazine and nitrate in shallow groundwaters are measured in wells over a several county area. For each sample, the concentration of one is plotted versus the concentration of the other. As atrazine concentrations increase, so do nitrate. How might the strength of this association be measured and summarized? Streams draining the Sierra Nevada mountains in California usually receive less precipitation in November than in other months. Has the amount of November precipitation significantly changed over the last 70 years, showing a gradual change in the climate of the area? How might this be tested? The above situations require a measure of the strength of association between two continuous variables, such as between two chemical concentrations, or between amount of precipitation and time. How do they co-vary? One class of measures are called correlation coefficients. Also important is how the significance of that association can be tested for, to determine whether the observed pattern differs from what is expected due entirely to chance. Whenever a correlation coefficient is calculated, the data should be plotted on a scatterplot. No single numerical measure can substitute for the visual insight gained from a plot. Many different patterns can produce the same correlation coefficient, and similar strengths of relationships can produce differing coefficients, depending on the curvature of the relationship. Implications Most research questions attempt to explain cause and effect. - In experimental research, the relationship is constructed and the experiment is somewhat of a failure if none of the presumed causal (causal == explainatory) variables influence the response (response == effect) - In a data science experimental context, causality may be impossible to establish, however correlations can be established and exploited. In data science, many studies involve observations on a group of individuals, a factor of interest called a treatment (explainatory variable, predictor variable, predictor feature ...), and an outcome (response, effect, state, predicted value ...) measured on each individual. The presumptive establishment of causality takes place in two stages. First, an association is observed. Any relation between the treatment and the outcome is called an association (we can measure the strength of the association using correlation coefficients!). Second, A more careful analysis is used to establish causality. a. One approach would be to control all variables other than the suspected (explainatory) variables, which for any meaningful process is essentially impossible. b. Another approach is to establish randomized control studies: 1. Start with a sample from a population (e.g. volunteers to test Covid 19 vaccines) 2. Randomly assign members to either a. Control group b. Treatment group 3. Expose the two groups identically, except the control group recieves a false (null) treatment 4. Compare the responses of the two groups, if they are same, there exists no evidence that the treatment variable CAUSES a response These concepts can be extended with some ingenuity to engineered systems and natural systems. Consider Data Science Questions: - Does going to school cause flu? - Does flu cause school attendance? - Does going to school contribute to the spread of flu? - Does the spread of flu contribute to the school attendance? - Are there other variables that affects both? a. These are called \u201cconfounding factors\u201d or \u201clurking variables\u201d. b. Cold weather?, more indoor time?, more interaction? Confounding Factors An underlying difference between the two groups (other than the treatment) is called a confounding factor, because it might confound you (that is, mess you up) when you try to reach a conclusion. For example, Cold weather in the previous example. Confounding also occurs when explainatory variables are correlated to another, for instance flood flows are well correlated to drainage area, main channel length, mean annual precipitation, main channel slope, and elevation. However main channel length is itself strongly correlated to drainage area, so much so as to be nearly useless as an explainatory variable when drainage area is retained in a data model. It would be a \"confounding variable\" in this context. Randomization To establish presumptive causality in our data science experiments, we need randomization tools. We can use Python to make psuedo-random choices. There are built-in functions in numpy library under random submodule. The choice function randomly picks one item from an array. The syntax is np.random.choice(array_name) , where array_name is the name of the array from which to make the choice.\u200b #Making Random Choice from an Array (or list) import numpy as np two_groups = np.array(['treatment', 'control']) np.random.choice(two_groups,1) # mylist = ['treatment', 'control'] # this works too # np.random.choice(mylist) array(['treatment'], dtype='<U9') The difference of this function from others that we learned so far, is that it doesn\u2019t give the same result every time. We can roll a dice using this function by randomly selecting from an array from 1 to 6. my_die = np.array(['one', 'two','three', 'four','five', 'six']) np.random.choice(my_die) 'six' # now a bunch of rolls print('roll #1 ',np.random.choice(my_die) ) print('roll #2 ',np.random.choice(my_die) ) print('roll #3 ',np.random.choice(my_die) ) print('roll #4 ',np.random.choice(my_die) ) print('roll #5 ',np.random.choice(my_die) ) print('roll #6 ',np.random.choice(my_die) ) roll #1 four roll #2 four roll #3 four roll #4 five roll #5 six roll #6 one # or multiple rolls, single call myDiceRolls = np.random.choice(my_die,6) print(myDiceRolls) ['six' 'two' 'two' 'six' 'one' 'five'] 'six' We might need to repeat a process multiple times to reach better results or cover more results. Let\u2019s create a game with following rules: If the dice shows 1 or 2 spots, my net gain is -1 dollar. If the dice shows 3 or 4 spots, my net gain is 0 dollars. If the dice shows 5 or 6 spots, my net gain is 1 dollar. my_wallet = 1 # start with 1 dollars def place_a_bet(wallet): print(\"Place your bet!\") if wallet == 0: print(\"You have no money, get out of my Casino!\") return(wallet) else: wallet = wallet - 1 return(wallet) def make_a_roll(wallet): \"\"\"Returns my net gain on one bet\"\"\" print(\"Roll the die!\") x = np.random.choice(np.arange(1, 7)) # roll a die once and record the number of spots if x <= 2: print(\"You Lose, Bummer!\") return(wallet) # lose the bet elif x <= 4: print(\"You Draw, Take your bet back.\") wallet = wallet+1 return(wallet) # draw, get bet back elif x <= 6: print(\"You win a dollar!\") wallet = wallet+2 return (wallet) # win, get bet back and win a dollar! # Single play print(\"Amount in my account =:\",my_wallet) my_wallet = place_a_bet(my_wallet) my_wallet = make_a_roll(my_wallet) print(\"Amount in my account =:\",my_wallet) Amount in my account =: 1 Place your bet! Roll the die! You Lose, Bummer! Amount in my account =: 0 A more automated solution is to use a for statement to loop over the contents of a sequence. Each result is called iteration. Here we use a for statement in a more realistic way: we print the results of betting five times on the die as described earlier. This process is called simulating the results of five bets. We use the word simulating to remind ourselves that we are not physically rolling dice and exchanging money but using Python to mimic the process. # Some printing tricks CRED = '\\033[91m' CEND = '\\033[0m' my_wallet = 10 how_many_throws = 1 for i in range(how_many_throws): print(\"Amount in my account =:\",my_wallet) my_wallet = place_a_bet(my_wallet) my_wallet = make_a_roll(my_wallet) #print(CRED + \"Error, does not compute!\" + CEND) print(\"After \",i+1,\" plays\") print(CRED + \"Amount in my account =:\",my_wallet,CEND) print(\"_______________________\") Amount in my account =: 10 Place your bet! Roll the die! You win a dollar! After 1 plays \u001b[91mAmount in my account =: 11 \u001b[0m _______________________ Simulation of multiple gamblers/multiple visits to the Casino https://www.inferentialthinking.com/chapters/09/3/Simulation.html outcomes = np.array([]) #null array to store outcomes # redefine functions to suppress output def place_a_bet(wallet): # print(\"Place your bet!\") if wallet == 0: # print(\"You have no money, get out of my Casino!\") return(wallet) else: wallet = wallet - 1 return(wallet) def make_a_roll(wallet): \"\"\"Returns my net gain on one bet\"\"\" # print(\"Roll the die!\") x = np.random.choice(np.arange(1, 7)) # roll a die once and record the number of spots if x <= 2: #print(\"You Lose, Bummer!\") return(wallet) # lose the bet elif x <= 4: #print(\"You Draw, Take your bet back.\") wallet = wallet+1 return(wallet) # draw, get bet back elif x <= 6: #print(\"You win a dollar!\") wallet = wallet+2 return (wallet) # win, get bet back and win a dollar! # Some printing tricks CRED = '\\033[91m' CEND = '\\033[0m' how_many_simulations = 100000 for j in range(how_many_simulations): my_wallet = 1 how_many_throws = 30 for i in range(how_many_throws): # print(\"Amount in my account =:\",my_wallet) my_wallet = place_a_bet(my_wallet) my_wallet = make_a_roll(my_wallet) #print(CRED + \"Error, does not compute!\" + CEND) # print(\"After \",i+1,\" plays\") # print(CRED + \"Amount in my account =:\",my_wallet,CEND) # print(\"_______________________\") outcomes = np.append(outcomes,my_wallet) # build a histogram chart - outcomes is an array import matplotlib.pyplot as plt from scipy.stats import gamma #ax.hist(r, density=True, histtype='stepfilled', alpha=0.2) plt.hist(outcomes, density=True, bins = 20) plt.xlabel(\"Dollars in Gamer's Wallet\") plt.ylabel('Relative Frequency') #### just a data model, gamma distribution ############## # code below adapted from https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html a = 5 # bit of trial and error x = np.linspace(gamma.ppf(0.001, a),gamma.ppf(0.999, a), 1000) plt.plot(x, gamma.pdf(x, a, loc=-1.25, scale=1),'r-', lw=5, alpha=1.0, label='gamma pdf') ######################################################### # Render the plot plt.show() #print(\"Expected value of wallet (mean) =: \",outcomes.mean()) import pandas as pd df = pd.DataFrame(outcomes) df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 count 100000.000000 mean 1.632990 std 1.651133 min 0.000000 25% 0.000000 50% 1.000000 75% 2.000000 max 14.000000 Simulation Simulation is the process of using a computer to mimic a real experiment or process. In this class, those experiments will almost invariably involve chance. To summarize from: https://www.inferentialthinking.com/chapters/09/3/Simulation.html Step 1: What to Simulate: Specify the quantity you want to simulate. For example, you might decide that you want to simulate the outcomes of tosses of a coin. Step 2: Simulating One Value: Figure out how to simulate one value of the quantity you specified in Step 1. (usually turn into a function for readability) Step 3: Number of Repetitions: Decide how many times you want to simulate the quantity. You will have to repeat Step 2 that many times. Step 4: Coding the Simulation: Put it all together in code. Step 5: Interpret the results (plots, Simulation Example Should I change my choice? Based on Monty Hall example from https://youtu.be/Xp6V_lO1ZKA But we already have a small car! (Also watch https://www.youtube.com/watch?v=6Ewq_ytHA7g to learn significance of the small car!) Consider The gist of the game is that a contestent chooses a door, the host reveals one of the unselected doors and offers the contestant a chance to change their choice. Should the contestant stick with her initial choice, or switch to the other door? That is the Monty Hall problem. Using classical probability theory it is straightforward to show that: The chance that the car is behind the originally chosen door is 1/3. After Monty opens the door with the goat, the chance distribution changes. If the contestant switches the decision, he/she doubles the chance. Suppose we have harder situations, can we use this simple problem to learn how to ask complex questions? import numpy as np import pandas as pd import matplotlib.pyplot as plt def othergoat(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return \"Goat 2\" elif x == \"Goat 2\": return \"Goat 1\" Doors = np.array([\"Car\",\"Goat 1\",\"Goat 2\"]) #Define a list for objects behind the doors goats = np.array([\"Goat 1\" , \"Goat 2\"]) #Define a list for goats! def MHgame(): #Function to simulate the Monty Hall Game #For each guess, return [\"the guess\",\"the revealed\", \"the remaining\"] userguess=np.random.choice(Doors) #randomly selects a door as userguess if userguess == \"Goat 1\": return [userguess, \"Goat 2\",\"Car\"] if userguess == \"Goat 2\": return [userguess, \"Goat 1\",\"Car\"] if userguess == \"Car\": revealed = np.random.choice(goats) return [userguess, revealed,othergoat(revealed)] # Check and see if the MHgame function is doing what it is supposed to do: for i in np.arange(1): a =MHgame() print(a) print(a[0]) print(a[1]) print(a[2]) ['Goat 1', 'Goat 2', 'Car'] Goat 1 Goat 2 Car c1 = [] #Create an empty list for the userguess c2 = [] #Create an empty list for the revealed c3 = [] #Create an empty list for the remaining how_many_games = 10000 for i in np.arange(how_many_games): #Simulate the game for 1000 rounds - or any other number of rounds you desire game = MHgame() c1.append(game[0]) #In each round, add the first element to the userguess list c2.append(game[1]) #In each round, add the second element to the revealed list c3.append(game[2]) #In each round, add the third element to the remaining list #Create a data frame (gamedf) with 3 columns (\"Guess\",\"Revealed\", \"Remaining\") and 1000 (or how many number of rounds) rows gamedf = pd.DataFrame({'Guess':c1, 'Revealed':c2, 'Remaining':c3}) gamedf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Guess Revealed Remaining 0 Goat 2 Goat 1 Car 1 Goat 1 Goat 2 Car 2 Goat 1 Goat 2 Car 3 Goat 2 Goat 1 Car 4 Goat 2 Goat 1 Car ... ... ... ... 9995 Car Goat 2 Goat 1 9996 Car Goat 1 Goat 2 9997 Car Goat 2 Goat 1 9998 Car Goat 2 Goat 1 9999 Goat 1 Goat 2 Car 10000 rows \u00d7 3 columns # Get the count of each item in the first and 3rd column original_car =gamedf[gamedf.Guess == 'Car'].shape[0] remaining_car =gamedf[gamedf.Remaining == 'Car'].shape[0] original_g1 =gamedf[gamedf.Guess == 'Goat 1'].shape[0] remaining_g1 =gamedf[gamedf.Remaining == 'Goat 1'].shape[0] original_g2 =gamedf[gamedf.Guess == 'Goat 2'].shape[0] remaining_g2 =gamedf[gamedf.Remaining == 'Goat 2'].shape[0] # Let's plot a grouped barplot # set width of bar barWidth = 0.25 # set height of bar bars1 = [original_car,original_g1,original_g2] bars2 = [remaining_car,remaining_g1,remaining_g2] # Set position of bar on X axis r1 = np.arange(len(bars1)) r2 = [x + barWidth for x in r1] # Make the plot plt.bar(r1, bars1, color='darkorange', width=barWidth, edgecolor='white', label='Original Guess') plt.bar(r2, bars2, color='midnightblue', width=barWidth, edgecolor='white', label='Remaining Door') # Add xticks on the middle of the group bars plt.xlabel('Item', fontweight='bold') plt.xticks([r + barWidth/2 for r in range(len(bars1))], ['Car', 'Goat 1', 'Goat 2']) # Create legend & Show graphic plt.legend() plt.show() Interpret Results According to the plot, it is beneficial for the players to switch doors because the initial chance for being correct is only 1/3 Does changing doors have a CAUSAL effect on outcome? ## Various Examples Defect Chances A sample of four electronic components is taken from the output of a production line. The probabilities of the various outcomes are calculated to be: Pr [0 defectives] = 0.6561, Pr [1 defective] = 0.2916, Pr [2 defectives] = 0.0486, Pr [3 defectives] = 0.0036, Pr [4 defectives] = 0.0001. What is the probability of at least one defective? #Method-1 pr_atleast1 = 1-0.6561 print(pr_atleast1) 0.3439 #Method-2 pr_atleast1 = 0.2916+0.0483+0.0036+0.0001 print(pr_atleast1) 0.3436 Common is a Birthday? A class of engineering students consists of 45 people. What is the probability that no two students have birthdays on the same day, not considering the year of birth? To simplify the calculation, assume that there are 365 days in the year and that births are equally likely on all of them. Then what is the probability that some members of the class have birthdays on the same day? Also, vary the number of students in the class from 2 to 200 to see its effect on the probability values. #A student in the class states his birthday. So the probability that he/she has the birthday on that date is 1 pr_first = 1 print(pr_first) 1 #Probability that the second student has different birthday than the first student is 364/365 pr_second = 364/365 print(pr_second) 0.9972602739726028 #Probability that the third student has different birthday than the first and the second students is 363/365 pr_third = 363/365 print(pr_third) 0.9945205479452055 #Probability that the fourth student has different birthday than the first, the second, and the third students is 362/365 pr_fourth = 362/365 print(pr_fourth) 0.9917808219178083 #Probability that none of the 45 students have the same birthday in the class will then be -- # P[no same birthdays] = (1)*(364/365)*(363/365)*(362/365)*........*((365-i+1)/365)*........*((365-45+1)/365) #How will you generalize this? #Method-1: Looping over a list student_ids = list(range(2,46,1)) pr_nosame = 1 for i in student_ids: pr_nosame = pr_nosame*((365-i+1)/365) print(pr_nosame) #Probability that at least one pair out of the 45 students have the same birthday in the class will then be -- # P[same birthday] = 1 - P[no same birthday] pr_same = 1 - pr_nosame print(pr_same) 0.05902410053422507 0.940975899465775 #Probability that none of the 45 students have the same birthday in the class will then be -- # P[no same birthdays] = (1)*(364/365)*(363/365)*(362/365)*........*((365-i+1)/365)*........*((365-45+1)/365) #How will you generalize this? #Method-2: Using NumPy array instead of a list so that we can avoid writing a for loop student_ids = np.arange(2,46,1) pr_eachstudent = ((365-student_ids+1)/365) pr_nosame = np.prod(pr_eachstudent) print(pr_nosame) #Probability that at least one pair out of the 45 students have the same birthday in the class will then be -- # P[same birthday] = 1 - P[no same birthday] pr_same = 1 - pr_nosame print(pr_same) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-19-e397c0f6a5ec> in <module> 7 #Method-2: Using NumPy array instead of a list so that we can avoid writing a for loop 8 ----> 9 student_ids = np.arange(2,46,1) 10 11 pr_eachstudent = ((365-student_ids+1)/365) NameError: name 'np' is not defined #Simulation: Getting the probability for different numbers of total students in the class total_students = np.arange(2,201,1) pr_nosame = [] pr_same = [] for i in total_students: student_ids = np.arange(2,i,1) pr_eachstudent = ((365-student_ids+1)/365) pr_nosame_total = np.prod(pr_eachstudent) pr_nosame.append(pr_nosame_total) pr_same.append(1 - pr_nosame_total) #Creating a dataframe with columns - number of students and probability import pandas as pd final_data = {'Number of students': total_students, 'Probability': pr_same} df = pd.DataFrame(final_data) print(df) #Creating a scatter plot between number of students and probability that at least a pair of students have the same birthday import matplotlib.pyplot as plt plt.scatter(total_students, pr_same, color = 'blue') plt.xlabel('No. of students in the class') plt.ylabel('P [same birthday]') plt.title('Effect of sample size on the chance of success') Making Hole (and money!) An oil company is bidding for the rights to drill a well in field A and a well in field B. The probability it will drill a well in field A is 40%. If it does, the probability the well will be successful is 45%. The probability it will drill a well in field B is 30%. If it does, the probability the well will be successful is 55%. Calculate each of the following probabilities: a) What is the probability of a successful well in field A? pr_successA = 0.40*0.45 pr_successA 0.18000000000000002 b) What is the probability of a successful well in field B? pr_successB = 0.30*0.55 pr_successB 0.165 c) What is the probability of both a successful well in field A and a successful well in field B? pr_successAB = pr_successA*pr_successB pr_successAB 0.029700000000000004 d) What is the probability of at least one successful well in the two fields together? pr_onesuccess = pr_successA + pr_successB - pr_successAB pr_onesuccess 0.3153 e) What is the probability of no successful well in field A? pr_nosuccessA = (1-0.4)+(0.4*0.55) pr_nosuccessA 0.8200000000000001 f) What is the probability of no successful well in field B? pr_nosuccessB = (1-0.3)+(0.3*0.45) pr_nosuccessB 0.835 g) What is the probability of no successful well in the two fields together? pr_nosuccessAB = 1 - pr_onesuccess pr_nosuccessAB 0.6847 h) What is the probability of exactly one successful well in the two fields together? pr_exactonesuccess = (0.18*0.835)+(0.165*0.82) pr_exactonesuccess 0.28559999999999997 References Ford, Martin. 2009 The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future (p. 107). Acculant Publishing. Kindle Edition. Computational and Inferential Thinking: The Foundations of Data Science. By Ani Adhikari and John DeNero, with Contributions by David Wagner and Henry Milner. Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0). https://www.inferentialthinking.com/chapters/09/Randomness.html # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) ! pwd atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) /home/sensei/1330-textbook-webroot/docs/lesson9","title":"Lesson 9"},{"location":"lesson9/lesson9/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 18 February 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson9/lesson9/#lesson-9-data-modeling-statistical-approach","text":"This lesson covers concepts related to modeling data - it is the start of several lessons on the subject. The ultimate goal is to explain observed behavior with a model (like \\textbf{F} = m\\textbf{a} ) so that the model can be used to predict behavior. If we are predicting between existing observations, that's interpolation and is relatively straightforward. If we are predicting beyond existing observations, that's called extrapolation and is less straightforward. To get started we will examine the concepts of causality (cause => effect) and correlation, and the use of simulation to generate probability estimates.","title":"Lesson 9 Data Modeling: Statistical Approach"},{"location":"lesson9/lesson9/#objectives","text":"To understand the fundamental concepts involved in causality; and the difference between cause and correlation. To understand the fundamental concepts involved in iteration. To understand the fundamental concepts involved in simulation","title":"Objectives"},{"location":"lesson9/lesson9/#computational-thinking-concepts","text":"The CT concepts include: Algorithm Design => Causality, Iteration, Simulation System Integration => Iteration, Simulation","title":"Computational Thinking Concepts"},{"location":"lesson9/lesson9/#correlation-and-causality","text":"","title":"Correlation and Causality"},{"location":"lesson9/lesson9/#what-is-causality-a-long-winded-psuedo-definition","text":"Causality is the relationship between causes and effects. The notion of causality does not have a uniform definition in the sciences, and is studied using philosophy and statistics. From the perspective of physics, it is generally believed that causality cannot occur between an effect and an event that is not in the back (past) light cone of said effect. Similarly, a cause could not have an effect outside its front (future) light cone. Here are some recent articles regarding Closed Time Loops, that explains causal consistency. The second paper is by an undergraduate student! https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.125.040605 https://iopscience.iop.org/article/10.1088/1361-6382/aba4bc Both to some extent theoretically support our popular notion of time travel (aka Dr. Who) without pesky paradoxes; someone with creative writing juices, could have a good science fiction career using these papers as a starting thesis! In classical physics, an effect cannot occur before its cause. In Einstein's theory of special relativity, causality means that an effect can not occur from a cause that is not in the back (past) light cone of that event. Similarly, a cause cannot have an effect outside its front (future) light cone. These restrictions are consistent with the assumption that causal influences cannot travel faster than the speed of light and/or backwards in time. In quantum field theory, observables of events with a spacelike relationship, \"elsewhere\", have to commute, so the order of observations or measurements of such observables do not impact each other. Causality in this context should not be confused with Newton's second law, which is related to the conservation of momentum, and is a consequence of the spatial homogeneity of physical laws. The word causality in this context means that all effects must have specific causes. Another requirement, at least valid at the level of human experience, is that cause and effect be mediated across space and time (requirement of contiguity). This requirement has been very influential in the past, in the first place as a result of direct observation of causal processes (like pushing a cart), in the second place as a problematic aspect of Newton's theory of gravitation (attraction of the earth by the sun by means of action at a distance) replacing mechanistic proposals like Descartes' vortex theory; in the third place as an incentive to develop dynamic field theories (e.g., Maxwell's electrodynamics and Einstein's general theory of relativity) restoring contiguity in the transmission of influences in a more successful way than in Descartes' theory. Yada yada bla bla bla ...","title":"What is causality? (A long winded psuedo definition!)"},{"location":"lesson9/lesson9/#correlation-causalitys-mimic","text":"The literary (as in writing!) formulation of causality is a \"why?, because ...\" structure (sort of like if=>then) The answer to a because question, should be the \"cause.\" Many authors use \"since\" to imply cause, but it is incorrect grammar - since answers the question of when? Think \"CAUSE\" => \"EFFECT\" Correlation doesn\u2019t mean cause (although it is a really good predictor of the crap we all buy - its why Amazon is sucessfull) Consider the chart below The correlation between money spent on pets and the number of lawyers is quite good (nearly perfect), so does having pets cause lawyers? Of course not, the general social economic conditions that improve general wealth, and create sufficient disposable income to have pets (here we mean companion animals, not food on the hoof) also creates conditions for laywers to proliferate, hence a good correlation. Nice video : Correlation and Causation https://www.youtube.com/watch?v=1Sa2v7kVEc0 Quoting from http://water.usgs.gov/pubs/twri/twri4a3/ Concentrations of atrazine and nitrate in shallow groundwaters are measured in wells over a several county area. For each sample, the concentration of one is plotted versus the concentration of the other. As atrazine concentrations increase, so do nitrate. How might the strength of this association be measured and summarized? Streams draining the Sierra Nevada mountains in California usually receive less precipitation in November than in other months. Has the amount of November precipitation significantly changed over the last 70 years, showing a gradual change in the climate of the area? How might this be tested? The above situations require a measure of the strength of association between two continuous variables, such as between two chemical concentrations, or between amount of precipitation and time. How do they co-vary? One class of measures are called correlation coefficients. Also important is how the significance of that association can be tested for, to determine whether the observed pattern differs from what is expected due entirely to chance. Whenever a correlation coefficient is calculated, the data should be plotted on a scatterplot. No single numerical measure can substitute for the visual insight gained from a plot. Many different patterns can produce the same correlation coefficient, and similar strengths of relationships can produce differing coefficients, depending on the curvature of the relationship.","title":"Correlation (Causality's mimic!)"},{"location":"lesson9/lesson9/#implications","text":"Most research questions attempt to explain cause and effect. - In experimental research, the relationship is constructed and the experiment is somewhat of a failure if none of the presumed causal (causal == explainatory) variables influence the response (response == effect) - In a data science experimental context, causality may be impossible to establish, however correlations can be established and exploited. In data science, many studies involve observations on a group of individuals, a factor of interest called a treatment (explainatory variable, predictor variable, predictor feature ...), and an outcome (response, effect, state, predicted value ...) measured on each individual. The presumptive establishment of causality takes place in two stages. First, an association is observed. Any relation between the treatment and the outcome is called an association (we can measure the strength of the association using correlation coefficients!). Second, A more careful analysis is used to establish causality. a. One approach would be to control all variables other than the suspected (explainatory) variables, which for any meaningful process is essentially impossible. b. Another approach is to establish randomized control studies: 1. Start with a sample from a population (e.g. volunteers to test Covid 19 vaccines) 2. Randomly assign members to either a. Control group b. Treatment group 3. Expose the two groups identically, except the control group recieves a false (null) treatment 4. Compare the responses of the two groups, if they are same, there exists no evidence that the treatment variable CAUSES a response These concepts can be extended with some ingenuity to engineered systems and natural systems. Consider Data Science Questions: - Does going to school cause flu? - Does flu cause school attendance? - Does going to school contribute to the spread of flu? - Does the spread of flu contribute to the school attendance? - Are there other variables that affects both? a. These are called \u201cconfounding factors\u201d or \u201clurking variables\u201d. b. Cold weather?, more indoor time?, more interaction?","title":"Implications"},{"location":"lesson9/lesson9/#confounding-factors","text":"An underlying difference between the two groups (other than the treatment) is called a confounding factor, because it might confound you (that is, mess you up) when you try to reach a conclusion. For example, Cold weather in the previous example. Confounding also occurs when explainatory variables are correlated to another, for instance flood flows are well correlated to drainage area, main channel length, mean annual precipitation, main channel slope, and elevation. However main channel length is itself strongly correlated to drainage area, so much so as to be nearly useless as an explainatory variable when drainage area is retained in a data model. It would be a \"confounding variable\" in this context.","title":"Confounding Factors"},{"location":"lesson9/lesson9/#randomization","text":"To establish presumptive causality in our data science experiments, we need randomization tools. We can use Python to make psuedo-random choices. There are built-in functions in numpy library under random submodule. The choice function randomly picks one item from an array. The syntax is np.random.choice(array_name) , where array_name is the name of the array from which to make the choice.\u200b #Making Random Choice from an Array (or list) import numpy as np two_groups = np.array(['treatment', 'control']) np.random.choice(two_groups,1) # mylist = ['treatment', 'control'] # this works too # np.random.choice(mylist) array(['treatment'], dtype='<U9') The difference of this function from others that we learned so far, is that it doesn\u2019t give the same result every time. We can roll a dice using this function by randomly selecting from an array from 1 to 6. my_die = np.array(['one', 'two','three', 'four','five', 'six']) np.random.choice(my_die) 'six' # now a bunch of rolls print('roll #1 ',np.random.choice(my_die) ) print('roll #2 ',np.random.choice(my_die) ) print('roll #3 ',np.random.choice(my_die) ) print('roll #4 ',np.random.choice(my_die) ) print('roll #5 ',np.random.choice(my_die) ) print('roll #6 ',np.random.choice(my_die) ) roll #1 four roll #2 four roll #3 four roll #4 five roll #5 six roll #6 one # or multiple rolls, single call myDiceRolls = np.random.choice(my_die,6) print(myDiceRolls) ['six' 'two' 'two' 'six' 'one' 'five'] 'six' We might need to repeat a process multiple times to reach better results or cover more results. Let\u2019s create a game with following rules: If the dice shows 1 or 2 spots, my net gain is -1 dollar. If the dice shows 3 or 4 spots, my net gain is 0 dollars. If the dice shows 5 or 6 spots, my net gain is 1 dollar. my_wallet = 1 # start with 1 dollars def place_a_bet(wallet): print(\"Place your bet!\") if wallet == 0: print(\"You have no money, get out of my Casino!\") return(wallet) else: wallet = wallet - 1 return(wallet) def make_a_roll(wallet): \"\"\"Returns my net gain on one bet\"\"\" print(\"Roll the die!\") x = np.random.choice(np.arange(1, 7)) # roll a die once and record the number of spots if x <= 2: print(\"You Lose, Bummer!\") return(wallet) # lose the bet elif x <= 4: print(\"You Draw, Take your bet back.\") wallet = wallet+1 return(wallet) # draw, get bet back elif x <= 6: print(\"You win a dollar!\") wallet = wallet+2 return (wallet) # win, get bet back and win a dollar! # Single play print(\"Amount in my account =:\",my_wallet) my_wallet = place_a_bet(my_wallet) my_wallet = make_a_roll(my_wallet) print(\"Amount in my account =:\",my_wallet) Amount in my account =: 1 Place your bet! Roll the die! You Lose, Bummer! Amount in my account =: 0 A more automated solution is to use a for statement to loop over the contents of a sequence. Each result is called iteration. Here we use a for statement in a more realistic way: we print the results of betting five times on the die as described earlier. This process is called simulating the results of five bets. We use the word simulating to remind ourselves that we are not physically rolling dice and exchanging money but using Python to mimic the process. # Some printing tricks CRED = '\\033[91m' CEND = '\\033[0m' my_wallet = 10 how_many_throws = 1 for i in range(how_many_throws): print(\"Amount in my account =:\",my_wallet) my_wallet = place_a_bet(my_wallet) my_wallet = make_a_roll(my_wallet) #print(CRED + \"Error, does not compute!\" + CEND) print(\"After \",i+1,\" plays\") print(CRED + \"Amount in my account =:\",my_wallet,CEND) print(\"_______________________\") Amount in my account =: 10 Place your bet! Roll the die! You win a dollar! After 1 plays \u001b[91mAmount in my account =: 11 \u001b[0m _______________________","title":"Randomization"},{"location":"lesson9/lesson9/#simulation-of-multiple-gamblersmultiple-visits-to-the-casino","text":"https://www.inferentialthinking.com/chapters/09/3/Simulation.html outcomes = np.array([]) #null array to store outcomes # redefine functions to suppress output def place_a_bet(wallet): # print(\"Place your bet!\") if wallet == 0: # print(\"You have no money, get out of my Casino!\") return(wallet) else: wallet = wallet - 1 return(wallet) def make_a_roll(wallet): \"\"\"Returns my net gain on one bet\"\"\" # print(\"Roll the die!\") x = np.random.choice(np.arange(1, 7)) # roll a die once and record the number of spots if x <= 2: #print(\"You Lose, Bummer!\") return(wallet) # lose the bet elif x <= 4: #print(\"You Draw, Take your bet back.\") wallet = wallet+1 return(wallet) # draw, get bet back elif x <= 6: #print(\"You win a dollar!\") wallet = wallet+2 return (wallet) # win, get bet back and win a dollar! # Some printing tricks CRED = '\\033[91m' CEND = '\\033[0m' how_many_simulations = 100000 for j in range(how_many_simulations): my_wallet = 1 how_many_throws = 30 for i in range(how_many_throws): # print(\"Amount in my account =:\",my_wallet) my_wallet = place_a_bet(my_wallet) my_wallet = make_a_roll(my_wallet) #print(CRED + \"Error, does not compute!\" + CEND) # print(\"After \",i+1,\" plays\") # print(CRED + \"Amount in my account =:\",my_wallet,CEND) # print(\"_______________________\") outcomes = np.append(outcomes,my_wallet) # build a histogram chart - outcomes is an array import matplotlib.pyplot as plt from scipy.stats import gamma #ax.hist(r, density=True, histtype='stepfilled', alpha=0.2) plt.hist(outcomes, density=True, bins = 20) plt.xlabel(\"Dollars in Gamer's Wallet\") plt.ylabel('Relative Frequency') #### just a data model, gamma distribution ############## # code below adapted from https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html a = 5 # bit of trial and error x = np.linspace(gamma.ppf(0.001, a),gamma.ppf(0.999, a), 1000) plt.plot(x, gamma.pdf(x, a, loc=-1.25, scale=1),'r-', lw=5, alpha=1.0, label='gamma pdf') ######################################################### # Render the plot plt.show() #print(\"Expected value of wallet (mean) =: \",outcomes.mean()) import pandas as pd df = pd.DataFrame(outcomes) df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 count 100000.000000 mean 1.632990 std 1.651133 min 0.000000 25% 0.000000 50% 1.000000 75% 2.000000 max 14.000000","title":"Simulation of multiple gamblers/multiple visits to the Casino"},{"location":"lesson9/lesson9/#simulation","text":"Simulation is the process of using a computer to mimic a real experiment or process. In this class, those experiments will almost invariably involve chance. To summarize from: https://www.inferentialthinking.com/chapters/09/3/Simulation.html Step 1: What to Simulate: Specify the quantity you want to simulate. For example, you might decide that you want to simulate the outcomes of tosses of a coin. Step 2: Simulating One Value: Figure out how to simulate one value of the quantity you specified in Step 1. (usually turn into a function for readability) Step 3: Number of Repetitions: Decide how many times you want to simulate the quantity. You will have to repeat Step 2 that many times. Step 4: Coding the Simulation: Put it all together in code. Step 5: Interpret the results (plots,","title":"Simulation"},{"location":"lesson9/lesson9/#simulation-example","text":"Should I change my choice? Based on Monty Hall example from https://youtu.be/Xp6V_lO1ZKA But we already have a small car! (Also watch https://www.youtube.com/watch?v=6Ewq_ytHA7g to learn significance of the small car!) Consider The gist of the game is that a contestent chooses a door, the host reveals one of the unselected doors and offers the contestant a chance to change their choice. Should the contestant stick with her initial choice, or switch to the other door? That is the Monty Hall problem. Using classical probability theory it is straightforward to show that: The chance that the car is behind the originally chosen door is 1/3. After Monty opens the door with the goat, the chance distribution changes. If the contestant switches the decision, he/she doubles the chance. Suppose we have harder situations, can we use this simple problem to learn how to ask complex questions? import numpy as np import pandas as pd import matplotlib.pyplot as plt def othergoat(x): #Define a function to return \"the other goat\"! if x == \"Goat 1\": return \"Goat 2\" elif x == \"Goat 2\": return \"Goat 1\" Doors = np.array([\"Car\",\"Goat 1\",\"Goat 2\"]) #Define a list for objects behind the doors goats = np.array([\"Goat 1\" , \"Goat 2\"]) #Define a list for goats! def MHgame(): #Function to simulate the Monty Hall Game #For each guess, return [\"the guess\",\"the revealed\", \"the remaining\"] userguess=np.random.choice(Doors) #randomly selects a door as userguess if userguess == \"Goat 1\": return [userguess, \"Goat 2\",\"Car\"] if userguess == \"Goat 2\": return [userguess, \"Goat 1\",\"Car\"] if userguess == \"Car\": revealed = np.random.choice(goats) return [userguess, revealed,othergoat(revealed)] # Check and see if the MHgame function is doing what it is supposed to do: for i in np.arange(1): a =MHgame() print(a) print(a[0]) print(a[1]) print(a[2]) ['Goat 1', 'Goat 2', 'Car'] Goat 1 Goat 2 Car c1 = [] #Create an empty list for the userguess c2 = [] #Create an empty list for the revealed c3 = [] #Create an empty list for the remaining how_many_games = 10000 for i in np.arange(how_many_games): #Simulate the game for 1000 rounds - or any other number of rounds you desire game = MHgame() c1.append(game[0]) #In each round, add the first element to the userguess list c2.append(game[1]) #In each round, add the second element to the revealed list c3.append(game[2]) #In each round, add the third element to the remaining list #Create a data frame (gamedf) with 3 columns (\"Guess\",\"Revealed\", \"Remaining\") and 1000 (or how many number of rounds) rows gamedf = pd.DataFrame({'Guess':c1, 'Revealed':c2, 'Remaining':c3}) gamedf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Guess Revealed Remaining 0 Goat 2 Goat 1 Car 1 Goat 1 Goat 2 Car 2 Goat 1 Goat 2 Car 3 Goat 2 Goat 1 Car 4 Goat 2 Goat 1 Car ... ... ... ... 9995 Car Goat 2 Goat 1 9996 Car Goat 1 Goat 2 9997 Car Goat 2 Goat 1 9998 Car Goat 2 Goat 1 9999 Goat 1 Goat 2 Car 10000 rows \u00d7 3 columns # Get the count of each item in the first and 3rd column original_car =gamedf[gamedf.Guess == 'Car'].shape[0] remaining_car =gamedf[gamedf.Remaining == 'Car'].shape[0] original_g1 =gamedf[gamedf.Guess == 'Goat 1'].shape[0] remaining_g1 =gamedf[gamedf.Remaining == 'Goat 1'].shape[0] original_g2 =gamedf[gamedf.Guess == 'Goat 2'].shape[0] remaining_g2 =gamedf[gamedf.Remaining == 'Goat 2'].shape[0] # Let's plot a grouped barplot # set width of bar barWidth = 0.25 # set height of bar bars1 = [original_car,original_g1,original_g2] bars2 = [remaining_car,remaining_g1,remaining_g2] # Set position of bar on X axis r1 = np.arange(len(bars1)) r2 = [x + barWidth for x in r1] # Make the plot plt.bar(r1, bars1, color='darkorange', width=barWidth, edgecolor='white', label='Original Guess') plt.bar(r2, bars2, color='midnightblue', width=barWidth, edgecolor='white', label='Remaining Door') # Add xticks on the middle of the group bars plt.xlabel('Item', fontweight='bold') plt.xticks([r + barWidth/2 for r in range(len(bars1))], ['Car', 'Goat 1', 'Goat 2']) # Create legend & Show graphic plt.legend() plt.show()","title":"Simulation Example"},{"location":"lesson9/lesson9/#interpret-results","text":"According to the plot, it is beneficial for the players to switch doors because the initial chance for being correct is only 1/3 Does changing doors have a CAUSAL effect on outcome? ## Various Examples","title":"Interpret Results"},{"location":"lesson9/lesson9/#defect-chances","text":"A sample of four electronic components is taken from the output of a production line. The probabilities of the various outcomes are calculated to be: Pr [0 defectives] = 0.6561, Pr [1 defective] = 0.2916, Pr [2 defectives] = 0.0486, Pr [3 defectives] = 0.0036, Pr [4 defectives] = 0.0001. What is the probability of at least one defective? #Method-1 pr_atleast1 = 1-0.6561 print(pr_atleast1) 0.3439 #Method-2 pr_atleast1 = 0.2916+0.0483+0.0036+0.0001 print(pr_atleast1) 0.3436","title":"Defect Chances"},{"location":"lesson9/lesson9/#common-is-a-birthday","text":"A class of engineering students consists of 45 people. What is the probability that no two students have birthdays on the same day, not considering the year of birth? To simplify the calculation, assume that there are 365 days in the year and that births are equally likely on all of them. Then what is the probability that some members of the class have birthdays on the same day? Also, vary the number of students in the class from 2 to 200 to see its effect on the probability values. #A student in the class states his birthday. So the probability that he/she has the birthday on that date is 1 pr_first = 1 print(pr_first) 1 #Probability that the second student has different birthday than the first student is 364/365 pr_second = 364/365 print(pr_second) 0.9972602739726028 #Probability that the third student has different birthday than the first and the second students is 363/365 pr_third = 363/365 print(pr_third) 0.9945205479452055 #Probability that the fourth student has different birthday than the first, the second, and the third students is 362/365 pr_fourth = 362/365 print(pr_fourth) 0.9917808219178083 #Probability that none of the 45 students have the same birthday in the class will then be -- # P[no same birthdays] = (1)*(364/365)*(363/365)*(362/365)*........*((365-i+1)/365)*........*((365-45+1)/365) #How will you generalize this? #Method-1: Looping over a list student_ids = list(range(2,46,1)) pr_nosame = 1 for i in student_ids: pr_nosame = pr_nosame*((365-i+1)/365) print(pr_nosame) #Probability that at least one pair out of the 45 students have the same birthday in the class will then be -- # P[same birthday] = 1 - P[no same birthday] pr_same = 1 - pr_nosame print(pr_same) 0.05902410053422507 0.940975899465775 #Probability that none of the 45 students have the same birthday in the class will then be -- # P[no same birthdays] = (1)*(364/365)*(363/365)*(362/365)*........*((365-i+1)/365)*........*((365-45+1)/365) #How will you generalize this? #Method-2: Using NumPy array instead of a list so that we can avoid writing a for loop student_ids = np.arange(2,46,1) pr_eachstudent = ((365-student_ids+1)/365) pr_nosame = np.prod(pr_eachstudent) print(pr_nosame) #Probability that at least one pair out of the 45 students have the same birthday in the class will then be -- # P[same birthday] = 1 - P[no same birthday] pr_same = 1 - pr_nosame print(pr_same) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-19-e397c0f6a5ec> in <module> 7 #Method-2: Using NumPy array instead of a list so that we can avoid writing a for loop 8 ----> 9 student_ids = np.arange(2,46,1) 10 11 pr_eachstudent = ((365-student_ids+1)/365) NameError: name 'np' is not defined #Simulation: Getting the probability for different numbers of total students in the class total_students = np.arange(2,201,1) pr_nosame = [] pr_same = [] for i in total_students: student_ids = np.arange(2,i,1) pr_eachstudent = ((365-student_ids+1)/365) pr_nosame_total = np.prod(pr_eachstudent) pr_nosame.append(pr_nosame_total) pr_same.append(1 - pr_nosame_total) #Creating a dataframe with columns - number of students and probability import pandas as pd final_data = {'Number of students': total_students, 'Probability': pr_same} df = pd.DataFrame(final_data) print(df) #Creating a scatter plot between number of students and probability that at least a pair of students have the same birthday import matplotlib.pyplot as plt plt.scatter(total_students, pr_same, color = 'blue') plt.xlabel('No. of students in the class') plt.ylabel('P [same birthday]') plt.title('Effect of sample size on the chance of success')","title":"Common is a Birthday?"},{"location":"lesson9/lesson9/#making-hole-and-money","text":"An oil company is bidding for the rights to drill a well in field A and a well in field B. The probability it will drill a well in field A is 40%. If it does, the probability the well will be successful is 45%. The probability it will drill a well in field B is 30%. If it does, the probability the well will be successful is 55%. Calculate each of the following probabilities: a) What is the probability of a successful well in field A? pr_successA = 0.40*0.45 pr_successA 0.18000000000000002 b) What is the probability of a successful well in field B? pr_successB = 0.30*0.55 pr_successB 0.165 c) What is the probability of both a successful well in field A and a successful well in field B? pr_successAB = pr_successA*pr_successB pr_successAB 0.029700000000000004 d) What is the probability of at least one successful well in the two fields together? pr_onesuccess = pr_successA + pr_successB - pr_successAB pr_onesuccess 0.3153 e) What is the probability of no successful well in field A? pr_nosuccessA = (1-0.4)+(0.4*0.55) pr_nosuccessA 0.8200000000000001 f) What is the probability of no successful well in field B? pr_nosuccessB = (1-0.3)+(0.3*0.45) pr_nosuccessB 0.835 g) What is the probability of no successful well in the two fields together? pr_nosuccessAB = 1 - pr_onesuccess pr_nosuccessAB 0.6847 h) What is the probability of exactly one successful well in the two fields together? pr_exactonesuccess = (0.18*0.835)+(0.165*0.82) pr_exactonesuccess 0.28559999999999997","title":"Making Hole (and money!)"},{"location":"lesson9/lesson9/#references","text":"Ford, Martin. 2009 The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future (p. 107). Acculant Publishing. Kindle Edition. Computational and Inferential Thinking: The Foundations of Data Science. By Ani Adhikari and John DeNero, with Contributions by David Wagner and Henry Milner. Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0). https://www.inferentialthinking.com/chapters/09/Randomness.html # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) ! pwd atomickitty sensei /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) /home/sensei/1330-textbook-webroot/docs/lesson9","title":"References"},{"location":"scraps/about/","text":"About this document Put something here about the document, authors, copyright (GPL or MIT Open License) On-Line Book Author's Notes Inserting Code Fragments To insert a code fragment such as print('Hello World') simply indent in the source file used to generate the document print('hello world') These fragments can be cut-and-paste into a JupyterLab notebook. Inserting Images If the image is taken from a URL, use the following: ![image-name (a local tag)](url_to_image_source) Such as: ![image-name](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQqn40YbupkMAzY63jYtA6auEmjRfCOvCd0FA&usqp=CAU) Which will render a black swan: If the image is local to the host replace the url with the path to the image. Inserting URL links This is a variation of images, but without the ! , such as [link-name-that-will-display](url_to_link_destimation) For example the code below will link to the black swan search results: [link-to-images-of-black-swans](https://www.google.com/search?q=images+of+black+swan&client=safari&rls=en&sxsrf=ALeKk03oIoQ387TWjJoKzX-D_b7o1to43Q:1613002985584&tbm=isch&source=iu&ictx=1&fir=L2P5MiS1ICLTxM%252CC6BDdJoXT9KcEM%252C_&vet=1&usg=AI4_-kTXrBMpj__xL5IkGCshrXTp04fX3w&sa=X&ved=2ahUKEwiCneivyODuAhVJBs0KHY88CaAQ9QF6BAgUEAE&biw=1447&bih=975#imgrc=i_lxoojURNE3XM) link-to-images-of-black-swans","title":"About this document"},{"location":"scraps/about/#about-this-document","text":"Put something here about the document, authors, copyright (GPL or MIT Open License)","title":"About this document"},{"location":"scraps/about/#on-line-book-authors-notes","text":"Inserting Code Fragments To insert a code fragment such as print('Hello World') simply indent in the source file used to generate the document print('hello world') These fragments can be cut-and-paste into a JupyterLab notebook. Inserting Images If the image is taken from a URL, use the following: ![image-name (a local tag)](url_to_image_source) Such as: ![image-name](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQqn40YbupkMAzY63jYtA6auEmjRfCOvCd0FA&usqp=CAU) Which will render a black swan: If the image is local to the host replace the url with the path to the image. Inserting URL links This is a variation of images, but without the ! , such as [link-name-that-will-display](url_to_link_destimation) For example the code below will link to the black swan search results: [link-to-images-of-black-swans](https://www.google.com/search?q=images+of+black+swan&client=safari&rls=en&sxsrf=ALeKk03oIoQ387TWjJoKzX-D_b7o1to43Q:1613002985584&tbm=isch&source=iu&ictx=1&fir=L2P5MiS1ICLTxM%252CC6BDdJoXT9KcEM%252C_&vet=1&usg=AI4_-kTXrBMpj__xL5IkGCshrXTp04fX3w&sa=X&ved=2ahUKEwiCneivyODuAhVJBs0KHY88CaAQ9QF6BAgUEAE&biw=1447&bih=975#imgrc=i_lxoojURNE3XM) link-to-images-of-black-swans","title":"On-Line Book Author's Notes"},{"location":"syllabus/syllabus/","text":"%%html <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} ENGR 1330 Computational Thinking with Data Science Course Description: Introducion to Python programming, its relevant modules and libraries, and computational thinking for solving problems in Data Science. Data science approaches for importing, manipulating, and analyzing data. Modeling and visualizing real-world data sets in various science and engineering disciplines. 3 credit hours comprising of lectures and hands-on lab sessions. This course provides a hands-on learning experience in programming and data science using iPython and JupyterLab. iPython is the interactive python kernel implemented in JupyterLab. Prerequisites: Prior programming background is NOT required. The course is intended for first-year WCOE students (aka engineering foundational) COVID-19 Important Guidelines: If Texas Tech University campus operations are required to change because of health concerns related to the COVID-19 pandemic, it is possible that this course will move to a fully online delivery format. Should that be necessary, students will be advised of technical and/or equipment requirements, including remote proctoring software. Policy on absences resulting from illness: We anticipate that some students may have extended absences. To avoid students feeling compelled to attend in-person class periods when having symptoms or feeling unwell, a standard policy is provided that holds students harmless for illness-related absences (see Section A below). A. Illness-Based Absence Policy (Face-to-Face Classes) If at any time during the semester you are ill, in the interest of your own health and safety as well as the health and safety of your instructors and classmates, you are encouraged not to attend face-to-face class meetings or events. Please review the steps outlined below that you should follow to ensure your absence for illness will be excused. These steps also apply to not participating in synchronous online class meetings if you feel too ill to do so and missing specified assignment due dates in asynchronous online classes because of illness. If you are ill and think the symptoms might be COVID-19-related: Call Student Health Services at 806.743.2848 or your health care provider. During after-hours and on weekends, contact TTU COVID-19 Helpline at TBD. Self-report as soon as possible using the Dean of Students COVID-19 webpage. This website has specific directions about how to upload documentation from a medical provider and what will happen if your illness renders you unable to participate in classes for more than one week. If your illness is determined to be COVID-19-related, all remaining documentation and communication will be handled through the Office of the Dean of Students, including notification of your instructors of the time you may be absent from and may return to classes. If your illness is determined not to be COVID-19-related, please follow steps 2.a-d below. If you are ill and can attribute your symptoms to something other than COVID-19: If your illness renders you unable to attend face-to-face classes, participate in synchronous online classes, or miss specified assignment due dates in asynchronous online classes, you are encouraged to contact either Student Health Services at 806.743.2848 or your health care provider. Note that Student Health Services and your own and other health care providers may arrange virtual visits. During the health provider visit, request a \u201creturn to school\u201d note. E-mail the instructor a picture of that note. Return to class by the next class period after the date indicated on your note. Following the steps outlined above helps to keep your instructors informed about your absences and ensures your absence or missing an assignment due date because of illness will be marked excused. You will still be responsible to complete within a week of returning to class any assignments, quizzes, or exams you miss because of illness. B. Illness-Based Absence Policy (Telepresence/On-Line Classes) Same as above with respect potential to infect others; go to a health care provider if you are ill. Telepresence courses are recorded and will be available on TTU MediaSite and/or YouTube (unlisted). Exercises, Quizzes, and Examinations are all administered by a Learning Management System (Blackboard) and students need to allow enough time to complete and upload their work. Due date adjustments/late submits on case-by-case basis; documentation required as in subsection A above. Course Sections Lesson time, days, and location: Section D04; CRN 64436; 1000-1120 T, TH ; Telepresence Lab Section D66; CRN 64441; 1130-1250 T, TH Section D01; CRN 63306; 1000-1120 T, TH ; Telepresence Lab Section D61; CRN 63744; 1130-1250 T, TH Course Instructor: Instructor: Theodore G. Cleveland, Ph.D., P.E., M. ASCE, F. EWRI Email: theodore.cleveland@ttu.edu (put ENGR 1330 in subject line for email related to this class) Office location: Telepresence ( Zoom ) Office hours: 1000-1100 M, 1600-1700 W or by appointment (meetings will be by Zoom call) Teaching Assistant: Teaching Assistant: Farhang Forghanparast, MSCE Email : Farhang.Forghanparast@ttu.edu Office location: Telepresence ( Zoom ) Office hours: 0900-1000 M; 1700-1800 W Textbook: Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0). Link: https://www.inferentialthinking.com/chapters/intro. Course Contents: Computational thinking for problem-solving: Logical problem solving, decomposition, pattern recognition, abstraction, representation, algorithm design, and generalization. Python Programming: Variables, constants, data types, data structures, strings, math operators boolean operators, expressions, program constructs, functions, looping, I/O files, modules, and database. Data science fundamentals: Experimental setup: Importing and formatting data sets, Displaying data, Data pre-processing. Introductory statistical analysis with Python: Elementary statistics, randomness, sampling, probability distributions, Confidence intervals, hypothesis testing, and A/B testing. Basic data analysis, visualization, and machine learning: Data pre-processing, Supervised/unsupervised learning, Performance evaluation metrics. Learning Outcomes: On completion of the course, students will have * Created Python programs employing computational thinking concepts to * Employed Python libraries relevant to data science. * Downloaded data files from selected public sources and analyzed content. * Created scripts to perform fundamental data analytics and basic visualization. ABET Student Outcomes Engineering: An ability to identify, formulate, and solve complex engineering problems by applying principles of engineering, science, and mathematics. An ability to acquire and apply new knowledge as needed, using appropriate learning strategies. Computer Science: Analyze a complex computing problem and to apply principles of computing and other relevant disciplines to identify solutions. Design, implement, and evaluate a computing-based solution to meet a given set of computing requirements in the context of the program\u2019s discipline. Resources/Tools Platforms for Python Programming (for your own computers) Anaconda platform (https://www.anaconda.com/): Anaconda distribution is an open-source Data Science Distribution Development Platform. It includes Python 3 with over 1,500 data science packages making it easy to manage libraries and dependencies. Available in Linux, Windows, and Mac OS X. Jupyter (https://jupyter.org/): JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data. JupyterLab is flexible: Configure and arrange the user interface to support a wide range of workflows in data science, scientific computing, and machine learning. note Anaconda for MacOS includes a JupyterLab instance, so a separate install is not required. Additional Modules for Python Programming Math module (https://docs.python.org/3/library/math.html): Gives access to the mathematical functions defined by the C standard e.g. factorial, gcd, exponential, logarithm. Operator module (https://docs.python.org/3/library/operator.html): Helps in exporting a set of efficient functions corresponding to the intrinsic operators of Python. For example, the operator add(x,y) is equivalent to the expression x+y. Python Modules for Data Science Scipy module (https://www.scipy.org/): A Python-based ecosystem of open-source software for mathematics, science, and engineering. Some of the core packages are: Numpy: Provides n-dimensional array package Scipy: Fundamental for scientific computing (e.g. linear algorithm, optimization) Matplotlib: Visualizations/2D plotting IPython: Enhanced interactive console <<= this is the kernel used in JupyterLab Pandas: Data structures and data analysis Scikit-learn module (https://scikit-learn.org/stable/): A library for machine learning in Python. It is a simple and efficient tool for predictive data analysis. It is built on NumPy, SciPy, and matplotlib modules. On-Line Options AWS Lightsail Instance (use Windows Server 2000 template; lowest resource provision tier; AWS RDP client, or download and install own RDP client) Then install Anaconda onto the AWS Instance Hardware Requirements Minimal, in fact this syllabus was created using a JupyterLab notebook (as a markdown processor) on a Raspberry Pi 4B, which technically cannot support a JupyterHub, but does. Your current laptop should be fine, or if you only have a chromebook, build an AWS instance. The college of engineering has specific laptop requirements for your other courses that are listed at https://www.depts.ttu.edu/coe/dean/engineeringitservices/buyingtherightcomputer.php Content Server Blackboard is used as the learning management system (LMS) for this class, and it uses web links to a content server at https://3.137.111.182/engr-1330-webroot/ The Blackboard links will generally go directly to a section in the webroot, but feel free to explore by going in the front door! Course Schedule Item Lesson Lab JupyterLab(Python Kernel) and Programming 21Jan2021 Lesson 0 Introduction to Computational Thinking with Data Science: - Computational thinking concepts - Python as a programming environment - Data science and practices - CCMR Approach Computing Environment set up: - Installing Anaconda (Win/MacOS/AWS) \u2013 Jupyter notebooks - Simple Examples 26Jan2021 Lesson 1 Programming Fundamentals: - Data types (int, float, string, bool) - Variables, operators, expressions, basic I/O - String functions and operations Introduction to Python - Data types (e.g. int, float, string, bool) - Expressions 28Jan2021 Lesson 2 Programming Fundamentals: - Data structures: Array, list, tuple, set, dictionary - Conditional statements Introduction to Python - Data structures - Conditional statements 2Feb2021 Lesson 3 Programming Fundamentals: - Loops - Flowcharts Introduction to Python - Loops 4Feb2021 Lesson 4 Programming Fundamentals: - Functions - Variable scope Introduction to Python - Functions - Variable scope 9Feb2021 Lesson 5 Programming Fundamentals: - Class and objects - File handling Introduction to Python - Class and objects - File handling Data Science External Modules 11Feb2021 Lesson 6 Data Representation and Operations: Python library: NumPy - Data representation: Arrays, vectors, matrices - Data operations: Indexing, math functions Exercises on NumPy 16Feb2021 Lesson 7 Data Query and Manipulation: Python Library: Pandas - Data frames: - Create, index, summarize statistics - fill and drop values - read/write to file Exercises on Pandas 18Feb2021 Lesson 8 Data Display: Python Libraries: Matplotlib - Graphing Conventions - Data Display for line charts, bar charts, box plot, scatter plot, and histograms Exercises on data display 23Feb2021 Lesson 9 Data Modeling: - Establishing causality - Randomness - Models as Preciction Machines Exercises on causality and simulation 25Feb2021 Review for Exam-1 (Lessons 0-9) Exam-1 - LMS administered Data Modeling: Statistical Approaches 2Mar2021 Lesson 10 Randomness and Probabilities: - Sampling - Empirical distributions Exercises on probabilities 4Mar2021 Lesson 11 Descriptive Statistics - Location/Center (mean, median,mode) - Dispersion/Spread (variance, standard deviation) - Asymmetry/Skew (Coefficient of Skewness) Descriptive Statistics 9Mar2021 Lesson 12 Distributions: - Normal, LogNormal - Gamma, Weibull - Extreme Value (Gumbell) Exercises on sampling 11Mar2021 Lesson 13 Probability Estimation Modeling - Ranking, order, plotting position - Distribution Fitting ; Method Of Moments; Maximum Likelihood Estimation Exercises 16Mar2021 Lesson 14 Hypothesis testing: - General concept - Assessing data models. Exercises on hypothesis testing 18Mar2021 Lesson 15 Hypothesis testing: -Comparing proportions - Type1 & Type2 errors - Attained significance (p-value) Exercises on hypothesis testing 23Mar2021 Lesson 16 Comparing two samples: A/B Testing Exercises on A/B testing 25Mar2021 Review for Exam-2 (Lessons 10-16) Exam-2 - LMS administered 30Mar2021 17. Confidence intervals Exercises Data Modeling: Regression (Model Fitting) Approaches 1Apr2021 18. Data Modeling: Regression Approach - Linear algebra of equation fitting Exercises 6Apr2021 19. Estimation Modeling by Regression: - Ordinary least squares (OLS) regression - Weighted least squares - Explanitory variables (features) - Response variable(s) exre 8Apr2021 20. Estimation Modeling by Regression: - Residuals - Performance metrics: Accuracy, error - Inference exercises 13Apr2021 21. Estimation Modeling by Regression: - Logistic Regression (a type of classification) Exercises on sample means Data Modeling: Machine Learning Approaches 15Apr2021 22. Data Modeling : The Machine Learning Approach: - Correlation - Training (a model fitting analog) - Confusion matrix, precision, recall, accuracy, F-score. - Making decisions Final projects selection - Project choices - Delivery schedule 20Apr2021 Lesson 23 Evaluation and Making Decisions: - Confusion matrix, precision, recall, accuracy, F-score. - Making decisions KNN with evaluation 22Apr2021 Lesson 24 Classification: - K Nearest Neighbor (KNN) More KNN Demonstration/Examples 27Apr2021 Review for Exam-3 (Lessons 17-24) Exam 3 - LMS administered 29Apr2021 Lesson 25 Classification: - Support Vector Machines (SVM) SVM Demonstration/Examples 4May2021 Lesson 26 Classification: - Artifical Neural Networks (ANN) ANN Demonstration 11May2021 Final Project Report and Link to Video Course Assessment and Grading Criteria: There will be three exams and one comprehensive final project for this course. An AI-supervised online community using the Packback Questions (https://www.packback.co) platform will be used for online discussion about class topics. The platform is the place to pose questions and answers and share codes and problems. Face-to-face sections do not use packback, and use a different scoring distribution In addition, lab notebooks, quizzes, and homework assignments also contribute to the final grade. Late assignments will not be scored. Grades will be based on the following components; weighting is approximate: Assessment Instrument Weight(%) Exam-1 10 Exam-2 10 Exam-3 15 Lab Notebooks & Homework 30 Quizzes 10 Packback 15 Final project 10 Overall total 100 Letter grades will be assigned using the following proportions: Normalized Score Range Letter Grade \u2265 90 A 80-89 B 70-79 C 55-69 D < 55 F Packback Questions Environment Participation is a requirement for this course, and the Packback Questions platform will be used for online discussion about class topics. Packback Questions is an online community where you can be fearlessly curious and ask open-ended questions to build on top of what we are covering in class and relate topics to real-world applications. Packback Requirements: Your participation on Packback will count toward 15% of your overall course grade. There will be a Weekly Sunday at 10:00PM CST deadline for submissions. In order to receive your points per week, you should submit the following per each deadline period: 1 open-ended Question per week with a minimum Curiosity Score of 30, each worth 33.33% of each assignment grade 2 Responses per week with a minimum Curiosity Score of 30, each worth 66.67% of each assignment grade Half credit will be provided for questions and responses that do not meet the minimum curiosity score. How to Register on Packback: An email invitation will be sent to you from help@packback.co prompting you to finish registration. If you don\u2019t receive an email (be sure to check your spam), you may register by following the instructions below: Create an account by navigating to https://questions.packback.co and clicking \u201cSign up for an Account\u201d Note: If you already have an account on Packback you can log in with your credentials. Then enter our class community\u2019s lookup key into the \u201cLooking to join a community you don't see here?\u201d section in Packback at the bottom of the homepage. Community Lookup Key: 1e3bb85a-ddb2-456a-a8fc-178ead55206d Follow the instructions on your screen to finish your registration. Packback will require a paid subscription (~$25). Refer to www.packback.co/product/pricing for more information. How to Get Help from the Packback Team: If you have any questions or concerns about Packback throughout the semester, please read their FAQ at help.packback.co. If you need more help, contact their customer support team directly at help@packback.co. For a brief introduction to Packback Questions and why we are using it in class, watch this video: vimeo.com/packback/Welcome-to-Packback-Questions Classroom Policy: The following activities are not allowed in the classroom: Texting or talking on the cellphone or other electronic devices, and reading non-course related materials. Telepresence (On-line) Courses Obviously electronic devices are vital; disrupting the conference is prohibited, please mute your microphone unless you have a question - consider typing your question into the chat window as well. Be aware of bandwidth issues and remember most lessons and laboratory sessions are recorded and posted on youtube. Recording, editing, and rendering takes awhile, so expect 24-36 hour delay before video is available. ADA Statement: Any student who, because of a disability, may require special arrangements in order to meet the course requirements should contact the instructor as soon as possible to make necessary arrangements. Students must present appropriate verification from Student Disability Services during the instructor's office hours. Please note that instructors are not allowed to provide classroom accommodation to a student until appropriate verification from Student Disability Services has been provided. For additional information, please contact Student Disability Services office in 335 West Hall or call 806.742.2405. Academic Integrity Statement: Academic integrity is taking responsibility for one\u2019s own class and/or course work, being individually accountable, and demonstrating intellectual honesty and ethical behavior. Academic integrity is a personal choice to abide by the standards of intellectual honesty and responsibility. Because education is a shared effort to achieve learning through the exchange of ideas, students, faculty, and staff have the collective responsibility to build mutual trust and respect. Ethical behavior and independent thought are essential for the highest level of academic achievement, which then must be measured. Academic achievement includes scholarship, teaching, and learning, all of which are shared endeavors. Grades are a device used to quantify the successful accumulation of knowledge through learning. Adhering to the standards of academic integrity ensures grades are earned honestly. Academic integrity is the foundation upon which students, faculty, and staff build their educational and professional careers. [Texas Tech University (\u201cUniversity\u201d) Quality Enhancement Plan, Academic Integrity Task Force, 2010]. Religious Holy Day Statement: \u201cReligious holy day\u201d means a holy day observed by a religion whose places of worship are exempt from property taxation under Texas Tax Code \u00a711.20. A student who intends to observe a religious holy day should make that intention known to the instructor prior to the absence. A student who is absent from classes for the observance of a religious holy day shall be allowed to take an examination or complete an assignment scheduled for that day within a reasonable time after the absence. A student who is excused may not be penalized for the absence; however, the instructor may respond appropriately if the student fails to complete the assignment satisfactorily. Ethical Conduct Policy: Cheating is prohibited, and the representation of the work of another person as your own will be grounds for receiving a failing grade in the course. DISCRIMINATION, HARASSMENT, AND SEXUAL VIOLENCE STATEMENT: Texas Tech University is committed to providing and strengthening an educational, working, and living environment where students, faculty, staff, and visitors are free from gender and/or sex discrimination of any kind. Sexual assault, discrimination, harassment, and other Title IX violations are not tolerated by the University. Report any incidents to the Office for Student Rights & Resolution, (806)-742-SAFE (7233) or file a report online at titleix.ttu.edu/students. Faculty and staff members at TTU are committed to connecting you to resources on campus. Some of these available resources are: TTU Student Counseling Center, 806- 742-3674, https://www.depts.ttu.edu/scc/(Provides confidential support on campus.) TTU 24-hour Crisis Helpline, 806-742-5555, (Assists students who are experiencing a mental health or interpersonal violence crisis. If you call the helpline, you will speak with a mental health counselor.) Voice of Hope Lubbock Rape Crisis Center, 806-763-7273, voiceofhopelubbock.org (24-hour hotline that provides support for survivors of sexual violence.) The Risk, Intervention, Safety and Education (RISE) Office, 806-742-2110, https://www.depts.ttu.edu/rise/ (Provides a range of resources and support options focused on prevention education and student wellness.) Texas Tech Police Department, 806-742- 3931,http://www.depts.ttu.edu/ttpd/ (To report criminal activity that occurs on or near Texas Tech campus.) CIVILITY IN THE CLASSROOM STATEMENT: Texas Tech University is a community of faculty, students, and staff that enjoys an expectation of cooperation, professionalism, and civility during the conduct of all forms of university business, including the conduct of student\u2013student and student\u2013faculty interactions in and out of the classroom. Further, the classroom is a setting in which an exchange of ideas and creative thinking should be encouraged and where intellectual growth and development are fostered. Students who disrupt this classroom mission by rude, sarcastic, threatening, abusive or obscene language and/or behavior will be subject to appropriate sanctions according to university policy. Likewise, faculty members are expected to maintain the highest standards of professionalism in all interactions with all constituents of the university. To ensure that you are fully engaged in class discussions and account team meetings during class time, you are expected to do the following: - Maintain the same level of civility and professionalism that would be expected in a face-to-face classroom setting. - Attend all classes regularly. - Log into the video conference on time and remain logged in for the duration of the class period. - Activate your camera so that you are visible to the instructor and other students in the class. If you have concerns about leaving your camera on (such as childcare obligations, privacy issues, or a particular circumstance during a class period), please talk to the instructor. - Refrain from engaging in non-class related activities during class time that create a distraction for other students in the class and/or limit your ability to engage in the course. Failure to meet these expectations may result in the following consequences: 1. Being counted as absent for the class meeting. 2. Not receiving credit for class participation for that class period. 3. Other consequences as stipulated in the syllabus, Texas Tech Code of Student Conduct, or other university policy. Repeated failure to meet expectations (e.g., attendance, participation in class, etc.), in addition to the above consequences, may result in the one or more of the following consequences: 1. Referral to the appropriate Associate Dean. 2. Academic penalty, ranging from a warning to failure of the course. (www.depts.ttu.edu/ethics/matadorchallenge/ethicalprinciples.php). LGBTQIA SUPPORT STATEMENT: I identify as an ally to the lesbian, gay, bisexual, transgender, queer, intersex, and asexual (LGBTQIA) community, and I am available to listen and support you in an affirming manner. I can assist in connecting you with resources on campus to address problems you may face pertaining to sexual orientation and/or gender identity that could interfere with your success at Texas Tech. Please note that additional resources are available through the Office of LGBTQIA within the Center for Campus Life, Student Union Building Room 201, www.lgbtqia.ttu.edu, 806.742.5433.\u201d Office of LGBTQIA, Student Union Building Room 201, www.lgbtqia.ttu.edu, 806.742.5433 Within the Center for Campus Life, the Office serves the Texas Tech community through facilitation and leadership of programming and advocacy efforts. This work is aimed at strengthening the lesbian, gay, bisexual, transgender, queer, intersex, and asexual (LGBTQIA) community and sustaining an inclusive campus that welcomes people of all sexual orientations, gender identities, and gender expressions.","title":"Syllabus"},{"location":"syllabus/syllabus/#engr-1330-computational-thinking-with-data-science","text":"","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"syllabus/syllabus/#course-description","text":"Introducion to Python programming, its relevant modules and libraries, and computational thinking for solving problems in Data Science. Data science approaches for importing, manipulating, and analyzing data. Modeling and visualizing real-world data sets in various science and engineering disciplines. 3 credit hours comprising of lectures and hands-on lab sessions. This course provides a hands-on learning experience in programming and data science using iPython and JupyterLab. iPython is the interactive python kernel implemented in JupyterLab.","title":"Course Description:"},{"location":"syllabus/syllabus/#prerequisites","text":"Prior programming background is NOT required. The course is intended for first-year WCOE students (aka engineering foundational)","title":"Prerequisites:"},{"location":"syllabus/syllabus/#covid-19-important-guidelines","text":"If Texas Tech University campus operations are required to change because of health concerns related to the COVID-19 pandemic, it is possible that this course will move to a fully online delivery format. Should that be necessary, students will be advised of technical and/or equipment requirements, including remote proctoring software. Policy on absences resulting from illness: We anticipate that some students may have extended absences. To avoid students feeling compelled to attend in-person class periods when having symptoms or feeling unwell, a standard policy is provided that holds students harmless for illness-related absences (see Section A below).","title":"COVID-19 Important Guidelines:"},{"location":"syllabus/syllabus/#a-illness-based-absence-policy-face-to-face-classes","text":"If at any time during the semester you are ill, in the interest of your own health and safety as well as the health and safety of your instructors and classmates, you are encouraged not to attend face-to-face class meetings or events. Please review the steps outlined below that you should follow to ensure your absence for illness will be excused. These steps also apply to not participating in synchronous online class meetings if you feel too ill to do so and missing specified assignment due dates in asynchronous online classes because of illness. If you are ill and think the symptoms might be COVID-19-related: Call Student Health Services at 806.743.2848 or your health care provider. During after-hours and on weekends, contact TTU COVID-19 Helpline at TBD. Self-report as soon as possible using the Dean of Students COVID-19 webpage. This website has specific directions about how to upload documentation from a medical provider and what will happen if your illness renders you unable to participate in classes for more than one week. If your illness is determined to be COVID-19-related, all remaining documentation and communication will be handled through the Office of the Dean of Students, including notification of your instructors of the time you may be absent from and may return to classes. If your illness is determined not to be COVID-19-related, please follow steps 2.a-d below. If you are ill and can attribute your symptoms to something other than COVID-19: If your illness renders you unable to attend face-to-face classes, participate in synchronous online classes, or miss specified assignment due dates in asynchronous online classes, you are encouraged to contact either Student Health Services at 806.743.2848 or your health care provider. Note that Student Health Services and your own and other health care providers may arrange virtual visits. During the health provider visit, request a \u201creturn to school\u201d note. E-mail the instructor a picture of that note. Return to class by the next class period after the date indicated on your note. Following the steps outlined above helps to keep your instructors informed about your absences and ensures your absence or missing an assignment due date because of illness will be marked excused. You will still be responsible to complete within a week of returning to class any assignments, quizzes, or exams you miss because of illness.","title":"A. Illness-Based Absence Policy (Face-to-Face Classes)"},{"location":"syllabus/syllabus/#b-illness-based-absence-policy-telepresenceon-line-classes","text":"Same as above with respect potential to infect others; go to a health care provider if you are ill. Telepresence courses are recorded and will be available on TTU MediaSite and/or YouTube (unlisted). Exercises, Quizzes, and Examinations are all administered by a Learning Management System (Blackboard) and students need to allow enough time to complete and upload their work. Due date adjustments/late submits on case-by-case basis; documentation required as in subsection A above.","title":"B. Illness-Based Absence Policy (Telepresence/On-Line Classes)"},{"location":"syllabus/syllabus/#course-sections","text":"Lesson time, days, and location: Section D04; CRN 64436; 1000-1120 T, TH ; Telepresence Lab Section D66; CRN 64441; 1130-1250 T, TH Section D01; CRN 63306; 1000-1120 T, TH ; Telepresence Lab Section D61; CRN 63744; 1130-1250 T, TH","title":"Course Sections"},{"location":"syllabus/syllabus/#course-instructor","text":"Instructor: Theodore G. Cleveland, Ph.D., P.E., M. ASCE, F. EWRI Email: theodore.cleveland@ttu.edu (put ENGR 1330 in subject line for email related to this class) Office location: Telepresence ( Zoom ) Office hours: 1000-1100 M, 1600-1700 W or by appointment (meetings will be by Zoom call)","title":"Course Instructor:"},{"location":"syllabus/syllabus/#teaching-assistant","text":"Teaching Assistant: Farhang Forghanparast, MSCE Email : Farhang.Forghanparast@ttu.edu Office location: Telepresence ( Zoom ) Office hours: 0900-1000 M; 1700-1800 W","title":"Teaching Assistant:"},{"location":"syllabus/syllabus/#textbook","text":"Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0). Link: https://www.inferentialthinking.com/chapters/intro.","title":"Textbook:"},{"location":"syllabus/syllabus/#course-contents","text":"Computational thinking for problem-solving: Logical problem solving, decomposition, pattern recognition, abstraction, representation, algorithm design, and generalization. Python Programming: Variables, constants, data types, data structures, strings, math operators boolean operators, expressions, program constructs, functions, looping, I/O files, modules, and database. Data science fundamentals: Experimental setup: Importing and formatting data sets, Displaying data, Data pre-processing. Introductory statistical analysis with Python: Elementary statistics, randomness, sampling, probability distributions, Confidence intervals, hypothesis testing, and A/B testing. Basic data analysis, visualization, and machine learning: Data pre-processing, Supervised/unsupervised learning, Performance evaluation metrics.","title":"Course Contents:"},{"location":"syllabus/syllabus/#learning-outcomes","text":"On completion of the course, students will have * Created Python programs employing computational thinking concepts to * Employed Python libraries relevant to data science. * Downloaded data files from selected public sources and analyzed content. * Created scripts to perform fundamental data analytics and basic visualization.","title":"Learning Outcomes:"},{"location":"syllabus/syllabus/#abet-student-outcomes","text":"Engineering: An ability to identify, formulate, and solve complex engineering problems by applying principles of engineering, science, and mathematics. An ability to acquire and apply new knowledge as needed, using appropriate learning strategies. Computer Science: Analyze a complex computing problem and to apply principles of computing and other relevant disciplines to identify solutions. Design, implement, and evaluate a computing-based solution to meet a given set of computing requirements in the context of the program\u2019s discipline.","title":"ABET Student Outcomes"},{"location":"syllabus/syllabus/#resourcestools","text":"","title":"Resources/Tools"},{"location":"syllabus/syllabus/#platforms-for-python-programming-for-your-own-computers","text":"Anaconda platform (https://www.anaconda.com/): Anaconda distribution is an open-source Data Science Distribution Development Platform. It includes Python 3 with over 1,500 data science packages making it easy to manage libraries and dependencies. Available in Linux, Windows, and Mac OS X. Jupyter (https://jupyter.org/): JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data. JupyterLab is flexible: Configure and arrange the user interface to support a wide range of workflows in data science, scientific computing, and machine learning. note Anaconda for MacOS includes a JupyterLab instance, so a separate install is not required.","title":"Platforms for Python Programming (for your own computers)"},{"location":"syllabus/syllabus/#additional-modules-for-python-programming","text":"Math module (https://docs.python.org/3/library/math.html): Gives access to the mathematical functions defined by the C standard e.g. factorial, gcd, exponential, logarithm. Operator module (https://docs.python.org/3/library/operator.html): Helps in exporting a set of efficient functions corresponding to the intrinsic operators of Python. For example, the operator add(x,y) is equivalent to the expression x+y.","title":"Additional Modules for Python Programming"},{"location":"syllabus/syllabus/#python-modules-for-data-science","text":"Scipy module (https://www.scipy.org/): A Python-based ecosystem of open-source software for mathematics, science, and engineering. Some of the core packages are: Numpy: Provides n-dimensional array package Scipy: Fundamental for scientific computing (e.g. linear algorithm, optimization) Matplotlib: Visualizations/2D plotting IPython: Enhanced interactive console <<= this is the kernel used in JupyterLab Pandas: Data structures and data analysis Scikit-learn module (https://scikit-learn.org/stable/): A library for machine learning in Python. It is a simple and efficient tool for predictive data analysis. It is built on NumPy, SciPy, and matplotlib modules.","title":"Python Modules for Data Science"},{"location":"syllabus/syllabus/#on-line-options","text":"AWS Lightsail Instance (use Windows Server 2000 template; lowest resource provision tier; AWS RDP client, or download and install own RDP client) Then install Anaconda onto the AWS Instance","title":"On-Line Options"},{"location":"syllabus/syllabus/#hardware-requirements","text":"Minimal, in fact this syllabus was created using a JupyterLab notebook (as a markdown processor) on a Raspberry Pi 4B, which technically cannot support a JupyterHub, but does. Your current laptop should be fine, or if you only have a chromebook, build an AWS instance. The college of engineering has specific laptop requirements for your other courses that are listed at https://www.depts.ttu.edu/coe/dean/engineeringitservices/buyingtherightcomputer.php","title":"Hardware Requirements"},{"location":"syllabus/syllabus/#content-server","text":"Blackboard is used as the learning management system (LMS) for this class, and it uses web links to a content server at https://3.137.111.182/engr-1330-webroot/ The Blackboard links will generally go directly to a section in the webroot, but feel free to explore by going in the front door!","title":"Content Server"},{"location":"syllabus/syllabus/#course-schedule","text":"Item Lesson Lab JupyterLab(Python Kernel) and Programming 21Jan2021 Lesson 0 Introduction to Computational Thinking with Data Science: - Computational thinking concepts - Python as a programming environment - Data science and practices - CCMR Approach Computing Environment set up: - Installing Anaconda (Win/MacOS/AWS) \u2013 Jupyter notebooks - Simple Examples 26Jan2021 Lesson 1 Programming Fundamentals: - Data types (int, float, string, bool) - Variables, operators, expressions, basic I/O - String functions and operations Introduction to Python - Data types (e.g. int, float, string, bool) - Expressions 28Jan2021 Lesson 2 Programming Fundamentals: - Data structures: Array, list, tuple, set, dictionary - Conditional statements Introduction to Python - Data structures - Conditional statements 2Feb2021 Lesson 3 Programming Fundamentals: - Loops - Flowcharts Introduction to Python - Loops 4Feb2021 Lesson 4 Programming Fundamentals: - Functions - Variable scope Introduction to Python - Functions - Variable scope 9Feb2021 Lesson 5 Programming Fundamentals: - Class and objects - File handling Introduction to Python - Class and objects - File handling Data Science External Modules 11Feb2021 Lesson 6 Data Representation and Operations: Python library: NumPy - Data representation: Arrays, vectors, matrices - Data operations: Indexing, math functions Exercises on NumPy 16Feb2021 Lesson 7 Data Query and Manipulation: Python Library: Pandas - Data frames: - Create, index, summarize statistics - fill and drop values - read/write to file Exercises on Pandas 18Feb2021 Lesson 8 Data Display: Python Libraries: Matplotlib - Graphing Conventions - Data Display for line charts, bar charts, box plot, scatter plot, and histograms Exercises on data display 23Feb2021 Lesson 9 Data Modeling: - Establishing causality - Randomness - Models as Preciction Machines Exercises on causality and simulation 25Feb2021 Review for Exam-1 (Lessons 0-9) Exam-1 - LMS administered Data Modeling: Statistical Approaches 2Mar2021 Lesson 10 Randomness and Probabilities: - Sampling - Empirical distributions Exercises on probabilities 4Mar2021 Lesson 11 Descriptive Statistics - Location/Center (mean, median,mode) - Dispersion/Spread (variance, standard deviation) - Asymmetry/Skew (Coefficient of Skewness) Descriptive Statistics 9Mar2021 Lesson 12 Distributions: - Normal, LogNormal - Gamma, Weibull - Extreme Value (Gumbell) Exercises on sampling 11Mar2021 Lesson 13 Probability Estimation Modeling - Ranking, order, plotting position - Distribution Fitting ; Method Of Moments; Maximum Likelihood Estimation Exercises 16Mar2021 Lesson 14 Hypothesis testing: - General concept - Assessing data models. Exercises on hypothesis testing 18Mar2021 Lesson 15 Hypothesis testing: -Comparing proportions - Type1 & Type2 errors - Attained significance (p-value) Exercises on hypothesis testing 23Mar2021 Lesson 16 Comparing two samples: A/B Testing Exercises on A/B testing 25Mar2021 Review for Exam-2 (Lessons 10-16) Exam-2 - LMS administered 30Mar2021 17. Confidence intervals Exercises Data Modeling: Regression (Model Fitting) Approaches 1Apr2021 18. Data Modeling: Regression Approach - Linear algebra of equation fitting Exercises 6Apr2021 19. Estimation Modeling by Regression: - Ordinary least squares (OLS) regression - Weighted least squares - Explanitory variables (features) - Response variable(s) exre 8Apr2021 20. Estimation Modeling by Regression: - Residuals - Performance metrics: Accuracy, error - Inference exercises 13Apr2021 21. Estimation Modeling by Regression: - Logistic Regression (a type of classification) Exercises on sample means Data Modeling: Machine Learning Approaches 15Apr2021 22. Data Modeling : The Machine Learning Approach: - Correlation - Training (a model fitting analog) - Confusion matrix, precision, recall, accuracy, F-score. - Making decisions Final projects selection - Project choices - Delivery schedule 20Apr2021 Lesson 23 Evaluation and Making Decisions: - Confusion matrix, precision, recall, accuracy, F-score. - Making decisions KNN with evaluation 22Apr2021 Lesson 24 Classification: - K Nearest Neighbor (KNN) More KNN Demonstration/Examples 27Apr2021 Review for Exam-3 (Lessons 17-24) Exam 3 - LMS administered 29Apr2021 Lesson 25 Classification: - Support Vector Machines (SVM) SVM Demonstration/Examples 4May2021 Lesson 26 Classification: - Artifical Neural Networks (ANN) ANN Demonstration 11May2021 Final Project Report and Link to Video","title":"Course Schedule"},{"location":"syllabus/syllabus/#course-assessment-and-grading-criteria","text":"There will be three exams and one comprehensive final project for this course. An AI-supervised online community using the Packback Questions (https://www.packback.co) platform will be used for online discussion about class topics. The platform is the place to pose questions and answers and share codes and problems. Face-to-face sections do not use packback, and use a different scoring distribution In addition, lab notebooks, quizzes, and homework assignments also contribute to the final grade. Late assignments will not be scored. Grades will be based on the following components; weighting is approximate: Assessment Instrument Weight(%) Exam-1 10 Exam-2 10 Exam-3 15 Lab Notebooks & Homework 30 Quizzes 10 Packback 15 Final project 10 Overall total 100 Letter grades will be assigned using the following proportions: Normalized Score Range Letter Grade \u2265 90 A 80-89 B 70-79 C 55-69 D < 55 F","title":"Course Assessment and Grading Criteria:"},{"location":"syllabus/syllabus/#packback-questions-environment","text":"Participation is a requirement for this course, and the Packback Questions platform will be used for online discussion about class topics. Packback Questions is an online community where you can be fearlessly curious and ask open-ended questions to build on top of what we are covering in class and relate topics to real-world applications.","title":"Packback Questions Environment"},{"location":"syllabus/syllabus/#packback-requirements","text":"Your participation on Packback will count toward 15% of your overall course grade. There will be a Weekly Sunday at 10:00PM CST deadline for submissions. In order to receive your points per week, you should submit the following per each deadline period: 1 open-ended Question per week with a minimum Curiosity Score of 30, each worth 33.33% of each assignment grade 2 Responses per week with a minimum Curiosity Score of 30, each worth 66.67% of each assignment grade Half credit will be provided for questions and responses that do not meet the minimum curiosity score.","title":"Packback Requirements:"},{"location":"syllabus/syllabus/#how-to-register-on-packback","text":"An email invitation will be sent to you from help@packback.co prompting you to finish registration. If you don\u2019t receive an email (be sure to check your spam), you may register by following the instructions below: Create an account by navigating to https://questions.packback.co and clicking \u201cSign up for an Account\u201d Note: If you already have an account on Packback you can log in with your credentials. Then enter our class community\u2019s lookup key into the \u201cLooking to join a community you don't see here?\u201d section in Packback at the bottom of the homepage. Community Lookup Key: 1e3bb85a-ddb2-456a-a8fc-178ead55206d Follow the instructions on your screen to finish your registration. Packback will require a paid subscription (~$25). Refer to www.packback.co/product/pricing for more information. How to Get Help from the Packback Team: If you have any questions or concerns about Packback throughout the semester, please read their FAQ at help.packback.co. If you need more help, contact their customer support team directly at help@packback.co. For a brief introduction to Packback Questions and why we are using it in class, watch this video: vimeo.com/packback/Welcome-to-Packback-Questions","title":"How to Register on Packback:"},{"location":"syllabus/syllabus/#classroom-policy","text":"The following activities are not allowed in the classroom: Texting or talking on the cellphone or other electronic devices, and reading non-course related materials.","title":"Classroom Policy:"},{"location":"syllabus/syllabus/#telepresence-on-line-courses","text":"Obviously electronic devices are vital; disrupting the conference is prohibited, please mute your microphone unless you have a question - consider typing your question into the chat window as well. Be aware of bandwidth issues and remember most lessons and laboratory sessions are recorded and posted on youtube. Recording, editing, and rendering takes awhile, so expect 24-36 hour delay before video is available.","title":"Telepresence (On-line) Courses"},{"location":"syllabus/syllabus/#ada-statement","text":"Any student who, because of a disability, may require special arrangements in order to meet the course requirements should contact the instructor as soon as possible to make necessary arrangements. Students must present appropriate verification from Student Disability Services during the instructor's office hours. Please note that instructors are not allowed to provide classroom accommodation to a student until appropriate verification from Student Disability Services has been provided. For additional information, please contact Student Disability Services office in 335 West Hall or call 806.742.2405.","title":"ADA Statement:"},{"location":"syllabus/syllabus/#academic-integrity-statement","text":"Academic integrity is taking responsibility for one\u2019s own class and/or course work, being individually accountable, and demonstrating intellectual honesty and ethical behavior. Academic integrity is a personal choice to abide by the standards of intellectual honesty and responsibility. Because education is a shared effort to achieve learning through the exchange of ideas, students, faculty, and staff have the collective responsibility to build mutual trust and respect. Ethical behavior and independent thought are essential for the highest level of academic achievement, which then must be measured. Academic achievement includes scholarship, teaching, and learning, all of which are shared endeavors. Grades are a device used to quantify the successful accumulation of knowledge through learning. Adhering to the standards of academic integrity ensures grades are earned honestly. Academic integrity is the foundation upon which students, faculty, and staff build their educational and professional careers. [Texas Tech University (\u201cUniversity\u201d) Quality Enhancement Plan, Academic Integrity Task Force, 2010].","title":"Academic Integrity Statement:"},{"location":"syllabus/syllabus/#religious-holy-day-statement","text":"\u201cReligious holy day\u201d means a holy day observed by a religion whose places of worship are exempt from property taxation under Texas Tax Code \u00a711.20. A student who intends to observe a religious holy day should make that intention known to the instructor prior to the absence. A student who is absent from classes for the observance of a religious holy day shall be allowed to take an examination or complete an assignment scheduled for that day within a reasonable time after the absence. A student who is excused may not be penalized for the absence; however, the instructor may respond appropriately if the student fails to complete the assignment satisfactorily.","title":"Religious Holy Day Statement:"},{"location":"syllabus/syllabus/#ethical-conduct-policy","text":"Cheating is prohibited, and the representation of the work of another person as your own will be grounds for receiving a failing grade in the course. DISCRIMINATION, HARASSMENT, AND SEXUAL VIOLENCE STATEMENT: Texas Tech University is committed to providing and strengthening an educational, working, and living environment where students, faculty, staff, and visitors are free from gender and/or sex discrimination of any kind. Sexual assault, discrimination, harassment, and other Title IX violations are not tolerated by the University. Report any incidents to the Office for Student Rights & Resolution, (806)-742-SAFE (7233) or file a report online at titleix.ttu.edu/students. Faculty and staff members at TTU are committed to connecting you to resources on campus. Some of these available resources are: TTU Student Counseling Center, 806- 742-3674, https://www.depts.ttu.edu/scc/(Provides confidential support on campus.) TTU 24-hour Crisis Helpline, 806-742-5555, (Assists students who are experiencing a mental health or interpersonal violence crisis. If you call the helpline, you will speak with a mental health counselor.) Voice of Hope Lubbock Rape Crisis Center, 806-763-7273, voiceofhopelubbock.org (24-hour hotline that provides support for survivors of sexual violence.) The Risk, Intervention, Safety and Education (RISE) Office, 806-742-2110, https://www.depts.ttu.edu/rise/ (Provides a range of resources and support options focused on prevention education and student wellness.) Texas Tech Police Department, 806-742- 3931,http://www.depts.ttu.edu/ttpd/ (To report criminal activity that occurs on or near Texas Tech campus.) CIVILITY IN THE CLASSROOM STATEMENT: Texas Tech University is a community of faculty, students, and staff that enjoys an expectation of cooperation, professionalism, and civility during the conduct of all forms of university business, including the conduct of student\u2013student and student\u2013faculty interactions in and out of the classroom. Further, the classroom is a setting in which an exchange of ideas and creative thinking should be encouraged and where intellectual growth and development are fostered. Students who disrupt this classroom mission by rude, sarcastic, threatening, abusive or obscene language and/or behavior will be subject to appropriate sanctions according to university policy. Likewise, faculty members are expected to maintain the highest standards of professionalism in all interactions with all constituents of the university. To ensure that you are fully engaged in class discussions and account team meetings during class time, you are expected to do the following: - Maintain the same level of civility and professionalism that would be expected in a face-to-face classroom setting. - Attend all classes regularly. - Log into the video conference on time and remain logged in for the duration of the class period. - Activate your camera so that you are visible to the instructor and other students in the class. If you have concerns about leaving your camera on (such as childcare obligations, privacy issues, or a particular circumstance during a class period), please talk to the instructor. - Refrain from engaging in non-class related activities during class time that create a distraction for other students in the class and/or limit your ability to engage in the course. Failure to meet these expectations may result in the following consequences: 1. Being counted as absent for the class meeting. 2. Not receiving credit for class participation for that class period. 3. Other consequences as stipulated in the syllabus, Texas Tech Code of Student Conduct, or other university policy. Repeated failure to meet expectations (e.g., attendance, participation in class, etc.), in addition to the above consequences, may result in the one or more of the following consequences: 1. Referral to the appropriate Associate Dean. 2. Academic penalty, ranging from a warning to failure of the course. (www.depts.ttu.edu/ethics/matadorchallenge/ethicalprinciples.php). LGBTQIA SUPPORT STATEMENT: I identify as an ally to the lesbian, gay, bisexual, transgender, queer, intersex, and asexual (LGBTQIA) community, and I am available to listen and support you in an affirming manner. I can assist in connecting you with resources on campus to address problems you may face pertaining to sexual orientation and/or gender identity that could interfere with your success at Texas Tech. Please note that additional resources are available through the Office of LGBTQIA within the Center for Campus Life, Student Union Building Room 201, www.lgbtqia.ttu.edu, 806.742.5433.\u201d Office of LGBTQIA, Student Union Building Room 201, www.lgbtqia.ttu.edu, 806.742.5433 Within the Center for Campus Life, the Office serves the Texas Tech community through facilitation and leadership of programming and advocacy efforts. This work is aimed at strengthening the lesbian, gay, bisexual, transgender, queer, intersex, and asexual (LGBTQIA) community and sustaining an inclusive campus that welcomes people of all sexual orientations, gender identities, and gender expressions.","title":"Ethical Conduct Policy:"}]}