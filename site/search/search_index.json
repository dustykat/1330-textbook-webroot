{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"WCOE ENGR 1330 Workbook (Draft) by Theodore G. Cleveland, Farhang Forghanparast, Dinesh Sundaravadivelu Devarajan, Turgut Batuhan Baturalp (Batu), Tanja Karp, Long Nguyen, and Mona Rizvi Introduction This on-line workbook is a collection of lessons and workshop contents for ENGR-1330 sections taught bt the forst two authors; students in other sections are welcome to use this as a resource with proper attribution (check with your instructor regarding what they will consider acceptable) suggested citation goes here The entire course content is served here and can be accessed from blackboard.ttu.edu or directly using the public URL. Homeworks and exams must be uploaded to blackboard.ttu.edu to be graded. Solutions are posted after due dates have passed, these links are updated weekly-ish. Document History This document is a living document, so whatever you can access from the public URL is whatever is current. Administrator Information The development hardware is a Raspberry Pi 4B (4GB) running Ubuntu 20.XX, an Apache Web Server, a JupyterHub (fully encrypted) with iPython extensions, R core, Latex, and MkDocs with extensions. The deployment hardware is whatever Amazon Web Services is providing at the time of upload (typically x86-64 Xeon-type virtual servers ) A backup is maintained at github/dustykat/rest of url .","title":"Home"},{"location":"#wcoe-engr-1330-workbook-draft","text":"by Theodore G. Cleveland, Farhang Forghanparast, Dinesh Sundaravadivelu Devarajan, Turgut Batuhan Baturalp (Batu), Tanja Karp, Long Nguyen, and Mona Rizvi","title":"WCOE ENGR 1330 Workbook (Draft)"},{"location":"#introduction","text":"This on-line workbook is a collection of lessons and workshop contents for ENGR-1330 sections taught bt the forst two authors; students in other sections are welcome to use this as a resource with proper attribution (check with your instructor regarding what they will consider acceptable) suggested citation goes here The entire course content is served here and can be accessed from blackboard.ttu.edu or directly using the public URL. Homeworks and exams must be uploaded to blackboard.ttu.edu to be graded. Solutions are posted after due dates have passed, these links are updated weekly-ish.","title":"Introduction"},{"location":"#document-history","text":"This document is a living document, so whatever you can access from the public URL is whatever is current.","title":"Document History"},{"location":"#administrator-information","text":"The development hardware is a Raspberry Pi 4B (4GB) running Ubuntu 20.XX, an Apache Web Server, a JupyterHub (fully encrypted) with iPython extensions, R core, Latex, and MkDocs with extensions. The deployment hardware is whatever Amazon Web Services is providing at the time of upload (typically x86-64 Xeon-type virtual servers ) A backup is maintained at github/dustykat/rest of url .","title":"Administrator Information"},{"location":"Lesson0/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 13 January 2021 Lesson 0 Introduction to Computational Thinking with Data Science: Syllabus Review Computational Thinking Fundamental Concepts Practices Data Science Fundamental Concepts Practices Computational Environment JupyterLab (iPython) as a programming environment Programming as a problem solving process The CCMR Approach","title":"Exam 3 Solution"},{"location":"Lesson0/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 13 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"Lesson0/#lesson-0-introduction-to-computational-thinking-with-data-science","text":"Syllabus Review Computational Thinking Fundamental Concepts Practices Data Science Fundamental Concepts Practices Computational Environment JupyterLab (iPython) as a programming environment Programming as a problem solving process The CCMR Approach","title":"Lesson 0 Introduction to Computational Thinking with Data Science:"},{"location":"about/","text":"About this document Put something here about the document, authors, copyright (GPL or MIT Open License) On-Line Book Author's Notes Inserting Code Fragments To insert a code fragment such as print('Hello World') simply indent in the source file used to generate the document print('hello world') These fragments can be cut-and-paste into a JupyterLab notebook. Inserting Images If the image is taken from a URL, use the following: ![image-name (a local tag)](url_to_image_source) Such as: ![image-name](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQqn40YbupkMAzY63jYtA6auEmjRfCOvCd0FA&usqp=CAU) Which will render a black swan: If the image is local to the host replace the url with the path to the image. Inserting URL links This is a variation of images, but without the ! , such as [link-name-that-will-display](url_to_link_destimation) For example the code below will link to the black swan search results: [link-to-images-of-black-swans](https://www.google.com/search?q=images+of+black+swan&client=safari&rls=en&sxsrf=ALeKk03oIoQ387TWjJoKzX-D_b7o1to43Q:1613002985584&tbm=isch&source=iu&ictx=1&fir=L2P5MiS1ICLTxM%252CC6BDdJoXT9KcEM%252C_&vet=1&usg=AI4_-kTXrBMpj__xL5IkGCshrXTp04fX3w&sa=X&ved=2ahUKEwiCneivyODuAhVJBs0KHY88CaAQ9QF6BAgUEAE&biw=1447&bih=975#imgrc=i_lxoojURNE3XM) link-to-images-of-black-swans","title":"About this document"},{"location":"about/#about-this-document","text":"Put something here about the document, authors, copyright (GPL or MIT Open License)","title":"About this document"},{"location":"about/#on-line-book-authors-notes","text":"Inserting Code Fragments To insert a code fragment such as print('Hello World') simply indent in the source file used to generate the document print('hello world') These fragments can be cut-and-paste into a JupyterLab notebook. Inserting Images If the image is taken from a URL, use the following: ![image-name (a local tag)](url_to_image_source) Such as: ![image-name](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQqn40YbupkMAzY63jYtA6auEmjRfCOvCd0FA&usqp=CAU) Which will render a black swan: If the image is local to the host replace the url with the path to the image. Inserting URL links This is a variation of images, but without the ! , such as [link-name-that-will-display](url_to_link_destimation) For example the code below will link to the black swan search results: [link-to-images-of-black-swans](https://www.google.com/search?q=images+of+black+swan&client=safari&rls=en&sxsrf=ALeKk03oIoQ387TWjJoKzX-D_b7o1to43Q:1613002985584&tbm=isch&source=iu&ictx=1&fir=L2P5MiS1ICLTxM%252CC6BDdJoXT9KcEM%252C_&vet=1&usg=AI4_-kTXrBMpj__xL5IkGCshrXTp04fX3w&sa=X&ved=2ahUKEwiCneivyODuAhVJBs0KHY88CaAQ9QF6BAgUEAE&biw=1447&bih=975#imgrc=i_lxoojURNE3XM) link-to-images-of-black-swans","title":"On-Line Book Author's Notes"},{"location":"lesson0/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 13 January 2021 Lesson 0 Introduction to Computational Thinking with Data Science: Syllabus Review Computational Thinking Fundamental Concepts Practices Data Science Fundamental Concepts Practices Computational Environment JupyterLab (iPython) as a programming environment Programming as a problem solving process The CCMR Approach","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson0/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 13 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson0/#lesson-0-introduction-to-computational-thinking-with-data-science","text":"Syllabus Review Computational Thinking Fundamental Concepts Practices Data Science Fundamental Concepts Practices Computational Environment JupyterLab (iPython) as a programming environment Programming as a problem solving process The CCMR Approach","title":"Lesson 0 Introduction to Computational Thinking with Data Science:"},{"location":"lesson1/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 13 January 2021 Lesson 1 Introduction to Computational Thinking with Data Science: Computational thinking concepts Data science and practices JupyterLab (iPython) as a programming environment Programming as a problem solving process CCMR Approach Special Script Blocks In the lesson notebooks there will usually be two script blocks, identical to the ones below. The first block identifies the particular computer, the user, and the python kernel in use. The second block sets markdown tables to left edge when rendering. I usually put both blocks at the top of the notebook, just after some kind of title block, as done here. # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson01/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) %%html <!-- Script Block to set tables to left alignment --> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} Computational Thinking Concepts Computational thinking (CT) refers to the thought processes involved in expressing solutions as computational steps or algorithms that can be carried out by a computer. Much of what follows is borrowed from (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2696102/). Computational thinking is taking an approach to solving problems, designing systems and understanding human behaviour that draws on concepts fundamental to computing (http://www.cs.cmu.edu/~15110-s13/Wing06-ct.pdf). Computational thinking is a kind of analytical thinking: It shares with mathematical thinking in the general ways in which we might approach solving a problem. It shares with engineering thinking in the general ways in which we might approach designing and evaluating a large, complex system that operates within the constraints of the real world. - It shares with scientific thinking in the general ways in which we might approach understanding computability, intelligence, the mind and human behaviour. The essence of computational thinking is abstraction and automation . In computing, we abstract notions beyond the physical dimensions of time and space. Our abstractions are extremely general because they are symbolic, where numeric abstractions are just a special case. CT Foundations CT is literally a process for breaking down a problem into smaller parts, looking for patterns in the problems, identifying what kind of information is needed, developing a step-by-step solution, and implementing that solution. Decomposition Pattern Recognition Abstraction Algorithms System Integration (implementation) Decomposition Decomposition is the process of taking a complex problem and breaking it into more manageable sub-problems. Examples include: - Writing a paper: - Introduction - Body - Conclusion Wide-viewed (Panorama) image: Taking multiple overlapped photos Stitch them Decomposition often leaves a framework of sub-problems that later have to be assembled (system integration) to produce a desired solution. Pattern Recognition Refers to finding similarities, or shared characteristics of problems. Allows a complex problem to become easier to solve. Allows use of same solution method for each occurrence of the pattern. Pattern recognition allows use of automation to process things - its a fundamental drilled shaft of CT. It also provides a way to use analogs from old problems to address new situations; it also will require assembly (system integration) to produce a desired solution. Abstraction Determine important characteristics of the problem and ignore characteristics that are not important. Use these characteristics to create a representation of what we are trying to solve. Books in an online bookstore Important NOT important title Cover color ISBN Author\u2019s hometown Authors ... ... ... Algorithms Step-by-step instructions of how to solve a problem (https://en.wikipedia.org/wiki/Algorithm). Identifies what is to be done, and the order in which they should be done. Image from https://www.newyorker.com/magazine/2021/01/18/whats-wrong-with-the-way-we-work?utm_source=pocket-newtab An algorithm is a finite sequence of defined, instructions, typically to solve a class of problems or to perform a computation. Algorithms are unambiguous and are used as specifications for performing calculations, data processing, automated reasoning, and other tasks. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, can incorporate random input. System Integration (implementation) System integration is the assembly of the parts above into the complete (integrated) solution. Integration combines parts into a program which is the realization of an algorithm using a syntax that the computer can understand. Data Science and Practice Data science is leveraging existing data sources, to create new ones as needed in order to extract meaningful information and actionable insights through business domain expertise, effective communication and results interpretation. Data science uses relevant statistical techniques, programming languages, software packages and libraries, and data infrastructure; The insights are used to drive business decisions and take actions intended to achieve business goals. Why is this important for engineers? Because engineering is a business! A list of typical skills (https://elitedatascience.com/data-science-resources): Foundational Skills Programming and Data Manipulation Statistics and Probability Technical Skills Data Collection SQL Data Visualization Applied Machine Learning Business Skills Communication Creativity and Innovation Operations and Strategy Business Analytics Supplementary Skills Natural Language Processing Recommendation Systems Time Series Analysis Practice Projects Competitions Problem Solving Challenges JupyterLab (iPython) Environment The tools: JupyterLab (https://jupyter.org/) is a web-based interactive development environment for Jupyter notebooks, code, and data. Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data organizing and transformation, numerical simulation, statistical modeling, visualization, machine learning, and other similar types of uses. JupyterHub (https://github.com/jupyterhub/jupyterhub) is a multi-user Hub that spawns, manages, and proxies multiple instances of the single-user Jupyter notebook server. All these tools allow use of various coding languages; Python is the choice for ENGR 1330. Installing JupyterLab on your own computer is relatively straightforward if it is an Intel-based Linux, Macintosh, or Windows machine - simply use Anaconda (https://www.anaconda.com/) as the installer. Installing onto an ARM-based machine is more difficult, but possible (this notebook was created on a Raspberry Pi). With both Apple and Microsoft abandoning Intel you can expect Anaconda builds for aarch64 (ARM) in the future. This course: You will create and use Jupyter Notebooks that use the ipython kernel, the notebook files will look like filename.ipynb ; these are ASCII files that the JupyterLab interprets and runs. Python The programming language we will use is Python (actually iPython). Python is an example of a high-level language; other high-level languages include C, C++, PHP, FORTRAN, ADA, Pascal, Go, Java, etc (there are a lot). As you might infer from the name high-level language, there are also low-level languages, sometimes referred to as machine languages or assembly languages. Machine language is the encoding of instructions in binary so that they can be directly executed by the computer. Assembly language uses a slightly easier format to refer to the low level instructions. Loosely speaking, computers can only execute programs written in low-level languages. To be exact, computers can actually only execute programs written in machine language. Thus, programs written in a high-level language (and even those in assembly language) have to be processed before they can run. This extra processing takes some time, which is a small disadvantage of high-level languages. However, the advantages to high-level languages are enormous. First, it is much easier to program in a high-level language. Programs written in a high-level language take less time to write, they are shorter and easier to read, and they are more likely to be correct. Second, high-level languages are portable, meaning that they can run on different kinds of computers with few or no modifications. Low-level programs can run on only one kind of computer and have to be rewritten to run on another. Due to these advantages, almost all programs are written in high-level languages. Low-level languages are used only for a few specialized applications, and for device drivers. Two kinds of programs process high-level languages into low-level languages: interpreters and compilers. An interpreter reads a high-level program and executes it, meaning that it does what the program says. It processes the program a little at a time, alternately reading lines and performing computations. Interpreted Program. Image from (https://runestone.academy/runestone/books/published/thinkcspy/GeneralIntro/ThePythonProgrammingLanguage.html) A compiler reads the program and translates it completely before the program starts running. In this case, the high-level program is called the source code, and the translated program is called the object code or the executable. Once a program is compiled, you can execute it repeatedly without further translation. Compiled Prorgam. Image from: (https://runestone.academy/runestone/books/published/thinkcspy/GeneralIntro/ThePythonProgrammingLanguage.html) Many modern languages use both processes. They are first compiled into a lower level language, called byte code, and then interpreted by a program called a virtual machine. Python uses both processes, but because of the way programmers interact with it, it is usually considered an interpreted language. As a language, python is a formal language that has certain requirements and structure called \"syntax.\" Formal languages are languages that are designed by people for specific applications. For example, the notation that mathematicians use is a formal language that is particularly good at denoting relationships among numbers and symbols. Chemists use a formal language to represent the chemical structure of molecules. Programming languages are formal languages that have been designed to express computations. Formal languages have strict rules about syntax. For example, 3+3=6 is a syntactically correct mathematical statement, but 3=+6& is not. Syntax rules come in two flavors, pertaining to tokens and structure . Tokens are the basic elements of the language, such as words, numbers, and chemical elements. One of the problems with 3=+6& is that & is not a legal token in mathematics (at least as far as we know). The second type of syntax rule pertains to the structure of a statement\u2014 that is, the way the tokens are arranged. The statement 3=+6& is structurally illegal (in mathematics) because you don\u2019t place a plus sign immediately after an equal sign (of course we will in python!). When you read a sentence in English or a statement in a formal language, you have to figure out what the structure of the sentence is; This process is called parsing . For example, when you hear the sentence, \u201cThe other shoe fell\u201d, you understand that the other shoe is the subject and fell is the verb. Once you have parsed a sentence, you can figure out what it means, or the semantics of the sentence. Assuming that you know what a shoe is and what it means to fall, you will understand the general implication of this sentence. Good Resources: Learn Python the Hard Way (Online Book) https://learnpythonthehardway.org/book/ Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) https://www.learnpython.org/ Short, interactive tutorial for those who just need a quick way to pick up Python syntax. How to Think Like a Computer Scientist (Interactive Book) https://runestone.academy/runestone/books/published/thinkcspy/index.html Interactive \"CS 101\" course taught in Python that really focuses on the art of problem solving. How to Learn Python for Data Science, The Self-Starter Way https://elitedatascience.com/learn-python-for-data-science Programming as a problem solving process The entire point of this course is to develop problem solving skills and begin using some tools (Statistics, Numerical Methods, Data Science, implemented as JupyterLab/Python programs). The scientific method https://en.wikipedia.org/wiki/Scientific_method is one example of an effective problem solving strategy. Stated as a protocol it goes something like: Observation: Formulation of a question Hypothesis: A conjecture that may explain observed behavior. Falsifiable by an experiment whose outcome conflicts with predictions deduced from the hypothesis Prediction: How the experiment should conclude if hypothesis is correct Testing: Experimental design, and conduct of the experiment. Analysis: Interpretation of experimental results This protocol can be directly adapted to CT/DS problems as: Define the problem (problem statement) Gather information (identify known and unknown values, and governing equations) Generate and evaluate potential solutions Refine and implement a solution Verify and test the solution. For actual computational methods the protocol becomes: Explicitly state the problem State: Input information Governing equations or principles, and The required output information. Work a sample problem by-hand for testing the general solution. Develop a general solution method (coding). Test the general solution against the by-hand example, then apply to the real problem. Oddly enough the first step is the most important and sometimes the most difficult. In a practical problem, step 2 is sometimes difficult because a skilled programmer is needed to translate the governing principles into an algorithm for the general solution (step 4). Example 1 Problem Solving Process Consider a need to compute an arithmetic mean, what would the process look like? Step 1. Develop script to compute the arithmetic mean of a stream of data of unknown length. Step 2. - Inputs: The data stream - Governing equation: \\bar x = \\frac{1}{N} \\sum_{i=1}^{N} x_i where N is the number of items in the data stream, and x_i is the value of the i-th element. - Outputs: The arithmetic mean \\bar x Step 3. Work a sample problem by-hand for testing the general solution. Data 23.43 37.43 34.91 28.37 30.62 The arithmetic mean requires us to count how many elements are in the data stream (in this case there are 5) and compute their sum (in this case 154.76), and finally divide the sum by the count and report this result as the arithmetic mean. \\bar x = \\frac{1}{5}(23.43+37.43+34.91+28.37+30.62)=\\frac{154.76}{5}=30.95 Step 4. Develop a general solution (code) The by-hand exercise helps identify the required steps in an \u201calgorithm\u201d or recipe to compute mean values. First we essentially capture or read the values then count how many there are (either as we go or as a separate step), then sum the values, then divide the values by the count, and finally report the result. In a flow-chart it would look like: Flowchart for Artihmetic Mean Algorithm Step 5. This step we would code the algorithm expressed in the figure and test it with the by-hand data and other small datasets until we are convinced it works correctly. In a simple JupyterLab script # Arithmetic Mean in Very Elementary and Primative Python xlist = [23.43,37.43,34.91,28.37,30.62] # list is a type of data structure howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + xlist[i] print(\"arithmetic mean = \",(accumulator/howlong)) arithmetic mean = 30.951999999999998 Step 6. This step we would refine the code to generalize the algorithm. In the example we want a way to supply the xlist from a file perhaps, and tidy the output by rounding to only two decimal places - rounding is relatively simple: # Arithmetic Mean in Very Elementary and Primative Python xlist = [23.43,37.43,34.91,28.37,30.62] # list is a type of data structure howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + xlist[i] print(\"arithmetic mean = \",round((accumulator/howlong),2)) arithmetic mean = 30.95 Reading from a file, is a bit more complicated. We need to create a connection to the file, then read the contents into our script, then put the contents into the xlist xlist=[] # list (null) is a type of data structure externalfile = open(\"data.txt\",'r') # create connection to file, set to read (r), file must exist how_many_lines = 0 for line in externalfile: # parse each line, append to xlist xlist.append(line) how_many_lines += 1 externalfile.close() # close the file connection howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + float(xlist[i]) print(\"arithmetic mean = \",round((accumulator/howlong),2)) arithmetic mean = 30.95 Finally, if we want to reuse the code a lot, it is convienent to make it into a function def average(inputlist): # inputlist should be a list of values howlong = len(inputlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + float(inputlist[i]) result = (accumulator/howlong) return(result) Put our file reading and compute mean code here xlist=[] # list (null) is a type of data structure externalfile = open(\"data.txt\",'r') # create connection to file, set to read (r), file must exist how_many_lines = 0 for line in externalfile: # parse each line, append to xlist xlist.append(line) how_many_lines += 1 externalfile.close() # close the file connection print(\"arithmetic mean = \",round(average(xlist),2)) arithmetic mean = 30.95 So the simple task of computing the mean of a collection of values, is a bit more complex when decomposed that it first appears, but illustrates a five step process (with a refinement step). Throughout the course this process is always in the background. CCMR Approach A lot of the problems we will encounter from a CT/DS perspective have already been solved, or at least analogs have been solved. It is perfectly acceptable to use prior work for a new set of conditions as long as proper attribution is made. We call this process CCMR: Copy: Find a solution to your problem from some online example: SourceForge, StackOverflow, GeeksForGeeks, DigitalOcean, etc. Cite: Cite the original source. In general a citation will look like one of the references below, but a URL to the source is sufficient at first. Modify: Modify the original cited work for your specific needs. Note the changes in the code using comment statements. Run: Apply the modified code to the problem of interest. In cases where we use CCMR we are not so much programming and developing our own work as scaffolding parts https://en.wikipedia.org/wiki/Scaffold_(programming) - a legitimate and valuable engineering activity. Readings Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 1 https://www.inferentialthinking.com/chapters/01/what-is-data-science.html","title":"Lesson 1"},{"location":"lesson1/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 13 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson1/#lesson-1-introduction-to-computational-thinking-with-data-science","text":"Computational thinking concepts Data science and practices JupyterLab (iPython) as a programming environment Programming as a problem solving process CCMR Approach","title":"Lesson 1 Introduction to Computational Thinking with Data Science:"},{"location":"lesson1/#special-script-blocks","text":"In the lesson notebooks there will usually be two script blocks, identical to the ones below. The first block identifies the particular computer, the user, and the python kernel in use. The second block sets markdown tables to left edge when rendering. I usually put both blocks at the top of the notebook, just after some kind of title block, as done here. # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson01/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) %%html <!-- Script Block to set tables to left alignment --> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;}","title":"Special Script Blocks"},{"location":"lesson1/#computational-thinking-concepts","text":"Computational thinking (CT) refers to the thought processes involved in expressing solutions as computational steps or algorithms that can be carried out by a computer. Much of what follows is borrowed from (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2696102/). Computational thinking is taking an approach to solving problems, designing systems and understanding human behaviour that draws on concepts fundamental to computing (http://www.cs.cmu.edu/~15110-s13/Wing06-ct.pdf). Computational thinking is a kind of analytical thinking: It shares with mathematical thinking in the general ways in which we might approach solving a problem. It shares with engineering thinking in the general ways in which we might approach designing and evaluating a large, complex system that operates within the constraints of the real world. - It shares with scientific thinking in the general ways in which we might approach understanding computability, intelligence, the mind and human behaviour. The essence of computational thinking is abstraction and automation . In computing, we abstract notions beyond the physical dimensions of time and space. Our abstractions are extremely general because they are symbolic, where numeric abstractions are just a special case.","title":"Computational Thinking Concepts"},{"location":"lesson1/#ct-foundations","text":"CT is literally a process for breaking down a problem into smaller parts, looking for patterns in the problems, identifying what kind of information is needed, developing a step-by-step solution, and implementing that solution. Decomposition Pattern Recognition Abstraction Algorithms System Integration (implementation)","title":"CT Foundations"},{"location":"lesson1/#decomposition","text":"Decomposition is the process of taking a complex problem and breaking it into more manageable sub-problems. Examples include: - Writing a paper: - Introduction - Body - Conclusion Wide-viewed (Panorama) image: Taking multiple overlapped photos Stitch them Decomposition often leaves a framework of sub-problems that later have to be assembled (system integration) to produce a desired solution.","title":"Decomposition"},{"location":"lesson1/#pattern-recognition","text":"Refers to finding similarities, or shared characteristics of problems. Allows a complex problem to become easier to solve. Allows use of same solution method for each occurrence of the pattern. Pattern recognition allows use of automation to process things - its a fundamental drilled shaft of CT. It also provides a way to use analogs from old problems to address new situations; it also will require assembly (system integration) to produce a desired solution.","title":"Pattern Recognition"},{"location":"lesson1/#abstraction","text":"Determine important characteristics of the problem and ignore characteristics that are not important. Use these characteristics to create a representation of what we are trying to solve. Books in an online bookstore Important NOT important title Cover color ISBN Author\u2019s hometown Authors ... ... ...","title":"Abstraction"},{"location":"lesson1/#algorithms","text":"Step-by-step instructions of how to solve a problem (https://en.wikipedia.org/wiki/Algorithm). Identifies what is to be done, and the order in which they should be done. Image from https://www.newyorker.com/magazine/2021/01/18/whats-wrong-with-the-way-we-work?utm_source=pocket-newtab An algorithm is a finite sequence of defined, instructions, typically to solve a class of problems or to perform a computation. Algorithms are unambiguous and are used as specifications for performing calculations, data processing, automated reasoning, and other tasks. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, can incorporate random input.","title":"Algorithms"},{"location":"lesson1/#system-integration-implementation","text":"System integration is the assembly of the parts above into the complete (integrated) solution. Integration combines parts into a program which is the realization of an algorithm using a syntax that the computer can understand.","title":"System Integration (implementation)"},{"location":"lesson1/#data-science-and-practice","text":"Data science is leveraging existing data sources, to create new ones as needed in order to extract meaningful information and actionable insights through business domain expertise, effective communication and results interpretation. Data science uses relevant statistical techniques, programming languages, software packages and libraries, and data infrastructure; The insights are used to drive business decisions and take actions intended to achieve business goals. Why is this important for engineers? Because engineering is a business! A list of typical skills (https://elitedatascience.com/data-science-resources): Foundational Skills Programming and Data Manipulation Statistics and Probability Technical Skills Data Collection SQL Data Visualization Applied Machine Learning Business Skills Communication Creativity and Innovation Operations and Strategy Business Analytics Supplementary Skills Natural Language Processing Recommendation Systems Time Series Analysis Practice Projects Competitions Problem Solving Challenges","title":"Data Science and Practice"},{"location":"lesson1/#jupyterlab-ipython-environment","text":"","title":"JupyterLab (iPython) Environment"},{"location":"lesson1/#the-tools","text":"JupyterLab (https://jupyter.org/) is a web-based interactive development environment for Jupyter notebooks, code, and data. Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data organizing and transformation, numerical simulation, statistical modeling, visualization, machine learning, and other similar types of uses. JupyterHub (https://github.com/jupyterhub/jupyterhub) is a multi-user Hub that spawns, manages, and proxies multiple instances of the single-user Jupyter notebook server. All these tools allow use of various coding languages; Python is the choice for ENGR 1330. Installing JupyterLab on your own computer is relatively straightforward if it is an Intel-based Linux, Macintosh, or Windows machine - simply use Anaconda (https://www.anaconda.com/) as the installer. Installing onto an ARM-based machine is more difficult, but possible (this notebook was created on a Raspberry Pi). With both Apple and Microsoft abandoning Intel you can expect Anaconda builds for aarch64 (ARM) in the future.","title":"The tools:"},{"location":"lesson1/#this-course","text":"You will create and use Jupyter Notebooks that use the ipython kernel, the notebook files will look like filename.ipynb ; these are ASCII files that the JupyterLab interprets and runs.","title":"This course:"},{"location":"lesson1/#python","text":"The programming language we will use is Python (actually iPython). Python is an example of a high-level language; other high-level languages include C, C++, PHP, FORTRAN, ADA, Pascal, Go, Java, etc (there are a lot). As you might infer from the name high-level language, there are also low-level languages, sometimes referred to as machine languages or assembly languages. Machine language is the encoding of instructions in binary so that they can be directly executed by the computer. Assembly language uses a slightly easier format to refer to the low level instructions. Loosely speaking, computers can only execute programs written in low-level languages. To be exact, computers can actually only execute programs written in machine language. Thus, programs written in a high-level language (and even those in assembly language) have to be processed before they can run. This extra processing takes some time, which is a small disadvantage of high-level languages. However, the advantages to high-level languages are enormous. First, it is much easier to program in a high-level language. Programs written in a high-level language take less time to write, they are shorter and easier to read, and they are more likely to be correct. Second, high-level languages are portable, meaning that they can run on different kinds of computers with few or no modifications. Low-level programs can run on only one kind of computer and have to be rewritten to run on another. Due to these advantages, almost all programs are written in high-level languages. Low-level languages are used only for a few specialized applications, and for device drivers. Two kinds of programs process high-level languages into low-level languages: interpreters and compilers. An interpreter reads a high-level program and executes it, meaning that it does what the program says. It processes the program a little at a time, alternately reading lines and performing computations. Interpreted Program. Image from (https://runestone.academy/runestone/books/published/thinkcspy/GeneralIntro/ThePythonProgrammingLanguage.html) A compiler reads the program and translates it completely before the program starts running. In this case, the high-level program is called the source code, and the translated program is called the object code or the executable. Once a program is compiled, you can execute it repeatedly without further translation. Compiled Prorgam. Image from: (https://runestone.academy/runestone/books/published/thinkcspy/GeneralIntro/ThePythonProgrammingLanguage.html) Many modern languages use both processes. They are first compiled into a lower level language, called byte code, and then interpreted by a program called a virtual machine. Python uses both processes, but because of the way programmers interact with it, it is usually considered an interpreted language. As a language, python is a formal language that has certain requirements and structure called \"syntax.\" Formal languages are languages that are designed by people for specific applications. For example, the notation that mathematicians use is a formal language that is particularly good at denoting relationships among numbers and symbols. Chemists use a formal language to represent the chemical structure of molecules. Programming languages are formal languages that have been designed to express computations. Formal languages have strict rules about syntax. For example, 3+3=6 is a syntactically correct mathematical statement, but 3=+6& is not. Syntax rules come in two flavors, pertaining to tokens and structure . Tokens are the basic elements of the language, such as words, numbers, and chemical elements. One of the problems with 3=+6& is that & is not a legal token in mathematics (at least as far as we know). The second type of syntax rule pertains to the structure of a statement\u2014 that is, the way the tokens are arranged. The statement 3=+6& is structurally illegal (in mathematics) because you don\u2019t place a plus sign immediately after an equal sign (of course we will in python!). When you read a sentence in English or a statement in a formal language, you have to figure out what the structure of the sentence is; This process is called parsing . For example, when you hear the sentence, \u201cThe other shoe fell\u201d, you understand that the other shoe is the subject and fell is the verb. Once you have parsed a sentence, you can figure out what it means, or the semantics of the sentence. Assuming that you know what a shoe is and what it means to fall, you will understand the general implication of this sentence.","title":"Python"},{"location":"lesson1/#good-resources","text":"Learn Python the Hard Way (Online Book) https://learnpythonthehardway.org/book/ Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) https://www.learnpython.org/ Short, interactive tutorial for those who just need a quick way to pick up Python syntax. How to Think Like a Computer Scientist (Interactive Book) https://runestone.academy/runestone/books/published/thinkcspy/index.html Interactive \"CS 101\" course taught in Python that really focuses on the art of problem solving. How to Learn Python for Data Science, The Self-Starter Way https://elitedatascience.com/learn-python-for-data-science","title":"Good Resources:"},{"location":"lesson1/#programming-as-a-problem-solving-process","text":"The entire point of this course is to develop problem solving skills and begin using some tools (Statistics, Numerical Methods, Data Science, implemented as JupyterLab/Python programs). The scientific method https://en.wikipedia.org/wiki/Scientific_method is one example of an effective problem solving strategy. Stated as a protocol it goes something like: Observation: Formulation of a question Hypothesis: A conjecture that may explain observed behavior. Falsifiable by an experiment whose outcome conflicts with predictions deduced from the hypothesis Prediction: How the experiment should conclude if hypothesis is correct Testing: Experimental design, and conduct of the experiment. Analysis: Interpretation of experimental results This protocol can be directly adapted to CT/DS problems as: Define the problem (problem statement) Gather information (identify known and unknown values, and governing equations) Generate and evaluate potential solutions Refine and implement a solution Verify and test the solution. For actual computational methods the protocol becomes: Explicitly state the problem State: Input information Governing equations or principles, and The required output information. Work a sample problem by-hand for testing the general solution. Develop a general solution method (coding). Test the general solution against the by-hand example, then apply to the real problem. Oddly enough the first step is the most important and sometimes the most difficult. In a practical problem, step 2 is sometimes difficult because a skilled programmer is needed to translate the governing principles into an algorithm for the general solution (step 4).","title":"Programming as a problem solving process"},{"location":"lesson1/#example-1-problem-solving-process","text":"Consider a need to compute an arithmetic mean, what would the process look like? Step 1. Develop script to compute the arithmetic mean of a stream of data of unknown length. Step 2. - Inputs: The data stream - Governing equation: \\bar x = \\frac{1}{N} \\sum_{i=1}^{N} x_i where N is the number of items in the data stream, and x_i is the value of the i-th element. - Outputs: The arithmetic mean \\bar x Step 3. Work a sample problem by-hand for testing the general solution. Data 23.43 37.43 34.91 28.37 30.62 The arithmetic mean requires us to count how many elements are in the data stream (in this case there are 5) and compute their sum (in this case 154.76), and finally divide the sum by the count and report this result as the arithmetic mean. \\bar x = \\frac{1}{5}(23.43+37.43+34.91+28.37+30.62)=\\frac{154.76}{5}=30.95 Step 4. Develop a general solution (code) The by-hand exercise helps identify the required steps in an \u201calgorithm\u201d or recipe to compute mean values. First we essentially capture or read the values then count how many there are (either as we go or as a separate step), then sum the values, then divide the values by the count, and finally report the result. In a flow-chart it would look like: Flowchart for Artihmetic Mean Algorithm Step 5. This step we would code the algorithm expressed in the figure and test it with the by-hand data and other small datasets until we are convinced it works correctly. In a simple JupyterLab script # Arithmetic Mean in Very Elementary and Primative Python xlist = [23.43,37.43,34.91,28.37,30.62] # list is a type of data structure howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + xlist[i] print(\"arithmetic mean = \",(accumulator/howlong)) arithmetic mean = 30.951999999999998 Step 6. This step we would refine the code to generalize the algorithm. In the example we want a way to supply the xlist from a file perhaps, and tidy the output by rounding to only two decimal places - rounding is relatively simple: # Arithmetic Mean in Very Elementary and Primative Python xlist = [23.43,37.43,34.91,28.37,30.62] # list is a type of data structure howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + xlist[i] print(\"arithmetic mean = \",round((accumulator/howlong),2)) arithmetic mean = 30.95 Reading from a file, is a bit more complicated. We need to create a connection to the file, then read the contents into our script, then put the contents into the xlist xlist=[] # list (null) is a type of data structure externalfile = open(\"data.txt\",'r') # create connection to file, set to read (r), file must exist how_many_lines = 0 for line in externalfile: # parse each line, append to xlist xlist.append(line) how_many_lines += 1 externalfile.close() # close the file connection howlong = len(xlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + float(xlist[i]) print(\"arithmetic mean = \",round((accumulator/howlong),2)) arithmetic mean = 30.95 Finally, if we want to reuse the code a lot, it is convienent to make it into a function def average(inputlist): # inputlist should be a list of values howlong = len(inputlist) # len is a built-in function that returns how many items in a list accumulator = 0 # a variable to accumulate the sum for i in range(howlong): accumulator = accumulator + float(inputlist[i]) result = (accumulator/howlong) return(result) Put our file reading and compute mean code here xlist=[] # list (null) is a type of data structure externalfile = open(\"data.txt\",'r') # create connection to file, set to read (r), file must exist how_many_lines = 0 for line in externalfile: # parse each line, append to xlist xlist.append(line) how_many_lines += 1 externalfile.close() # close the file connection print(\"arithmetic mean = \",round(average(xlist),2)) arithmetic mean = 30.95 So the simple task of computing the mean of a collection of values, is a bit more complex when decomposed that it first appears, but illustrates a five step process (with a refinement step). Throughout the course this process is always in the background.","title":"Example 1 Problem Solving Process"},{"location":"lesson1/#ccmr-approach","text":"A lot of the problems we will encounter from a CT/DS perspective have already been solved, or at least analogs have been solved. It is perfectly acceptable to use prior work for a new set of conditions as long as proper attribution is made. We call this process CCMR: Copy: Find a solution to your problem from some online example: SourceForge, StackOverflow, GeeksForGeeks, DigitalOcean, etc. Cite: Cite the original source. In general a citation will look like one of the references below, but a URL to the source is sufficient at first. Modify: Modify the original cited work for your specific needs. Note the changes in the code using comment statements. Run: Apply the modified code to the problem of interest. In cases where we use CCMR we are not so much programming and developing our own work as scaffolding parts https://en.wikipedia.org/wiki/Scaffold_(programming) - a legitimate and valuable engineering activity.","title":"CCMR Approach"},{"location":"lesson1/#readings","text":"Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 1 https://www.inferentialthinking.com/chapters/01/what-is-data-science.html","title":"Readings"},{"location":"lesson2/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 19 January 2021 Lesson 2 Programming Fundamentals: iPython, tokens, and structure Data types (int, float, string, bool) Variables, operators, expressions, basic I/O String functions and operations Special Script Blocks In the lesson notebooks there will usually be two script blocks, identical to the ones below. The first block identifies the particular computer, the user, and the python kernel in use. The second block sets markdown tables to left edge when rendering. I usually put both blocks at the top of the notebook, just after some kind of title block, as done here. # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson02/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) %%html <!-- Script Block to set tables to left alignment --> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} %reset -f Programming Fundamentals Computational thinking (CT) refers to the thought processes involved in expressing solutions as computational steps or algorithms that can be carried out by a computer. CT is a process for breaking down a problem into smaller parts, looking for patterns in the problems, identifying what kind of information is needed, developing a step-by-step solution, and implementing that solution. Recall the 5 fundamental CT concepts are: Decomposition: the process of taking a complex problem and breaking it into more manageable sub-problems. Decomposition often leaves a framework of sub-problems that later have to be assembled (system integration) to produce a desired solution. Pattern Recognition: finding similarities, or shared characteristics of problems. Allows a complex problem to become easier to solve. Allows use of same solution method ( automation ) for each occurrence of the pattern. Abstraction : Determine important characteristics of the problem and use these characteristics to create a representation of the problem. Algorithms : Step-by-step instructions of how to solve a problem (https://en.wikipedia.org/wiki/Algorithm). Identifies what is to be done, and the order in which they should be done. System Integration: the assembly of the parts above into the complete (integrated) solution. Integration combines parts into a program which is the realization of an algorithm using a syntax that the computer can understand. Programming is (generally) writing code in a specific programming language to address a certain problem. In the above list it is largely contained within the algorithms concept. iPython The programming language we will use is Python (actually iPython). Python is an example of a high-level language; there are also low-level languages, sometimes referred to as machine languages or assembly languages. Machine language is the encoding of instructions in binary so that they can be directly executed by the computer. Assembly language uses a slightly easier format to refer to the low level instructions. Loosely speaking, computers can only execute programs written in low-level languages. To be exact, computers can actually only execute programs written in machine language. Thus, programs written in a high-level language (and even those in assembly language) have to be processed before they can run. This extra processing takes some time, which is a small disadvantage of high-level languages. However, the advantages to high-level languages are enormous: First, it is much easier to program in a high-level language. Programs written in a high-level language take less time to write, they are shorter and easier to read, and they are more likely to be correct. Second, high-level languages are portable, meaning that they can run on different kinds of computers with just a few modifications. Low-level programs can run on only one kind of computer (chipset-specific for sure, in some cases hardware specific) and have to be rewritten to run on other processors. (e.g. x86-64 vs. arm7 vs. aarch64 vs. PowerPC ...) Due to these advantages, almost all programs are written in high-level languages. Low-level languages are used only for a few specialized applications. Two kinds of programs process high-level languages into low-level languages: interpreters and compilers. An interpreter reads a high-level program and executes it, meaning that it does what the program says. It processes the program a little at a time, alternately reading lines and performing computations. As a language, python is a formal language that has certain requirements and structure called \"syntax.\" Syntax rules come in two flavors, pertaining to tokens and structure . Tokens are the basic elements of the language, such as words, numbers, and chemical elements. The second type of syntax rule pertains to the structure of a statement specifically in the way the tokens are arranged. Tokens and Structure Consider the relativistic equation relating energy, mass, and the speed of light e = m \\cdot c^2 In this equation the tokens are e , m , c , = , \\cdot , and the structure is parsed from left to right as into the token named e place the result of the product of the contents of the tokens m and c^2 . Given that the speed of light is some universal constant, the only things that can change are the contents of m and the resulting change in e . In the above discourse, the tokens e , m , c are names for things that can have values -- we will call these variables (or constants as appropriate). The tokens = , \\cdot , and ~^2 are symbols for various arithmetic operations -- we will call these operators. The structure of the equation is specific -- we will call it a statement. When we attempt to write and execute python scripts - we will make various mistakes; these will generate warnings and errors, which we will repair to make a working program. Consider our equation: #clear all variables# Example Energy = Mass * SpeedOfLight**2 --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-4-1c1f1fa5363a> in <module> 1 #clear all variables# Example ----> 2 Energy = Mass * SpeedOfLight**2 NameError: name 'Mass' is not defined Notice how the interpreter tells us that Mass is undefined - so a simple fix is to define it and try again # Example Mass = 1000000 Energy = Mass * SpeedOfLight**2 --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-5-a4a52966e6df> in <module> 1 # Example 2 Mass = 1000000 ----> 3 Energy = Mass * SpeedOfLight**2 NameError: name 'SpeedOfLight' is not defined Notice how the interpreter now tells us that SpeedOfLight is undefined - so a simple fix is to define it and try again # Example Mass = 1000000 #kilograms SpeedOfLight = 299792458 #meters per second Energy = Mass * SpeedOfLight**2 Now the script ran without any reported errors, but we have not instructed the program on how to produce output. To keep the example simple we will just add a generic print statement. # Example Mass = 1000000 #kilograms SpeedOfLight = 299792458 #meters per second Energy = Mass * SpeedOfLight**2 print(\"Energy is:\", Energy, \"Newton meters\") Energy is: 89875517873681764000000 Newton meters Now lets examine our program. Identify the tokens that have values, Identify the tokens that are symbols of operations, identify the structure. Variables Variables are names given to data that we want to store and manipulate in programs. A variable has a name and a value. The value representation depends on what type of object the variable represents. The utility of variables comes in when we have a structure that is universal, but values of variables within the structure will change - otherwise it would be simple enough to just hardwire the arithmetic. Suppose we want to store the time of concentration for some hydrologic calculation. To do so, we can name a variable TimeOfConcentration , and then assign a value to the variable, for instance: TimeOfConcentration = 0.0 After this assignment statement the variable is created in the program and has a value of 0.0. The use of a decimal point in the initial assignment establishes the variable as a float (a real variable is called a floating point representation -- or just a float). Naming Rules Variable names in Python can only contain letters (a - z, A - Z), numerals (0 - 9), or underscores. The first character cannot be a number, otherwise there is considerable freedom in naming. The names can be reasonably long. runTime , run_Time , _run_Time2 , _2runTime are all valid names, but 2runTime is not valid, and will create an error when you try to use it. # Script to illustrate variable names runTime = 1 _2runTime = 2 # change to 2runTime = 2 and rerun script runTime2 = 2 print(runTime,_2runTime,runTime2) 1 2 2 There are some reserved words that cannot be used as variable names because they have preassigned meaning in Parseltongue. These words include print , input , if , while , and for . There are several more; the interpreter won't allow you to use these names as variables and will issue an error message when you attempt to run a program with such words used as variables. Operators The = sign used in the variable definition is called an assignment operator (or assignment sign). The symbol means that the expression to the right of the symbol is to be evaluated and the result placed into the variable on the left side of the symbol. The \"operation\" is assignment, the \"=\" symbol is the operator name. Consider the script below # Assignment Operator x = 5 y = 10 print (x,y) x=y # reverse order y=x and re-run, what happens? print (x,y) 5 10 10 10 So look at what happened. When we assigned values to the variables named x and y , they started life as 5 and 10. We then wrote those values to the console, and the program returned 5 and 10. Then we assigned y to x which took the value in y and replaced the value that was in x with this value. We then wrote the contents again, and both variables have the value 10. Arithmetic Operators In addition to assignment we can also perform arithmetic operations on variables. The fundamental arithmetic operators are: Symbol Meaning Example = Assignment x=3 Assigns value of 3 to x. + Addition x+y Adds values in x and y. - Subtraction x-y Subtracts values in y from x. * Multiplication x*y Multiplies values in x and y. / Division x/y Divides value in x by value in y. // Floor division x//y Divide x by y, truncate result to whole number. % Modulus x%y Returns remainder when x is divided by y. ** Exponentation x y Raises value in x by value in y. ( e.g. x y) += Additive assignment x+=2 Equivalent to x = x+2. -= Subtractive assignment x-=2 Equivalent to x = x-2. *= Multiplicative assignment x*=3 Equivalent to x = x*3. /= Divide assignment x/3 Equivalent to x = x/3. Run the script in the next cell for some illustrative results # Uniary Arithmetic Operators x = 10 y = 5 print(x, y) print(x+y) print(x-y) print(x*y) print(x/y) print((x+1)//y) print((x+1)%y) print(x**y) 10 5 15 5 50 2.0 2 1 100000 # Arithmetic assignment operators x = 1 x += 2 print(type(x),x) x = 1 x -= 2 print(type(x),x) x = 1 x *=3 print(type(x),x) x = 10 x /= 2 print(type(x),x) # Interesting what division does to variable type <class 'int'> 3 <class 'int'> -1 <class 'int'> 3 <class 'float'> 5.0 Data Type In the computer data are all binary digits (actually 0 and +5 volts). At a higher level of abstraction data are typed into integers, real, or alphanumeric representation. The type affects the kind of arithmetic operations that are allowed (as well as the kind of arithmetic - integer versus real arithmetic; lexicographical ordering of alphanumeric , etc.) In scientific programming, a common (and really difficult to detect) source of slight inaccuracies (that tend to snowball as the program runs) is mixed mode arithmetic required because two numeric values are of different types (integer and real). Learn more from the textbook https://www.inferentialthinking.com/chapters/04/Data_Types.html Here we present a quick summary Integer Integers are numbers without any fractional portion (nothing after the decimal point { which is not used in integers). Numbers like -3, -2, -1, 0, 1, 2, 200 are integers. A number like 1.1 is not an integer, and 1.0 is also not an integer (the presence of the decimal point makes the number a real). To declare an integer in Python, just assign the variable name to an integer for example MyPhoneNumber = 14158576309 Real (Float) A real or float is a number that has (or can have) a fractional portion - the number has decimal parts. The numbers 3.14159, -0.001, 11.11, 1., are all floats. The last one is especially tricky, if you don't notice the decimal point you might think it is an integer but the inclusion of the decimal point in Python tells the program that the value is to be treated as a float. To declare a float in Python, just assign the variable name to a float for example MyMassInKilos = 74.8427 String(Alphanumeric) A string is a data type that is treated as text elements. The usual letters are strings, but numbers can be included. The numbers in a string are simply characters and cannot be directly used in arithmetic. There are some kinds of arithmetic that can be performed on strings but generally we process string variables to capture the text nature of their contents. To declare a string in Python, just assign the variable name to a string value - the trick is the value is enclosed in quotes. The quotes are delimiters that tell the program that the characters between the quotes are characters and are to be treated as literal representation. For example MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" are all string variables. The last assignment is made a string on purpose. String variables can be combined using an operation called concatenation. The symbol for concatenation is the plus symbol + . Strings can also be converted to all upper case using the upper() function. The syntax for the upper() function is 'string to be upper case'.upper() . Notice the \"dot\" in the syntax. The operation passes everything to the left of the dot to the function which then operates on that content and returns the result all upper case (or an error if the input stream is not a string). # Variable Types Example MyPhoneNumber = 14158576309 MyMassInKilos = 74.8427 MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" print(\"All about me\") print(\"Name: \",MyName, \" Mass :\",MyMassInKilos,\"Kg\" ) print('Phone : ',MyPhoneNumber) print('My cat\\'s name :', MyCatName) # the \\ escape character is used to get the ' into the literal print(\"All about concatenation!\") print(\"A Silly String : \",MyCatName+MyName+DustyMassInKilos) print(\"A SILLY STRING : \", (MyCatName+MyName+DustyMassInKilos).upper()) All about me Name: Theodore Mass : 74.8427 Kg Phone : 14158576309 My cat's name : Dusty All about concatenation! A Silly String : DustyTheodore7.48427 A SILLY STRING : DUSTYTHEODORE7.48427 Strings can be formatted using the % operator or the format() function. The concepts will be introduced later on as needed in the workbook, you can Google search for examples of how to do such formatting. Changing Types A variable type can be changed. This activity is called type casting. Three functions allow type casting: int() , float() , and str() . The function names indicate the result of using the function, hence int() returns an integer, float() returns a oat, and str() returns a string. There is also the useful function type() which returns the type of variable. The easiest way to understand is to see an example. # Type Casting Examples MyInteger = 234 MyFloat = 876.543 MyString = 'What is your name?' print(MyInteger,MyFloat,MyString) print('Integer as float',float(MyInteger)) print('Float as integer',int(MyFloat)) print('Integer as string',str(MyInteger)) print('Integer as hexadecimal',hex(MyInteger)) print('Integer Type',type((MyInteger))) # insert the hex conversion and see what happens! 234 876.543 What is your name? Integer as float 234.0 Float as integer 876 Integer as string 234 Integer as hexadecimal 0xea Integer Type <class 'int'> Expressions Expressions are the \"algebraic\" constructions that are evaluated and then placed into a variable. Consider x1 = 7 + 3 * 6 / 2 - 1 The expression is evaluated from the left to right and in words is Into the object named x1 place the result of: integer 7 + (integer 6 divide by integer 2 = float 3 * integer 3 = float 9 - integer 1 = float 8) = float 15 The division operation by default produces a float result unless forced otherwise. The result is the variable x1 is a float with a value of 15.0 # Expressions Example x1 = 7 + 3 * 6 // 2 - 1 # Change / into // and see what happens! print(type(x1),x1) ## Simple I/O (Input/Output) <class 'int'> 15 Summary So far consider our story - a tool to help with problem solving is CT leading to an algorithm. The tool to implement the algorithm is the program and in our case JupyterLab running iPython interpreter for us. As a formal language we introduced: - tokens - structure From these two constructs we further introduced variables (a kind of token), data types (an abstraction, and arguably a decomposition), and expressions (a structure). We created simple scripts (with errors), examined the errors, corrected our script, and eventually got an answer. So we are well on our way in CT as it applies in Engineering. Programming as a problem solving process Recall the entire point of this course is to develop problem solving skills and begin using some tools (Statistics, Numerical Methods, Data Science, implemented as JupyterLab/Python programs). Recall our suggested problem solving protocol: Explicitly state the problem State: Input information Governing equations or principles, and The required output information. Work a sample problem by-hand for testing the general solution. Develop a general solution method (coding). Test the general solution against the by-hand example, then apply to the real problem. Refine general solution for deployment (frequent use) Another protocol with the same goal is at https://3.137.111.182/engr-1330-webroot/1-Lessons/Lesson02/OriginalPowerpoint/HowToBuildAProgram.html Notice the similarity! Example 2 Problem Solving Process Consider an engineering material problem where we wish to classify whether a material in loaded in the elastic or inelastic region as determined the stress (solid pressure) in a rod for some applied load. The yield stress is the classifier, and once the material yields (begins to fail) it will not carry any additional load (until ultimate failure, when it carries no load). Step 1. Compute the material stress under an applied load; determine if value exceedes yield stress, and report the loading condition Step 2. - Inputs: applied load, cross sectional area, yield stress - Governing equation: \\sigma = \\frac{P}{A} when \\frac{P}{A} is less than the yield stress, and is equal to the yield stress otherwise. - Outputs: The material stress \\sigma , and the classification elastic or inelastic. Step 3. Work a sample problem by-hand for testing the general solution. Assuming the yield stress is 1 million psi (units matter in an actual problem - kind of glossed over here) Applied Load (lbf) Cross Section Area (sq.in.) Stress (psi) Classification 10,000 1.0 10,000 Elastic 10,000 0.1 100,000 Elastic 100,000 0.1 1,000,000 Inelastic The stress requires us to read in the load value, read in the cross sectional area, divide the load by the area, and compare the result to the yield stress. If it exceeds the yield stress, then the actual stress is the yield stress, and the loading is inelastic, otherwise elastic \\sigma = \\frac{P}{A} If \\sigma >= \\text{Yield Stress Report Inelastic} Step 4. Develop a general solution (code) In a flow-chart it would look like: Flowchart for Artihmetic Mean Algorithm Step 5. This step we would code the algorithm expressed in the figure and test it with the by-hand data and other small datasets until we are convinced it works correctly. We have not yet learned prompts to get input we simply direct assign values as below (and the conditional execution is the subject of a later lesson) In a simple JupyterLab script # Example 2 Problem Solving Process yield_stress = 1e6 applied_load = 1e5 cross_section = 0.1 computed_stress = applied_load/cross_section if(computed_stress < yield_stress): print(\"Elastic Region: Stress = \",computed_stress) elif(computed_stress >= yield_stress): print(\"Inelastic Region: Stress = \",yield_stress) Inelastic Region: Stress = 1000000.0 Step 6. This step we would refine the code to generalize the algorithm. In the example we want a way to supply the inputs by user entry,and tidy the output by rounding to only two decimal places. A little CCMR from https://www.geeksforgeeks.org/taking-input-in-python/ gives us a way to deal with the inputs and typecasting. Some more CCMR from https://www.programiz.com/python-programming/methods/built-in/round gets us rounded out! # Example 2 Problem Solving Process yield_stress = float(input('Yield Stress (psi)')) applied_load = float(input('Applied Load (lbf)')) cross_section = float(input('Cross Section Area (sq.in.)')) computed_stress = applied_load/cross_section if(computed_stress < yield_stress): print(\"Elastic Region: Stress = \",round(computed_stress,2)) elif(computed_stress >= yield_stress): print(\"Inelastic Region: Stress = \",round(yield_stress,2)) Yield Stress (psi) 1000000 Applied Load (lbf) 100000 Cross Section Area (sq.in.) 1 Elastic Region: Stress = 100000.0 So the simple task of computing the stress, is a bit more complex when decomposed, that it first appears, but illustrates a five step process (with a refinement step). CCMR Approach A lot of the problems we will encounter from a CT/DS perspective have already been solved, or at least analogs have been solved. It is perfectly acceptable to use prior work for a new set of conditions as long as proper attribution is made. We call this process CCMR: Copy: Find a solution to your problem from some online example: SourceForge, StackOverflow, GeeksForGeeks, DigitalOcean, etc. Cite: Cite the original source. In general a citation will look like one of the references below, but a URL to the source is sufficient at first. Modify: Modify the original cited work for your specific needs. Note the changes in the code using comment statements. Run: Apply the modified code to the problem of interest. In cases where we use CCMR we are not so much programming and developing our own work as scaffolding parts https://en.wikipedia.org/wiki/Scaffold_(programming) - a legitimate and valuable engineering activity. Readings Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 3 https://www.inferentialthinking.com/chapters/03/programming-in-python.html Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 https://www.inferentialthinking.com/chapters/04/Data_Types.html Learn Python in One Day and Learn It Well. Python for Beginners with Hands-on Project. (Learn Coding Fast with Hands-On Project Book -- Kindle Edition by LCF Publishing (Author), Jamie Chan https://www.amazon.com/Python-2nd-Beginners-Hands-Project-ebook/dp/B071Z2Q6TQ/ref=sr_1_3?dchild=1&keywords=learn+python+in+a+day&qid=1611108340&sr=8-3 Learn Python the Hard Way (Online Book) https://learnpythonthehardway.org/book/ Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial)[https://www.learnpython.org/] (https://www.learnpython.org/) Short, interactive tutorial for those who just need a quick way to pick up Python syntax. How to Think Like a Computer Scientist (Interactive Book) https://runestone.academy/runestone/books/published/thinkcspy/index.html Interactive \"CS 101\" course taught in Python that really focuses on the art of problem solving. How to Learn Python for Data Science, The Self-Starter Way https://elitedatascience.com/learn-python-for-data-science","title":"Lesson 2"},{"location":"lesson2/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 19 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson2/#lesson-2-programming-fundamentals","text":"iPython, tokens, and structure Data types (int, float, string, bool) Variables, operators, expressions, basic I/O String functions and operations","title":"Lesson 2 Programming Fundamentals:"},{"location":"lesson2/#special-script-blocks","text":"In the lesson notebooks there will usually be two script blocks, identical to the ones below. The first block identifies the particular computer, the user, and the python kernel in use. The second block sets markdown tables to left edge when rendering. I usually put both blocks at the top of the notebook, just after some kind of title block, as done here. # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson02/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) %%html <!-- Script Block to set tables to left alignment --> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} %reset -f","title":"Special Script Blocks"},{"location":"lesson2/#programming-fundamentals","text":"Computational thinking (CT) refers to the thought processes involved in expressing solutions as computational steps or algorithms that can be carried out by a computer. CT is a process for breaking down a problem into smaller parts, looking for patterns in the problems, identifying what kind of information is needed, developing a step-by-step solution, and implementing that solution. Recall the 5 fundamental CT concepts are: Decomposition: the process of taking a complex problem and breaking it into more manageable sub-problems. Decomposition often leaves a framework of sub-problems that later have to be assembled (system integration) to produce a desired solution. Pattern Recognition: finding similarities, or shared characteristics of problems. Allows a complex problem to become easier to solve. Allows use of same solution method ( automation ) for each occurrence of the pattern. Abstraction : Determine important characteristics of the problem and use these characteristics to create a representation of the problem. Algorithms : Step-by-step instructions of how to solve a problem (https://en.wikipedia.org/wiki/Algorithm). Identifies what is to be done, and the order in which they should be done. System Integration: the assembly of the parts above into the complete (integrated) solution. Integration combines parts into a program which is the realization of an algorithm using a syntax that the computer can understand. Programming is (generally) writing code in a specific programming language to address a certain problem. In the above list it is largely contained within the algorithms concept.","title":"Programming Fundamentals"},{"location":"lesson2/#ipython","text":"The programming language we will use is Python (actually iPython). Python is an example of a high-level language; there are also low-level languages, sometimes referred to as machine languages or assembly languages. Machine language is the encoding of instructions in binary so that they can be directly executed by the computer. Assembly language uses a slightly easier format to refer to the low level instructions. Loosely speaking, computers can only execute programs written in low-level languages. To be exact, computers can actually only execute programs written in machine language. Thus, programs written in a high-level language (and even those in assembly language) have to be processed before they can run. This extra processing takes some time, which is a small disadvantage of high-level languages. However, the advantages to high-level languages are enormous: First, it is much easier to program in a high-level language. Programs written in a high-level language take less time to write, they are shorter and easier to read, and they are more likely to be correct. Second, high-level languages are portable, meaning that they can run on different kinds of computers with just a few modifications. Low-level programs can run on only one kind of computer (chipset-specific for sure, in some cases hardware specific) and have to be rewritten to run on other processors. (e.g. x86-64 vs. arm7 vs. aarch64 vs. PowerPC ...) Due to these advantages, almost all programs are written in high-level languages. Low-level languages are used only for a few specialized applications. Two kinds of programs process high-level languages into low-level languages: interpreters and compilers. An interpreter reads a high-level program and executes it, meaning that it does what the program says. It processes the program a little at a time, alternately reading lines and performing computations. As a language, python is a formal language that has certain requirements and structure called \"syntax.\" Syntax rules come in two flavors, pertaining to tokens and structure . Tokens are the basic elements of the language, such as words, numbers, and chemical elements. The second type of syntax rule pertains to the structure of a statement specifically in the way the tokens are arranged.","title":"iPython"},{"location":"lesson2/#tokens-and-structure","text":"Consider the relativistic equation relating energy, mass, and the speed of light e = m \\cdot c^2 In this equation the tokens are e , m , c , = , \\cdot , and the structure is parsed from left to right as into the token named e place the result of the product of the contents of the tokens m and c^2 . Given that the speed of light is some universal constant, the only things that can change are the contents of m and the resulting change in e . In the above discourse, the tokens e , m , c are names for things that can have values -- we will call these variables (or constants as appropriate). The tokens = , \\cdot , and ~^2 are symbols for various arithmetic operations -- we will call these operators. The structure of the equation is specific -- we will call it a statement. When we attempt to write and execute python scripts - we will make various mistakes; these will generate warnings and errors, which we will repair to make a working program. Consider our equation: #clear all variables# Example Energy = Mass * SpeedOfLight**2 --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-4-1c1f1fa5363a> in <module> 1 #clear all variables# Example ----> 2 Energy = Mass * SpeedOfLight**2 NameError: name 'Mass' is not defined Notice how the interpreter tells us that Mass is undefined - so a simple fix is to define it and try again # Example Mass = 1000000 Energy = Mass * SpeedOfLight**2 --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-5-a4a52966e6df> in <module> 1 # Example 2 Mass = 1000000 ----> 3 Energy = Mass * SpeedOfLight**2 NameError: name 'SpeedOfLight' is not defined Notice how the interpreter now tells us that SpeedOfLight is undefined - so a simple fix is to define it and try again # Example Mass = 1000000 #kilograms SpeedOfLight = 299792458 #meters per second Energy = Mass * SpeedOfLight**2 Now the script ran without any reported errors, but we have not instructed the program on how to produce output. To keep the example simple we will just add a generic print statement. # Example Mass = 1000000 #kilograms SpeedOfLight = 299792458 #meters per second Energy = Mass * SpeedOfLight**2 print(\"Energy is:\", Energy, \"Newton meters\") Energy is: 89875517873681764000000 Newton meters Now lets examine our program. Identify the tokens that have values, Identify the tokens that are symbols of operations, identify the structure.","title":"Tokens and Structure"},{"location":"lesson2/#variables","text":"Variables are names given to data that we want to store and manipulate in programs. A variable has a name and a value. The value representation depends on what type of object the variable represents. The utility of variables comes in when we have a structure that is universal, but values of variables within the structure will change - otherwise it would be simple enough to just hardwire the arithmetic. Suppose we want to store the time of concentration for some hydrologic calculation. To do so, we can name a variable TimeOfConcentration , and then assign a value to the variable, for instance: TimeOfConcentration = 0.0 After this assignment statement the variable is created in the program and has a value of 0.0. The use of a decimal point in the initial assignment establishes the variable as a float (a real variable is called a floating point representation -- or just a float).","title":"Variables"},{"location":"lesson2/#naming-rules","text":"Variable names in Python can only contain letters (a - z, A - Z), numerals (0 - 9), or underscores. The first character cannot be a number, otherwise there is considerable freedom in naming. The names can be reasonably long. runTime , run_Time , _run_Time2 , _2runTime are all valid names, but 2runTime is not valid, and will create an error when you try to use it. # Script to illustrate variable names runTime = 1 _2runTime = 2 # change to 2runTime = 2 and rerun script runTime2 = 2 print(runTime,_2runTime,runTime2) 1 2 2 There are some reserved words that cannot be used as variable names because they have preassigned meaning in Parseltongue. These words include print , input , if , while , and for . There are several more; the interpreter won't allow you to use these names as variables and will issue an error message when you attempt to run a program with such words used as variables.","title":"Naming Rules"},{"location":"lesson2/#operators","text":"The = sign used in the variable definition is called an assignment operator (or assignment sign). The symbol means that the expression to the right of the symbol is to be evaluated and the result placed into the variable on the left side of the symbol. The \"operation\" is assignment, the \"=\" symbol is the operator name. Consider the script below # Assignment Operator x = 5 y = 10 print (x,y) x=y # reverse order y=x and re-run, what happens? print (x,y) 5 10 10 10 So look at what happened. When we assigned values to the variables named x and y , they started life as 5 and 10. We then wrote those values to the console, and the program returned 5 and 10. Then we assigned y to x which took the value in y and replaced the value that was in x with this value. We then wrote the contents again, and both variables have the value 10.","title":"Operators"},{"location":"lesson2/#arithmetic-operators","text":"In addition to assignment we can also perform arithmetic operations on variables. The fundamental arithmetic operators are: Symbol Meaning Example = Assignment x=3 Assigns value of 3 to x. + Addition x+y Adds values in x and y. - Subtraction x-y Subtracts values in y from x. * Multiplication x*y Multiplies values in x and y. / Division x/y Divides value in x by value in y. // Floor division x//y Divide x by y, truncate result to whole number. % Modulus x%y Returns remainder when x is divided by y. ** Exponentation x y Raises value in x by value in y. ( e.g. x y) += Additive assignment x+=2 Equivalent to x = x+2. -= Subtractive assignment x-=2 Equivalent to x = x-2. *= Multiplicative assignment x*=3 Equivalent to x = x*3. /= Divide assignment x/3 Equivalent to x = x/3. Run the script in the next cell for some illustrative results # Uniary Arithmetic Operators x = 10 y = 5 print(x, y) print(x+y) print(x-y) print(x*y) print(x/y) print((x+1)//y) print((x+1)%y) print(x**y) 10 5 15 5 50 2.0 2 1 100000 # Arithmetic assignment operators x = 1 x += 2 print(type(x),x) x = 1 x -= 2 print(type(x),x) x = 1 x *=3 print(type(x),x) x = 10 x /= 2 print(type(x),x) # Interesting what division does to variable type <class 'int'> 3 <class 'int'> -1 <class 'int'> 3 <class 'float'> 5.0","title":"Arithmetic Operators"},{"location":"lesson2/#data-type","text":"In the computer data are all binary digits (actually 0 and +5 volts). At a higher level of abstraction data are typed into integers, real, or alphanumeric representation. The type affects the kind of arithmetic operations that are allowed (as well as the kind of arithmetic - integer versus real arithmetic; lexicographical ordering of alphanumeric , etc.) In scientific programming, a common (and really difficult to detect) source of slight inaccuracies (that tend to snowball as the program runs) is mixed mode arithmetic required because two numeric values are of different types (integer and real). Learn more from the textbook https://www.inferentialthinking.com/chapters/04/Data_Types.html Here we present a quick summary","title":"Data Type"},{"location":"lesson2/#integer","text":"Integers are numbers without any fractional portion (nothing after the decimal point { which is not used in integers). Numbers like -3, -2, -1, 0, 1, 2, 200 are integers. A number like 1.1 is not an integer, and 1.0 is also not an integer (the presence of the decimal point makes the number a real). To declare an integer in Python, just assign the variable name to an integer for example MyPhoneNumber = 14158576309","title":"Integer"},{"location":"lesson2/#real-float","text":"A real or float is a number that has (or can have) a fractional portion - the number has decimal parts. The numbers 3.14159, -0.001, 11.11, 1., are all floats. The last one is especially tricky, if you don't notice the decimal point you might think it is an integer but the inclusion of the decimal point in Python tells the program that the value is to be treated as a float. To declare a float in Python, just assign the variable name to a float for example MyMassInKilos = 74.8427","title":"Real (Float)"},{"location":"lesson2/#stringalphanumeric","text":"A string is a data type that is treated as text elements. The usual letters are strings, but numbers can be included. The numbers in a string are simply characters and cannot be directly used in arithmetic. There are some kinds of arithmetic that can be performed on strings but generally we process string variables to capture the text nature of their contents. To declare a string in Python, just assign the variable name to a string value - the trick is the value is enclosed in quotes. The quotes are delimiters that tell the program that the characters between the quotes are characters and are to be treated as literal representation. For example MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" are all string variables. The last assignment is made a string on purpose. String variables can be combined using an operation called concatenation. The symbol for concatenation is the plus symbol + . Strings can also be converted to all upper case using the upper() function. The syntax for the upper() function is 'string to be upper case'.upper() . Notice the \"dot\" in the syntax. The operation passes everything to the left of the dot to the function which then operates on that content and returns the result all upper case (or an error if the input stream is not a string). # Variable Types Example MyPhoneNumber = 14158576309 MyMassInKilos = 74.8427 MyName = 'Theodore' MyCatName = \"Dusty\" DustyMassInKilos = \"7.48427\" print(\"All about me\") print(\"Name: \",MyName, \" Mass :\",MyMassInKilos,\"Kg\" ) print('Phone : ',MyPhoneNumber) print('My cat\\'s name :', MyCatName) # the \\ escape character is used to get the ' into the literal print(\"All about concatenation!\") print(\"A Silly String : \",MyCatName+MyName+DustyMassInKilos) print(\"A SILLY STRING : \", (MyCatName+MyName+DustyMassInKilos).upper()) All about me Name: Theodore Mass : 74.8427 Kg Phone : 14158576309 My cat's name : Dusty All about concatenation! A Silly String : DustyTheodore7.48427 A SILLY STRING : DUSTYTHEODORE7.48427 Strings can be formatted using the % operator or the format() function. The concepts will be introduced later on as needed in the workbook, you can Google search for examples of how to do such formatting.","title":"String(Alphanumeric)"},{"location":"lesson2/#changing-types","text":"A variable type can be changed. This activity is called type casting. Three functions allow type casting: int() , float() , and str() . The function names indicate the result of using the function, hence int() returns an integer, float() returns a oat, and str() returns a string. There is also the useful function type() which returns the type of variable. The easiest way to understand is to see an example. # Type Casting Examples MyInteger = 234 MyFloat = 876.543 MyString = 'What is your name?' print(MyInteger,MyFloat,MyString) print('Integer as float',float(MyInteger)) print('Float as integer',int(MyFloat)) print('Integer as string',str(MyInteger)) print('Integer as hexadecimal',hex(MyInteger)) print('Integer Type',type((MyInteger))) # insert the hex conversion and see what happens! 234 876.543 What is your name? Integer as float 234.0 Float as integer 876 Integer as string 234 Integer as hexadecimal 0xea Integer Type <class 'int'>","title":"Changing Types"},{"location":"lesson2/#expressions","text":"Expressions are the \"algebraic\" constructions that are evaluated and then placed into a variable. Consider x1 = 7 + 3 * 6 / 2 - 1 The expression is evaluated from the left to right and in words is Into the object named x1 place the result of: integer 7 + (integer 6 divide by integer 2 = float 3 * integer 3 = float 9 - integer 1 = float 8) = float 15 The division operation by default produces a float result unless forced otherwise. The result is the variable x1 is a float with a value of 15.0 # Expressions Example x1 = 7 + 3 * 6 // 2 - 1 # Change / into // and see what happens! print(type(x1),x1) ## Simple I/O (Input/Output) <class 'int'> 15","title":"Expressions"},{"location":"lesson2/#summary","text":"So far consider our story - a tool to help with problem solving is CT leading to an algorithm. The tool to implement the algorithm is the program and in our case JupyterLab running iPython interpreter for us. As a formal language we introduced: - tokens - structure From these two constructs we further introduced variables (a kind of token), data types (an abstraction, and arguably a decomposition), and expressions (a structure). We created simple scripts (with errors), examined the errors, corrected our script, and eventually got an answer. So we are well on our way in CT as it applies in Engineering.","title":"Summary"},{"location":"lesson2/#programming-as-a-problem-solving-process","text":"Recall the entire point of this course is to develop problem solving skills and begin using some tools (Statistics, Numerical Methods, Data Science, implemented as JupyterLab/Python programs). Recall our suggested problem solving protocol: Explicitly state the problem State: Input information Governing equations or principles, and The required output information. Work a sample problem by-hand for testing the general solution. Develop a general solution method (coding). Test the general solution against the by-hand example, then apply to the real problem. Refine general solution for deployment (frequent use) Another protocol with the same goal is at https://3.137.111.182/engr-1330-webroot/1-Lessons/Lesson02/OriginalPowerpoint/HowToBuildAProgram.html Notice the similarity!","title":"Programming as a problem solving process"},{"location":"lesson2/#example-2-problem-solving-process","text":"Consider an engineering material problem where we wish to classify whether a material in loaded in the elastic or inelastic region as determined the stress (solid pressure) in a rod for some applied load. The yield stress is the classifier, and once the material yields (begins to fail) it will not carry any additional load (until ultimate failure, when it carries no load). Step 1. Compute the material stress under an applied load; determine if value exceedes yield stress, and report the loading condition Step 2. - Inputs: applied load, cross sectional area, yield stress - Governing equation: \\sigma = \\frac{P}{A} when \\frac{P}{A} is less than the yield stress, and is equal to the yield stress otherwise. - Outputs: The material stress \\sigma , and the classification elastic or inelastic. Step 3. Work a sample problem by-hand for testing the general solution. Assuming the yield stress is 1 million psi (units matter in an actual problem - kind of glossed over here) Applied Load (lbf) Cross Section Area (sq.in.) Stress (psi) Classification 10,000 1.0 10,000 Elastic 10,000 0.1 100,000 Elastic 100,000 0.1 1,000,000 Inelastic The stress requires us to read in the load value, read in the cross sectional area, divide the load by the area, and compare the result to the yield stress. If it exceeds the yield stress, then the actual stress is the yield stress, and the loading is inelastic, otherwise elastic \\sigma = \\frac{P}{A} If \\sigma >= \\text{Yield Stress Report Inelastic} Step 4. Develop a general solution (code) In a flow-chart it would look like: Flowchart for Artihmetic Mean Algorithm Step 5. This step we would code the algorithm expressed in the figure and test it with the by-hand data and other small datasets until we are convinced it works correctly. We have not yet learned prompts to get input we simply direct assign values as below (and the conditional execution is the subject of a later lesson) In a simple JupyterLab script # Example 2 Problem Solving Process yield_stress = 1e6 applied_load = 1e5 cross_section = 0.1 computed_stress = applied_load/cross_section if(computed_stress < yield_stress): print(\"Elastic Region: Stress = \",computed_stress) elif(computed_stress >= yield_stress): print(\"Inelastic Region: Stress = \",yield_stress) Inelastic Region: Stress = 1000000.0 Step 6. This step we would refine the code to generalize the algorithm. In the example we want a way to supply the inputs by user entry,and tidy the output by rounding to only two decimal places. A little CCMR from https://www.geeksforgeeks.org/taking-input-in-python/ gives us a way to deal with the inputs and typecasting. Some more CCMR from https://www.programiz.com/python-programming/methods/built-in/round gets us rounded out! # Example 2 Problem Solving Process yield_stress = float(input('Yield Stress (psi)')) applied_load = float(input('Applied Load (lbf)')) cross_section = float(input('Cross Section Area (sq.in.)')) computed_stress = applied_load/cross_section if(computed_stress < yield_stress): print(\"Elastic Region: Stress = \",round(computed_stress,2)) elif(computed_stress >= yield_stress): print(\"Inelastic Region: Stress = \",round(yield_stress,2)) Yield Stress (psi) 1000000 Applied Load (lbf) 100000 Cross Section Area (sq.in.) 1 Elastic Region: Stress = 100000.0 So the simple task of computing the stress, is a bit more complex when decomposed, that it first appears, but illustrates a five step process (with a refinement step).","title":"Example 2 Problem Solving Process"},{"location":"lesson2/#ccmr-approach","text":"A lot of the problems we will encounter from a CT/DS perspective have already been solved, or at least analogs have been solved. It is perfectly acceptable to use prior work for a new set of conditions as long as proper attribution is made. We call this process CCMR: Copy: Find a solution to your problem from some online example: SourceForge, StackOverflow, GeeksForGeeks, DigitalOcean, etc. Cite: Cite the original source. In general a citation will look like one of the references below, but a URL to the source is sufficient at first. Modify: Modify the original cited work for your specific needs. Note the changes in the code using comment statements. Run: Apply the modified code to the problem of interest. In cases where we use CCMR we are not so much programming and developing our own work as scaffolding parts https://en.wikipedia.org/wiki/Scaffold_(programming) - a legitimate and valuable engineering activity.","title":"CCMR Approach"},{"location":"lesson2/#readings","text":"Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 3 https://www.inferentialthinking.com/chapters/03/programming-in-python.html Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 https://www.inferentialthinking.com/chapters/04/Data_Types.html Learn Python in One Day and Learn It Well. Python for Beginners with Hands-on Project. (Learn Coding Fast with Hands-On Project Book -- Kindle Edition by LCF Publishing (Author), Jamie Chan https://www.amazon.com/Python-2nd-Beginners-Hands-Project-ebook/dp/B071Z2Q6TQ/ref=sr_1_3?dchild=1&keywords=learn+python+in+a+day&qid=1611108340&sr=8-3 Learn Python the Hard Way (Online Book) https://learnpythonthehardway.org/book/ Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial)[https://www.learnpython.org/] (https://www.learnpython.org/) Short, interactive tutorial for those who just need a quick way to pick up Python syntax. How to Think Like a Computer Scientist (Interactive Book) https://runestone.academy/runestone/books/published/thinkcspy/index.html Interactive \"CS 101\" course taught in Python that really focuses on the art of problem solving. How to Learn Python for Data Science, The Self-Starter Way https://elitedatascience.com/learn-python-for-data-science","title":"Readings"},{"location":"lesson3/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 25 January 2021 Lesson 3 Data Structures and Conditional Statements: Data structures; lists, arrays, tuples, sets, dictionaries Name, index, contents; keys Conditional sturctures; logical compares, block and in-line if Special Script Blocks %%html <!-- Script Block to set tables to left alignment --> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} Objectives 1) Develop awareness of data structures available in Python to store and manipulate data 1. Implement arrays (lists), dictionaries, and tuples 2. Address contents of lists , dictionaries, and tuples 2) Develop awareness of decision making in Python 1. Implement decision making in Python using using if-then ... conditional statements Data Structures and Conditional Statements Computational thinking (CT) concepts involved are: Decomposition : Data interpretation, manipulation, and analysis of NumPy arrays Abstraction : Data structures; Arrays, lists, tuples, sets, and dictionaries Algorithms : Conditional statements What is a data structure? Data Structures are a specialized means of organizing and storing data in computers in such a way that we can perform operations on the stored data more efficiently. In our iPython world the structures are illustrated in the figure below Lists A list is a collection of data that are somehow related. It is a convenient way to refer to a collection of similar things by a single name, and using an index (like a subscript in math) to identify a particular item. Consider the \"math-like\" variable x below: \\begin{gather} x_0= 7 \\\\ x_1= 11 \\\\ x_2= 5 \\\\ x_3= 9 \\\\ x_4= 13 \\\\ \\dots \\\\ x_N= 223 \\\\ \\end{gather} The variable name is x and the subscripts correspond to different values. Thus the value of the variable named x associated with subscript 3 is the number 9 . The figure below is a visual representation of a the concept that treats a variable as a collection of cells. In the figure, the variable name is MyList , the subscripts are replaced by an index which identifies which cell is being referenced. The value is the cell content at the particular index. So in the figure the value of MyList at Index = 3 is the number 9.' In engineering and data science we use lists a lot - we often call then vectors, arrays, matrices and such, but they are ultimately just lists. To declare a list you can write the list name and assign it values. The square brackets are used to identify that the variable is a list. Like: MyList = [7,11,5,9,13,66,99,223] One can also declare a null list and use the append() method to fill it as needed. MyOtherList = [ ] Python indices start at ZERO . A lot of other languages start at ONE. It's just the convention. The first element in a list has an index of 0, the second an index of 1, and so on. We access the contents of a list by referring to its name and index. For example MyList[3] has a value of the number 9. Arrays Arrays are lists that are used to store only elements of a specific data type - Ordered: Elements in an array can be indexed - Mutable: Elements in an array can be altered Data type that an array must hold is specified using the type code when it is created - \u2018f\u2019 for float - \u2018d\u2019 for double - \u2018i\u2019 for signed int - \u2018I\u2019 for unsigned int More types are listed below Type Code C Data Type Python Data Type Minimum Size in Bytes 'b' signed char int 1 'B' unsigned char int 1 'h' signed short int 2 'H' unsigned short int 2 'i' signed int int 2 'I' unsigned int int 2 'l' signed long int 4 'L' unsigned long int 4 'q' signed long long int 8 'Q' unsigned long long int 8 'f' float float 4 'd' double float 8 To use arrays, a library named \u2018array\u2019 must be imported import array Creating an array that contains signed integer numbers myarray = array.array('i', [1, 2, 4, 8, 16, 32]) myarray[0] #1-st element, 0-th position 1 import array as arr #import using an alias so the calls dont look so funny myarray = arr.array('i', [1, 2, 4, 8, 16, 32]) myarray[0] #1-st element, 0-th position 1 Lists: Can store elements of different data types; like arrays they are (arrays are lists, but lists are not quite arrays!) - Ordered: Elements in a list can be indexed - Mutable: Elements in a list can be altered - Mathematical operations must be applied to each element of the list Tuple - A special list A tuple is a special kind of list where the values cannot be changed after the list is created. Such a property is called immutable It is useful for list-like things that are static - like days in a week, or months of a year. You declare a tuple like a list, except use round brackets instead of square brackets. MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") Tuples are often created as output from packages and functions. Dictionary - A special list A dictionary is a special kind of list where the items are related data PAIRS . It is a lot like a relational database (it probably is one in fact) where the first item in the pair is called the key, and must be unique in a dictionary, and the second item in the pair is the data. The second item could itself be a list, so a dictionary would be a meaningful way to build a database in Python. To declare a dictionary using curly brackets MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} To declare a dictionary using the dict() method MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) Dictionary properties - Unordered: Elements in a dictionary cannot be - Mutable elements: Elements in a dictionary can be altered - Immutable keys: Keys in a dictionary cannot be altered Sets - A special list Sets: Are used to store elements of different data types - Unordered: Elements in a set cannot be indexed - Mutable: Elements in a set can be altered - Non-repetition: Elements in a set are unique Elements of a set are enclosed in curly brackets { } - Creating sets that contains different data types - Sets cannot be nested What's the difference between a set and dictionary? From https://stackoverflow.com/questions/34370599/difference-between-dict-and-set-python \"Well, a set is like a dict with keys but no values, and they're both implemented using a hash table. But yes, it's a little annoying that the {} notation denotes an empty dict rather than an empty set , but that's a historical artifact.\" Conditional Statements Decision making via conditional statements is an important step in algorithm design; they control the flow of execution of a program. Conditional statements in Python include: if statement if....else statements if....elif....else statements Conditional statements are logical expressions that evaluate as TRUE or FALSE and using these results to perform further operations based on these conditions. All flow control in a program depends on evaluating conditions. The program will proceed diferently based on the outcome of one or more conditions - really sophisticated AI programs are a collection of conditions and correlations. Expressed in a flowchart a block if statement looks like: As psuedo code: if(condition is true): do stuff Amazon knowing what you kind of want is based on correlations of your past behavior compared to other peoples similar, but more recent behavior, and then it uses conditional statements to decide what item to offer you in your recommendation items. It's spooky, but ultimately just a program running in the background trying to make your money theirs. Comparison The most common conditional operation is comparison. If we wish to compare whether two variables are the same we use the == (double equal sign). For example x == y means the program will ask whether x and y have the same value. If they do, the result is TRUE if not then the result is FALSE. Other comparison signs are != does NOT equal, < smaller than, > larger than, <= less than or equal, and >= greater than or equal. There are also three logical operators when we want to build multiple compares (multiple conditioning); these are and , or , and not . The and operator returns TRUE if (and only if) all conditions are TRUE. For instance 5 == 5 and 5 < 6 will return a TRUE because both conditions are true. The or operator returns TRUE if at least one condition is true. If all conditions are FALSE, then it will return a FALSE. For instance 4 > 3 or 17 > 20 or 3 == 2 will return TRUE because the first condition is true. The not operator returns TRUE if the condition after the not keyword is false. Think of it as a way to do a logic reversal. Block if statement The if statement is a common flow control statement. It allows the program to evaluate if a certain condition is satisfied and to perform a designed action based on the result of the evaluation. The structure of an if statement is if condition1 is met: do A elif condition 2 is met: do b elif condition 3 is met: do c else: do e The elif means \"else if\". The : colon is an important part of the structure it tells where the action begins. Also there are no scope delimiters like (), or {} . Instead Python uses indentation to isolate blocks of code. This convention is hugely important - many other coding environments use delimiters (called scoping delimiters), but Python does not. The indentation itself is the scoping delimiter. Inline if statement An inline if statement is a simpler form of an if statement and is more convenient if you only need to perform a simple conditional task. The syntax is: do TaskA `if` condition is true `else` do TaskB An example would be myInt = 3 num1 = 12 if myInt == 0 else 13 num1 An alternative way is to enclose the condition in brackets for some clarity like myInt = 3 num1 = 12 if (myInt == 0) else 13 num1 In either case the result is that num1 will have the value 13 (unless you set myInt to 0). One can also use if to construct extremely inefficient loops. Readings Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 Subpart 3 https://www.inferentialthinking.com/chapters/04/3/Comparison.html Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 https://www.inferentialthinking.com/chapters/04/Data_Types.html Learn Python the Hard Way (Online Book) https://learnpythonthehardway.org/book/ Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) https://www.learnpython.org/ Short, interactive tutorial for those who just need a quick way to pick up Python syntax. # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson03/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Lesson 3"},{"location":"lesson3/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 25 January 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson3/#lesson-3-data-structures-and-conditional-statements","text":"Data structures; lists, arrays, tuples, sets, dictionaries Name, index, contents; keys Conditional sturctures; logical compares, block and in-line if","title":"Lesson 3 Data Structures and Conditional Statements:"},{"location":"lesson3/#special-script-blocks","text":"%%html <!-- Script Block to set tables to left alignment --> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;}","title":"Special Script Blocks"},{"location":"lesson3/#objectives","text":"1) Develop awareness of data structures available in Python to store and manipulate data 1. Implement arrays (lists), dictionaries, and tuples 2. Address contents of lists , dictionaries, and tuples 2) Develop awareness of decision making in Python 1. Implement decision making in Python using using if-then ... conditional statements","title":"Objectives"},{"location":"lesson3/#data-structures-and-conditional-statements","text":"Computational thinking (CT) concepts involved are: Decomposition : Data interpretation, manipulation, and analysis of NumPy arrays Abstraction : Data structures; Arrays, lists, tuples, sets, and dictionaries Algorithms : Conditional statements","title":"Data Structures and Conditional Statements"},{"location":"lesson3/#what-is-a-data-structure","text":"Data Structures are a specialized means of organizing and storing data in computers in such a way that we can perform operations on the stored data more efficiently. In our iPython world the structures are illustrated in the figure below","title":"What is a data structure?"},{"location":"lesson3/#lists","text":"A list is a collection of data that are somehow related. It is a convenient way to refer to a collection of similar things by a single name, and using an index (like a subscript in math) to identify a particular item. Consider the \"math-like\" variable x below: \\begin{gather} x_0= 7 \\\\ x_1= 11 \\\\ x_2= 5 \\\\ x_3= 9 \\\\ x_4= 13 \\\\ \\dots \\\\ x_N= 223 \\\\ \\end{gather} The variable name is x and the subscripts correspond to different values. Thus the value of the variable named x associated with subscript 3 is the number 9 . The figure below is a visual representation of a the concept that treats a variable as a collection of cells. In the figure, the variable name is MyList , the subscripts are replaced by an index which identifies which cell is being referenced. The value is the cell content at the particular index. So in the figure the value of MyList at Index = 3 is the number 9.' In engineering and data science we use lists a lot - we often call then vectors, arrays, matrices and such, but they are ultimately just lists. To declare a list you can write the list name and assign it values. The square brackets are used to identify that the variable is a list. Like: MyList = [7,11,5,9,13,66,99,223] One can also declare a null list and use the append() method to fill it as needed. MyOtherList = [ ] Python indices start at ZERO . A lot of other languages start at ONE. It's just the convention. The first element in a list has an index of 0, the second an index of 1, and so on. We access the contents of a list by referring to its name and index. For example MyList[3] has a value of the number 9.","title":"Lists"},{"location":"lesson3/#arrays","text":"Arrays are lists that are used to store only elements of a specific data type - Ordered: Elements in an array can be indexed - Mutable: Elements in an array can be altered Data type that an array must hold is specified using the type code when it is created - \u2018f\u2019 for float - \u2018d\u2019 for double - \u2018i\u2019 for signed int - \u2018I\u2019 for unsigned int More types are listed below Type Code C Data Type Python Data Type Minimum Size in Bytes 'b' signed char int 1 'B' unsigned char int 1 'h' signed short int 2 'H' unsigned short int 2 'i' signed int int 2 'I' unsigned int int 2 'l' signed long int 4 'L' unsigned long int 4 'q' signed long long int 8 'Q' unsigned long long int 8 'f' float float 4 'd' double float 8 To use arrays, a library named \u2018array\u2019 must be imported import array Creating an array that contains signed integer numbers myarray = array.array('i', [1, 2, 4, 8, 16, 32]) myarray[0] #1-st element, 0-th position 1 import array as arr #import using an alias so the calls dont look so funny myarray = arr.array('i', [1, 2, 4, 8, 16, 32]) myarray[0] #1-st element, 0-th position 1 Lists: Can store elements of different data types; like arrays they are (arrays are lists, but lists are not quite arrays!) - Ordered: Elements in a list can be indexed - Mutable: Elements in a list can be altered - Mathematical operations must be applied to each element of the list","title":"Arrays"},{"location":"lesson3/#tuple-a-special-list","text":"A tuple is a special kind of list where the values cannot be changed after the list is created. Such a property is called immutable It is useful for list-like things that are static - like days in a week, or months of a year. You declare a tuple like a list, except use round brackets instead of square brackets. MyTupleName = (\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\") Tuples are often created as output from packages and functions.","title":"Tuple - A special list"},{"location":"lesson3/#dictionary-a-special-list","text":"A dictionary is a special kind of list where the items are related data PAIRS . It is a lot like a relational database (it probably is one in fact) where the first item in the pair is called the key, and must be unique in a dictionary, and the second item in the pair is the data. The second item could itself be a list, so a dictionary would be a meaningful way to build a database in Python. To declare a dictionary using curly brackets MyPetsNamesAndMass = { \"Dusty\":7.8 , \"Aspen\":6.3, \"Merrimee\":0.03} To declare a dictionary using the dict() method MyPetsNamesAndMassToo = dict(Dusty = 7.8 , Aspen = 6.3, Merrimee = 0.03) Dictionary properties - Unordered: Elements in a dictionary cannot be - Mutable elements: Elements in a dictionary can be altered - Immutable keys: Keys in a dictionary cannot be altered","title":"Dictionary - A special list"},{"location":"lesson3/#sets-a-special-list","text":"Sets: Are used to store elements of different data types - Unordered: Elements in a set cannot be indexed - Mutable: Elements in a set can be altered - Non-repetition: Elements in a set are unique Elements of a set are enclosed in curly brackets { } - Creating sets that contains different data types - Sets cannot be nested","title":"Sets - A special list"},{"location":"lesson3/#whats-the-difference-between-a-set-and-dictionary","text":"From https://stackoverflow.com/questions/34370599/difference-between-dict-and-set-python \"Well, a set is like a dict with keys but no values, and they're both implemented using a hash table. But yes, it's a little annoying that the {} notation denotes an empty dict rather than an empty set , but that's a historical artifact.\"","title":"What's the difference between a set and dictionary?"},{"location":"lesson3/#conditional-statements","text":"Decision making via conditional statements is an important step in algorithm design; they control the flow of execution of a program. Conditional statements in Python include: if statement if....else statements if....elif....else statements Conditional statements are logical expressions that evaluate as TRUE or FALSE and using these results to perform further operations based on these conditions. All flow control in a program depends on evaluating conditions. The program will proceed diferently based on the outcome of one or more conditions - really sophisticated AI programs are a collection of conditions and correlations. Expressed in a flowchart a block if statement looks like: As psuedo code: if(condition is true): do stuff Amazon knowing what you kind of want is based on correlations of your past behavior compared to other peoples similar, but more recent behavior, and then it uses conditional statements to decide what item to offer you in your recommendation items. It's spooky, but ultimately just a program running in the background trying to make your money theirs.","title":"Conditional Statements"},{"location":"lesson3/#comparison","text":"The most common conditional operation is comparison. If we wish to compare whether two variables are the same we use the == (double equal sign). For example x == y means the program will ask whether x and y have the same value. If they do, the result is TRUE if not then the result is FALSE. Other comparison signs are != does NOT equal, < smaller than, > larger than, <= less than or equal, and >= greater than or equal. There are also three logical operators when we want to build multiple compares (multiple conditioning); these are and , or , and not . The and operator returns TRUE if (and only if) all conditions are TRUE. For instance 5 == 5 and 5 < 6 will return a TRUE because both conditions are true. The or operator returns TRUE if at least one condition is true. If all conditions are FALSE, then it will return a FALSE. For instance 4 > 3 or 17 > 20 or 3 == 2 will return TRUE because the first condition is true. The not operator returns TRUE if the condition after the not keyword is false. Think of it as a way to do a logic reversal.","title":"Comparison"},{"location":"lesson3/#block-if-statement","text":"The if statement is a common flow control statement. It allows the program to evaluate if a certain condition is satisfied and to perform a designed action based on the result of the evaluation. The structure of an if statement is if condition1 is met: do A elif condition 2 is met: do b elif condition 3 is met: do c else: do e The elif means \"else if\". The : colon is an important part of the structure it tells where the action begins. Also there are no scope delimiters like (), or {} . Instead Python uses indentation to isolate blocks of code. This convention is hugely important - many other coding environments use delimiters (called scoping delimiters), but Python does not. The indentation itself is the scoping delimiter.","title":"Block if statement"},{"location":"lesson3/#inline-if-statement","text":"An inline if statement is a simpler form of an if statement and is more convenient if you only need to perform a simple conditional task. The syntax is: do TaskA `if` condition is true `else` do TaskB An example would be myInt = 3 num1 = 12 if myInt == 0 else 13 num1 An alternative way is to enclose the condition in brackets for some clarity like myInt = 3 num1 = 12 if (myInt == 0) else 13 num1 In either case the result is that num1 will have the value 13 (unless you set myInt to 0). One can also use if to construct extremely inefficient loops.","title":"Inline if statement"},{"location":"lesson3/#readings","text":"Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 Subpart 3 https://www.inferentialthinking.com/chapters/04/3/Comparison.html Computational and Inferential Thinking Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND) Chapter 4 https://www.inferentialthinking.com/chapters/04/Data_Types.html Learn Python the Hard Way (Online Book) https://learnpythonthehardway.org/book/ Recommended for beginners who want a complete course in programming with Python. LearnPython.org (Interactive Tutorial) https://www.learnpython.org/ Short, interactive tutorial for those who just need a quick way to pick up Python syntax. # Script block to identify host, user, and kernel import sys ! hostname ! whoami ! pwd print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /home/compthink/engr-1330-webroot/1-Lessons/Lesson03/OriginalPowerpoint /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Readings"},{"location":"lesson8/","text":"ENGR 1330 Computational Thinking with Data Science Last GitHub Commit Date: 14 February 2021 Lesson 8 The Pandas module About Pandas How to install Anaconda JupyterHub/Lab (on Linux) JupyterHub/Lab (on MacOS) JupyterHub/Lab (on Windoze) The Dataframe Primatives Using Pandas Create, Modify, Delete datagrames Slice Dataframes Conditional Selection Synthetic Programming (Symbolic Function Application) Files Access Files from a remote Web Server Get file contents Get the actual file Adaptations for encrypted servers (future semester) Special Script Blocks %%html <!--Script block to left align Markdown Tables--> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;} Objectives To understand the dataframe abstraction as implemented in the Pandas library(module). To be able to access and manipulate data within a dataframe To be able to obtain basic statistical measures of data within a dataframe Read/Write from/to files MS Excel-type files (.xls,.xlsx,.csv) (LibreOffice files use the MS .xml standard) Ordinary ASCII (.txt) files Access files directly from a URL (advanced concept) Using a wget-type function Using a curl-type function Using API keys (future versions) Pandas: Pandas is the core library for dataframe manipulation in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays. The library\u2019s name is derived from the term \u2018Panel Data\u2019. If you are curious about Pandas, this cheat sheet is recommended: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf Data Structure The Primary data structure is called a dataframe. It is an abstraction where data are represented as a 2-dimensional mutable and heterogenous tabular data structure; much like a Worksheet in MS Excel. The structure itself is popular among statisticians and data scientists and business executives. According to the marketing department \"Pandas Provides rich data structures and functions designed to make working with data fast, easy, and expressive. It is useful in data manipulation, cleaning, and analysis; Pandas excels in performance and productivity \" The Dataframe A data table is called a DataFrame in pandas (and other programming environments too). The figure below from https://pandas.pydata.org/docs/getting_started/index.html illustrates a dataframe model: Each column and each row in a dataframe is called a series, the header row, and index column are special. Like MS Excel we can query the dataframe to find the contents of a particular cell using its row name and column name , or operate on entire rows and columns To use pandas, we need to import the module. Computational Thinking Concepts The CT concepts expressed within Pandas include: Decomposition : Data interpretation, manipulation, and analysis of Pandas dataframes is an act of decomposition -- although the dataframes can be quite complex. Abstraction : The dataframe is a data representation abstraction that allows for placeholder operations, later substituted with specific contents for a problem; enhances reuse and readability. We leverage the principle of algebraic replacement using these abstractions. Algorithms : Data interpretation, manipulation, and analysis of dataframes are generally implemented as part of a supervisory algorithm. Module Set-Up In principle, Pandas should be available in a default Anaconda install - You should not have to do any extra installation steps to install the library in Python - You do have to import the library in your scripts How to check - Simply open a code cell and run import pandas if the notebook does not protest (i.e. pink block of error), the youis good to go. import pandas If you do get an error, that means that you will have to install using conda or pip ; you are on-your-own here! On the content server the process is: Open a new terminal from the launcher Change to root user su then enter the root password sudo -H /opt/jupyterhib/bin/python3 -m pip install pandas Wait until the install is complete; for security, user compthink is not in the sudo group Verify the install by trying to execute import pandas as above. The process above will be similar on a Macintosh, or Windows if you did not use an Anaconda distribution. Best is to have a sucessful anaconda install, or go to the GoodJobUntilMyOrgansGetHarvested . If you have to do this kind of install, you will have to do some reading, some references I find useful are: 1. https://jupyterlab.readthedocs.io/en/stable/user/extensions.html 2. https://www.pugetsystems.com/labs/hpc/Note-How-To-Install-JupyterHub-on-a-Local-Server-1673/#InstallJupyterHub 3. https://jupyterhub.readthedocs.io/en/stable/installation-guide-hard.html (This is the approach on the content server which has a functioning JupyterHub) Dataframe-type Structure using primative python First lets construct a dataframe like object using python primatives. We will construct 3 lists, one for row names, one for column names, and one for the content. import numpy mytabular = numpy.random.randint(1,100,(5,4)) myrowname = ['A','B','C','D','E'] mycolname = ['W','X','Y','Z'] mytable = [['' for jcol in range(len(mycolname)+1)] for irow in range(len(myrowname)+1)] #non-null destination matrix, note the implied loop construction The above builds a placeholder named mytable for the psuedo-dataframe. Next we populate the table, using a for loop to write the column names in the first row, row names in the first column, and the table fill for the rest of the table. for irow in range(1,len(myrowname)+1): # write the row names mytable[irow][0]=myrowname[irow-1] for jcol in range(1,len(mycolname)+1): # write the column names mytable[0][jcol]=mycolname[jcol-1] for irow in range(1,len(myrowname)+1): # fill the table (note the nested loop) for jcol in range(1,len(mycolname)+1): mytable[irow][jcol]=mytabular[irow-1][jcol-1] Now lets print the table out by row and we see we have a very dataframe-like structure for irow in range(0,len(myrowname)+1): print(mytable[irow][0:len(mycolname)+1]) ['', 'W', 'X', 'Y', 'Z'] ['A', 3, 78, 15, 62] ['B', 82, 5, 27, 80] ['C', 36, 35, 63, 30] ['D', 88, 77, 55, 74] ['E', 9, 86, 44, 87] We can also query by row print(mytable[3][0:len(mycolname)+1]) ['C', 36, 35, 63, 30] Or by column for irow in range(0,len(myrowname)+1): #cannot use implied loop in a column slice print(mytable[irow][2]) X 78 5 35 77 86 Or by row+column index; sort of looks like a spreadsheet syntax. print(' ',mytable[0][3]) print(mytable[3][0],mytable[3][3]) Y C 63 Now we shall create a proper dataframe We will now do the same using pandas mydf = pandas.DataFrame(numpy.random.randint(1,100,(5,4)), ['A','B','C','D','E'], ['W','X','Y','Z']) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 C 91 63 19 69 D 83 24 96 95 E 75 23 71 74 We can also turn our table into a dataframe, notice how the constructor adds header row and index column mydf1 = pandas.DataFrame(mytable) mydf1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 0 W X Y Z 1 A 3 78 15 62 2 B 82 5 27 80 3 C 36 35 63 30 4 D 88 77 55 74 5 E 9 86 44 87 To get proper behavior, we can just reuse our original objects mydf2 = pandas.DataFrame(mytabular,myrowname,mycolname) mydf2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 3 78 15 62 B 82 5 27 80 C 36 35 63 30 D 88 77 55 74 E 9 86 44 87 Why are mydf and mydf2 different? Getting the shape of dataframes The shape method, which is available after the dataframe is constructed, will return the row and column rank (count) of a dataframe. mydf.shape (5, 4) mydf1.shape (6, 5) mydf2.shape (5, 4) Appending new columns To append a column simply assign a value to a new column name to the dataframe mydf['new']= 'NA' mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 33 46 69 49 NA B 65 66 90 24 NA C 91 63 19 69 NA D 83 24 96 95 NA E 75 23 71 74 NA Appending new rows This is sometimes a bit trickier but here is one way: - create a copy of a row, give it a new name. - concatenate it back into the dataframe. newrow = mydf.loc[['E']].rename(index={\"E\": \"X\"}) # create a single row, rename the index newtable = pandas.concat([mydf,newrow]) # concatenate the row to bottom of df - note the syntax newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 33 46 69 49 NA B 65 66 90 24 NA C 91 63 19 69 NA D 83 24 96 95 NA E 75 23 71 74 NA X 75 23 71 74 NA Removing Rows and Columns To remove a column is straightforward, we use the drop method newtable.drop('new', axis=1, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 C 91 63 19 69 D 83 24 96 95 E 75 23 71 74 X 75 23 71 74 To remove a row, you really got to want to, easiest is probablty to create a new dataframe with the row removed newtable = newtable.loc[['A','B','D','E','X']] # select all rows except C newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 D 83 24 96 95 E 75 23 71 74 X 75 23 71 74 # or just use drop with axis specify newtable.drop('X', axis=0, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 D 83 24 96 95 E 75 23 71 74 Indexing We have already been indexing, but a few examples follow: newtable['X'] #Selecing a single column A 46 B 66 D 24 E 23 Name: X, dtype: int64 newtable[['X','W']] #Selecing a multiple columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X W A 46 33 B 66 65 D 24 83 E 23 75 newtable.loc['E'] #Selecing rows based on label via loc[ ] indexer W 75 X 23 Y 71 Z 74 Name: E, dtype: int64 newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 D 83 24 96 95 E 75 23 71 74 newtable.loc[['E','D','B']] #Selecing multiple rows based on label via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z E 75 23 71 74 D 83 24 96 95 B 65 66 90 24 newtable.loc[['B','E','D'],['X','Y']] #Selecting elements via both rows and columns via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X Y B 66 90 E 23 71 D 24 96 Conditional Selection mydf = pandas.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach #What fruit corresponds to the number 555 in \u2018col2\u2019? mydf[mydf['col2']==555]['col3'] 1 apple Name: col3, dtype: object #What fruit corresponds to the minimum number in \u2018col2\u2019? mydf[mydf['col2']==mydf['col2'].min()]['col3'] 5 watermelon Name: col3, dtype: object Descriptor Functions #Creating a dataframe from a dictionary mydf = pandas.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach head method Returns the first few rows, useful to infer structure #Returns only the first five rows mydf.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit info method Returns the data model (data column count, names, data types) #Info about the dataframe mydf.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 8 entries, 0 to 7 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 col1 8 non-null int64 1 col2 8 non-null int64 2 col3 8 non-null object dtypes: int64(2), object(1) memory usage: 320.0+ bytes describe method Returns summary statistics of each numeric column. Also returns the minimum and maximum value in each column, and the IQR (Interquartile Range). Again useful to understand structure of the columns. #Statistics of the dataframe mydf.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 count 8.00000 8.0000 mean 4.50000 416.2500 std 2.44949 211.8576 min 1.00000 111.0000 25% 2.75000 222.0000 50% 4.50000 444.0000 75% 6.25000 582.7500 max 8.00000 666.0000 Counting and Sum methods There are also methods for counts and sums by specific columns mydf['col2'].sum() #Sum of a specified column 3330 The unique method returns a list of unique values (filters out duplicates in the list, underlying dataframe is preserved) mydf['col2'].unique() #Returns the list of unique values along the indexed column array([444, 555, 666, 111, 222]) The nunique method returns a count of unique values mydf['col2'].nunique() #Returns the total number of unique values along the indexed column 5 The value_counts() method returns the count of each unique value (kind of like a histogram, but each value is the bin) mydf['col2'].value_counts() #Returns the number of occurences of each unique value 666 2 444 2 222 2 555 1 111 1 Name: col2, dtype: int64 Using functions in dataframes - symbolic apply The power of Pandas is an ability to apply a function to each element of a dataframe series (or a whole frame) by a technique called symbolic (or synthetic programming) application of the function. This employs principles of pattern matching , abstraction , and algorithm development ; a holy trinity of Computational Thinning. It's somewhat complicated but quite handy, best shown by an example: def times2(x): # A prototype function to scalar multiply an object x by 2 return(x*2) print(mydf) print('Apply the times2 function to col2') mydf['col2'].apply(times2) #Symbolic apply the function to each element of column col2, result is another dataframe col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach Apply the times2 function to col2 0 888 1 1110 2 1332 3 888 4 1332 5 222 6 444 7 444 Name: col2, dtype: int64 Sorting mydf.sort_values('col2', ascending = True) #Sorting based on columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 5 6 111 watermelon 6 7 222 banana 7 8 222 peach 0 1 444 orange 3 4 444 mango 1 2 555 apple 2 3 666 grape 4 5 666 jackfruit mydf.sort_values('col3', ascending = True) #Lexiographic sort .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 1 2 555 apple 6 7 222 banana 2 3 666 grape 4 5 666 jackfruit 3 4 444 mango 0 1 444 orange 7 8 222 peach 5 6 111 watermelon Aggregating (Grouping Values) dataframe contents #Creating a dataframe from a dictionary data = { 'key' : ['A', 'B', 'C', 'A', 'B', 'C'], 'data1' : [1, 2, 3, 4, 5, 6], 'data2' : [10, 11, 12, 13, 14, 15], 'data3' : [20, 21, 22, 13, 24, 25] } mydf1 = pandas.DataFrame(data) mydf1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 data3 0 A 1 10 20 1 B 2 11 21 2 C 3 12 22 3 A 4 13 13 4 B 5 14 24 5 C 6 15 25 # Grouping and summing values in all the columns based on the column 'key' mydf1.groupby('key').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 data3 key A 5 23 33 B 7 25 45 C 9 27 47 # Grouping and summing values in the selected columns based on the column 'key' mydf1.groupby('key')[['data1', 'data2']].sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key A 5 23 B 7 25 C 9 27 Filtering out missing values Filtering and cleaning are often used to describe the process where data that does not support a narrative is removed ;typically for maintenance of profit applications, if the data are actually missing that is common situation where cleaning is justified. #Creating a dataframe from a dictionary df = pandas.DataFrame({'col1':[1,2,3,4,None,6,7,None], 'col2':[444,555,None,444,666,111,None,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 NaN grape 3 4.0 444.0 mango 4 NaN 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 NaN banana 7 NaN 222.0 peach Below we drop any row that contains a NaN code. df_dropped = df.dropna() df_dropped .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 3 4.0 444.0 mango 5 6.0 111.0 watermelon Below we replace NaN codes with some value, in this case 0 df_filled1 = df.fillna(0) df_filled1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 0.0 grape 3 4.0 444.0 mango 4 0.0 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 0.0 banana 7 0.0 222.0 peach Below we replace NaN codes with some value, in this case the mean value of of the column in which the missing value code resides. df_filled2 = df.fillna(df.mean()) df_filled2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.000000 444.0 orange 1 2.000000 555.0 apple 2 3.000000 407.0 grape 3 4.000000 444.0 mango 4 3.833333 666.0 jackfruit 5 6.000000 111.0 watermelon 6 7.000000 407.0 banana 7 3.833333 222.0 peach Reading a File into a Dataframe Pandas has methods to read common file types, such as csv , xlsx , and json . Ordinary text files are also quite manageable. On a machine you control you can write script to retrieve files from the internet and process them. readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') #Reading a .csv file print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 Similar to reading and writing .csv files, you can also read and write .xslx files as below (useful to know this) readfileexcel = pandas.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1') #Reading a .xlsx file print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 Writing a dataframe to file #Creating and writing to a .csv file readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile1.csv') readfilecsv = pandas.read_csv('CSV_WritingFile1.csv') print(readfilecsv) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 #Creating and writing to a .csv file by excluding row labels readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile2.csv', index = False) readfilecsv = pandas.read_csv('CSV_WritingFile2.csv') print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 #Creating and writing to a .xlsx file readfileexcel = pandas.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1') readfileexcel.to_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', index = False) readfileexcel = pandas.read_excel('Excel_WritingFile.xlsx', sheet_name='MySheet') print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 Downloading files from websites (optional) This section shows how to get files from a remote computer. There are several ways to get the files, most importantly you need the FQDN to the file. Method 1: Get data from a file on a remote server (unencrypted) This section shows how to obtain data files from public URLs. Prerequesites: You know the FQDN to the file it will be in structure of \"http://server-name/.../filename.ext\" The server is running ordinary (unencrypted) web services, i.e. http://... Web Developer Notes If you want to distribute files (web developers) the files need to be in the server webroot, but can be deep into the heirarchial structure. Here we will do an example with a file that contains topographic data in XYZ format, without header information. The first few lines of the remote file look like: 74.90959724 93.21251922 0 75.17907367 64.40278759 0 94.9935575 93.07951286 0 95.26234119 64.60091165 0 54.04976655 64.21159095 0 54.52914363 35.06934342 0 75.44993558 34.93079513 0 75.09317373 5.462959114 0 74.87357468 10.43130083 0 74.86249082 15.72938748 0 And importantly it is tab delimited. The module to manipulate url in python is called urllib Google search to learn more, here we are using only a small component without exception trapping. #Step 1: import needed modules to interact with the internet from urllib.request import urlopen # import a method that will connect to a url and read file contents import pandas #import pandas This next code fragment sets a string called remote_url ; it is just a variable, name can be anything that honors python naming rules. Then the urllib function urlopen with read and decode methods is employed, the result is stored in an object named elevationXYZ #Step 2: make the connection to the remote file (actually its implementing \"bash curl -O http://fqdn/path ...\") remote_url = 'http://www.rtfmps.com/share_files/pip-corner-sumps.txt' # elevationXYZ = urlopen(remote_url).read().decode().split() # Gets the file contents as a single vector, comma delimited, file is not retained locally At this point the object exists as a single vector with hundreds of elements. We now need to structure the content. Here using python primatives, and knowing how the data are supposed to look, we prepare variables to recieve the structured results #Step 3 Python primatives to structure the data, or use fancy modules (probably easy in numpy) howmany = len(elevationXYZ) # how long is the vector? nrow = int(howmany/3) xyz = [[0 for j in range(3)] for j in range(nrow)] # null space to receive data define columnX Now that everything is ready, we can extract from the object the values we want into xyz #Step4 Now will build xyz as a matrix with 3 columns index = 0 for irow in range(0,nrow): xyz[irow][0]=float(elevationXYZ[index]) xyz[irow][1]=float(elevationXYZ[index+1]) xyz[irow][2]=float(elevationXYZ[index+2]) index += 3 #increment the index xyz is now a 3-column float array and can now probably be treated as a data frame. Here we use a pandas method to build the dataframe. df = pandas.DataFrame(xyz) Get some info, yep three columns (ordered triples to be precise!) df.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 774 entries, 0 to 773 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 0 774 non-null float64 1 1 774 non-null float64 2 2 774 non-null float64 dtypes: float64(3) memory usage: 18.3 KB And some summary statistics (meaningless for these data), but now have taken data from the internet and prepared it for analysis. df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 count 774.000000 774.000000 774.000000 mean 52.064621 48.770060 2.364341 std 30.883400 32.886277 1.497413 min -2.113554 -11.360960 0.000000 25% 25.640786 21.809579 2.000000 50% 55.795821 49.059950 2.000000 75% 76.752290 75.015933 4.000000 max 111.726727 115.123931 4.000000 And lets look at the first few rows df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 74.909597 93.212519 0.0 1 75.179074 64.402788 0.0 2 94.993557 93.079513 0.0 3 95.262341 64.600912 0.0 4 54.049767 64.211591 0.0 Method 2: Get the actual file from a remote web server (unencrypted) You know the FQDN to the file it will be in structure of \"http://server-name/.../filename.ext\" The server is running ordinary (unencrypted) web services, i.e. http://... We will need a module to interface with the remote server, in this example lets use something different than urllib . Here we will use requests , so first we load the module import requests # Module to process http/https requests Now we will generate a GET request to the remote http server. I chose to do so using a variable to store the remote URL so I can reuse code in future projects. The GET request (an http/https method) is generated with the requests method get and assigned to an object named rget -- the name is arbitrary. Next we extract the file from the rget object and write it to a local file with the name of the remote file - esentially automating the download process. Then we import the pandas module. remote_url=\"http://54.243.252.9/engr-1330-psuedo-course/MyJupyterNotebooks/42-DataScience-EvaporationAnalysis/all_quads_gross_evaporation.csv\" # set the url rget = requests.get(remote_url, allow_redirects=True) # get the remote resource, follow imbedded links open('all_quads_gross_evaporation.csv','wb').write(rget.content) # extract from the remote the contents, assign to a local file same name import pandas as pd # Module to process dataframes (not absolutely needed but somewhat easier than using primatives, and gives graphing tools) # verify file exists ! pwd ! ls -la /home/compthink/engr-1330-webroot/1-Lessons/Lesson08/OriginalPowerpoint total 1268 drwxrwxr-x 4 compthink compthink 4096 Feb 15 01:30 . drwxrwxr-x 5 compthink compthink 4096 Feb 10 02:50 .. drwxrwxr-x 2 compthink compthink 4096 Feb 15 01:12 .ipynb_checkpoints -rw-rw-r-- 1 compthink compthink 21150 Feb 14 21:07 01-table-dataframe.png -rw-rw-r-- 1 compthink compthink 51 Feb 14 23:00 CSV_ReadingFile.csv -rw-rw-r-- 1 compthink compthink 55 Feb 14 23:12 CSV_WritingFile1.csv -rw-rw-r-- 1 compthink compthink 46 Feb 14 23:12 CSV_WritingFile2.csv -rw-rw-r-- 1 compthink compthink 693687 Feb 15 01:12 ENGR-1330-Lesson8-Dev.html -rw-rw-r-- 1 compthink compthink 164919 Feb 15 01:30 ENGR-1330-Lesson8-Dev.ipynb -rw-rw-r-- 1 compthink compthink 5508 Feb 14 23:01 Excel_ReadingFile.xlsx -rw-rw-r-- 1 compthink compthink 5042 Feb 14 23:12 Excel_WritingFile.xlsx -rw-rw-r-- 1 compthink compthink 363498 Feb 15 01:30 all_quads_gross_evaporation.csv drwxrwxr-x 3 compthink compthink 4096 Feb 15 01:12 src.old Now we can read the file contents and check its structure, before proceeding. evapdf = pd.read_csv(\"all_quads_gross_evaporation.csv\",parse_dates=[\"YYYY-MM\"]) # Read the file as a .CSV assign to a dataframe evapdf evapdf.head() # check structure .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } YYYY-MM 104 105 106 107 108 204 205 206 207 ... 911 912 1008 1009 1010 1011 1108 1109 1110 1210 0 1954-01-01 1.80 1.80 2.02 2.24 2.24 2.34 1.89 1.80 1.99 ... 1.42 1.30 2.50 2.42 1.94 1.29 2.59 2.49 2.22 2.27 1 1954-02-01 4.27 4.27 4.13 3.98 3.90 4.18 4.26 4.27 4.26 ... 2.59 2.51 4.71 4.30 3.84 2.50 5.07 4.62 4.05 4.18 2 1954-03-01 4.98 4.98 4.62 4.25 4.20 5.01 4.98 4.98 4.68 ... 3.21 3.21 6.21 6.06 5.02 3.21 6.32 6.20 5.68 5.70 3 1954-04-01 6.09 5.94 5.94 6.07 5.27 6.31 5.98 5.89 5.72 ... 3.83 3.54 6.45 6.25 4.92 3.54 6.59 6.44 5.88 5.95 4 1954-05-01 5.41 5.09 5.14 4.40 3.61 5.57 4.56 4.47 4.18 ... 3.48 3.97 7.92 8.13 6.31 3.99 7.75 7.98 7.40 7.40 5 rows \u00d7 93 columns Structure looks like a spreadsheet as expected; lets plot the time series for cell '911' evapdf.plot.line(x='YYYY-MM',y='911') # Plot quadrant 911 evaporation time series <AxesSubplot:xlabel='YYYY-MM'> Method 3: Get the actual file from an encrypted server This section is saved for future semesters References Overland, B. (2018). Python Without Fear. Addison-Wesley ISBN 978-0-13-468747-6. Grus, Joel (2015). Data Science from Scratch: First Principles with Python O\u2019Reilly Media. Kindle Edition. Precord, C. (2010) wxPython 2.8 Application Development Cookbook Packt Publishing Ltd. Birmingham , B27 6PA, UK ISBN 978-1-849511-78-0. # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"Lesson 8"},{"location":"lesson8/#engr-1330-computational-thinking-with-data-science","text":"Last GitHub Commit Date: 14 February 2021","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"lesson8/#lesson-8-the-pandas-module","text":"About Pandas How to install Anaconda JupyterHub/Lab (on Linux) JupyterHub/Lab (on MacOS) JupyterHub/Lab (on Windoze) The Dataframe Primatives Using Pandas Create, Modify, Delete datagrames Slice Dataframes Conditional Selection Synthetic Programming (Symbolic Function Application) Files Access Files from a remote Web Server Get file contents Get the actual file Adaptations for encrypted servers (future semester)","title":"Lesson 8 The Pandas module"},{"location":"lesson8/#special-script-blocks","text":"%%html <!--Script block to left align Markdown Tables--> <style> table {margin-left: 0 !important;} </style> table {margin-left: 0 !important;}","title":"Special Script Blocks"},{"location":"lesson8/#objectives","text":"To understand the dataframe abstraction as implemented in the Pandas library(module). To be able to access and manipulate data within a dataframe To be able to obtain basic statistical measures of data within a dataframe Read/Write from/to files MS Excel-type files (.xls,.xlsx,.csv) (LibreOffice files use the MS .xml standard) Ordinary ASCII (.txt) files Access files directly from a URL (advanced concept) Using a wget-type function Using a curl-type function Using API keys (future versions)","title":"Objectives"},{"location":"lesson8/#pandas","text":"Pandas is the core library for dataframe manipulation in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays. The library\u2019s name is derived from the term \u2018Panel Data\u2019. If you are curious about Pandas, this cheat sheet is recommended: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf","title":"Pandas:"},{"location":"lesson8/#data-structure","text":"The Primary data structure is called a dataframe. It is an abstraction where data are represented as a 2-dimensional mutable and heterogenous tabular data structure; much like a Worksheet in MS Excel. The structure itself is popular among statisticians and data scientists and business executives. According to the marketing department \"Pandas Provides rich data structures and functions designed to make working with data fast, easy, and expressive. It is useful in data manipulation, cleaning, and analysis; Pandas excels in performance and productivity \"","title":"Data Structure"},{"location":"lesson8/#the-dataframe","text":"A data table is called a DataFrame in pandas (and other programming environments too). The figure below from https://pandas.pydata.org/docs/getting_started/index.html illustrates a dataframe model: Each column and each row in a dataframe is called a series, the header row, and index column are special. Like MS Excel we can query the dataframe to find the contents of a particular cell using its row name and column name , or operate on entire rows and columns To use pandas, we need to import the module.","title":"The Dataframe"},{"location":"lesson8/#computational-thinking-concepts","text":"The CT concepts expressed within Pandas include: Decomposition : Data interpretation, manipulation, and analysis of Pandas dataframes is an act of decomposition -- although the dataframes can be quite complex. Abstraction : The dataframe is a data representation abstraction that allows for placeholder operations, later substituted with specific contents for a problem; enhances reuse and readability. We leverage the principle of algebraic replacement using these abstractions. Algorithms : Data interpretation, manipulation, and analysis of dataframes are generally implemented as part of a supervisory algorithm.","title":"Computational Thinking Concepts"},{"location":"lesson8/#module-set-up","text":"In principle, Pandas should be available in a default Anaconda install - You should not have to do any extra installation steps to install the library in Python - You do have to import the library in your scripts How to check - Simply open a code cell and run import pandas if the notebook does not protest (i.e. pink block of error), the youis good to go. import pandas If you do get an error, that means that you will have to install using conda or pip ; you are on-your-own here! On the content server the process is: Open a new terminal from the launcher Change to root user su then enter the root password sudo -H /opt/jupyterhib/bin/python3 -m pip install pandas Wait until the install is complete; for security, user compthink is not in the sudo group Verify the install by trying to execute import pandas as above. The process above will be similar on a Macintosh, or Windows if you did not use an Anaconda distribution. Best is to have a sucessful anaconda install, or go to the GoodJobUntilMyOrgansGetHarvested . If you have to do this kind of install, you will have to do some reading, some references I find useful are: 1. https://jupyterlab.readthedocs.io/en/stable/user/extensions.html 2. https://www.pugetsystems.com/labs/hpc/Note-How-To-Install-JupyterHub-on-a-Local-Server-1673/#InstallJupyterHub 3. https://jupyterhub.readthedocs.io/en/stable/installation-guide-hard.html (This is the approach on the content server which has a functioning JupyterHub)","title":"Module Set-Up"},{"location":"lesson8/#dataframe-type-structure-using-primative-python","text":"First lets construct a dataframe like object using python primatives. We will construct 3 lists, one for row names, one for column names, and one for the content. import numpy mytabular = numpy.random.randint(1,100,(5,4)) myrowname = ['A','B','C','D','E'] mycolname = ['W','X','Y','Z'] mytable = [['' for jcol in range(len(mycolname)+1)] for irow in range(len(myrowname)+1)] #non-null destination matrix, note the implied loop construction The above builds a placeholder named mytable for the psuedo-dataframe. Next we populate the table, using a for loop to write the column names in the first row, row names in the first column, and the table fill for the rest of the table. for irow in range(1,len(myrowname)+1): # write the row names mytable[irow][0]=myrowname[irow-1] for jcol in range(1,len(mycolname)+1): # write the column names mytable[0][jcol]=mycolname[jcol-1] for irow in range(1,len(myrowname)+1): # fill the table (note the nested loop) for jcol in range(1,len(mycolname)+1): mytable[irow][jcol]=mytabular[irow-1][jcol-1] Now lets print the table out by row and we see we have a very dataframe-like structure for irow in range(0,len(myrowname)+1): print(mytable[irow][0:len(mycolname)+1]) ['', 'W', 'X', 'Y', 'Z'] ['A', 3, 78, 15, 62] ['B', 82, 5, 27, 80] ['C', 36, 35, 63, 30] ['D', 88, 77, 55, 74] ['E', 9, 86, 44, 87] We can also query by row print(mytable[3][0:len(mycolname)+1]) ['C', 36, 35, 63, 30] Or by column for irow in range(0,len(myrowname)+1): #cannot use implied loop in a column slice print(mytable[irow][2]) X 78 5 35 77 86 Or by row+column index; sort of looks like a spreadsheet syntax. print(' ',mytable[0][3]) print(mytable[3][0],mytable[3][3]) Y C 63","title":"Dataframe-type Structure using primative python"},{"location":"lesson8/#now-we-shall-create-a-proper-dataframe","text":"We will now do the same using pandas mydf = pandas.DataFrame(numpy.random.randint(1,100,(5,4)), ['A','B','C','D','E'], ['W','X','Y','Z']) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 C 91 63 19 69 D 83 24 96 95 E 75 23 71 74 We can also turn our table into a dataframe, notice how the constructor adds header row and index column mydf1 = pandas.DataFrame(mytable) mydf1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 0 W X Y Z 1 A 3 78 15 62 2 B 82 5 27 80 3 C 36 35 63 30 4 D 88 77 55 74 5 E 9 86 44 87 To get proper behavior, we can just reuse our original objects mydf2 = pandas.DataFrame(mytabular,myrowname,mycolname) mydf2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 3 78 15 62 B 82 5 27 80 C 36 35 63 30 D 88 77 55 74 E 9 86 44 87 Why are mydf and mydf2 different?","title":"Now we shall create a proper dataframe"},{"location":"lesson8/#getting-the-shape-of-dataframes","text":"The shape method, which is available after the dataframe is constructed, will return the row and column rank (count) of a dataframe. mydf.shape (5, 4) mydf1.shape (6, 5) mydf2.shape (5, 4)","title":"Getting the shape of dataframes"},{"location":"lesson8/#appending-new-columns","text":"To append a column simply assign a value to a new column name to the dataframe mydf['new']= 'NA' mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 33 46 69 49 NA B 65 66 90 24 NA C 91 63 19 69 NA D 83 24 96 95 NA E 75 23 71 74 NA","title":"Appending new columns"},{"location":"lesson8/#appending-new-rows","text":"This is sometimes a bit trickier but here is one way: - create a copy of a row, give it a new name. - concatenate it back into the dataframe. newrow = mydf.loc[['E']].rename(index={\"E\": \"X\"}) # create a single row, rename the index newtable = pandas.concat([mydf,newrow]) # concatenate the row to bottom of df - note the syntax newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z new A 33 46 69 49 NA B 65 66 90 24 NA C 91 63 19 69 NA D 83 24 96 95 NA E 75 23 71 74 NA X 75 23 71 74 NA","title":"Appending new rows"},{"location":"lesson8/#removing-rows-and-columns","text":"To remove a column is straightforward, we use the drop method newtable.drop('new', axis=1, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 C 91 63 19 69 D 83 24 96 95 E 75 23 71 74 X 75 23 71 74 To remove a row, you really got to want to, easiest is probablty to create a new dataframe with the row removed newtable = newtable.loc[['A','B','D','E','X']] # select all rows except C newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 D 83 24 96 95 E 75 23 71 74 X 75 23 71 74 # or just use drop with axis specify newtable.drop('X', axis=0, inplace = True) newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 D 83 24 96 95 E 75 23 71 74","title":"Removing Rows and Columns"},{"location":"lesson8/#indexing","text":"We have already been indexing, but a few examples follow: newtable['X'] #Selecing a single column A 46 B 66 D 24 E 23 Name: X, dtype: int64 newtable[['X','W']] #Selecing a multiple columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X W A 46 33 B 66 65 D 24 83 E 23 75 newtable.loc['E'] #Selecing rows based on label via loc[ ] indexer W 75 X 23 Y 71 Z 74 Name: E, dtype: int64 newtable .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z A 33 46 69 49 B 65 66 90 24 D 83 24 96 95 E 75 23 71 74 newtable.loc[['E','D','B']] #Selecing multiple rows based on label via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } W X Y Z E 75 23 71 74 D 83 24 96 95 B 65 66 90 24 newtable.loc[['B','E','D'],['X','Y']] #Selecting elements via both rows and columns via loc[ ] indexer .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } X Y B 66 90 E 23 71 D 24 96","title":"Indexing"},{"location":"lesson8/#conditional-selection","text":"mydf = pandas.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach #What fruit corresponds to the number 555 in \u2018col2\u2019? mydf[mydf['col2']==555]['col3'] 1 apple Name: col3, dtype: object #What fruit corresponds to the minimum number in \u2018col2\u2019? mydf[mydf['col2']==mydf['col2'].min()]['col3'] 5 watermelon Name: col3, dtype: object","title":"Conditional Selection"},{"location":"lesson8/#descriptor-functions","text":"#Creating a dataframe from a dictionary mydf = pandas.DataFrame({'col1':[1,2,3,4,5,6,7,8], 'col2':[444,555,666,444,666,111,222,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) mydf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach","title":"Descriptor Functions"},{"location":"lesson8/#head-method","text":"Returns the first few rows, useful to infer structure #Returns only the first five rows mydf.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit","title":"head method"},{"location":"lesson8/#info-method","text":"Returns the data model (data column count, names, data types) #Info about the dataframe mydf.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 8 entries, 0 to 7 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 col1 8 non-null int64 1 col2 8 non-null int64 2 col3 8 non-null object dtypes: int64(2), object(1) memory usage: 320.0+ bytes","title":"info method"},{"location":"lesson8/#describe-method","text":"Returns summary statistics of each numeric column. Also returns the minimum and maximum value in each column, and the IQR (Interquartile Range). Again useful to understand structure of the columns. #Statistics of the dataframe mydf.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 count 8.00000 8.0000 mean 4.50000 416.2500 std 2.44949 211.8576 min 1.00000 111.0000 25% 2.75000 222.0000 50% 4.50000 444.0000 75% 6.25000 582.7500 max 8.00000 666.0000","title":"describe method"},{"location":"lesson8/#counting-and-sum-methods","text":"There are also methods for counts and sums by specific columns mydf['col2'].sum() #Sum of a specified column 3330 The unique method returns a list of unique values (filters out duplicates in the list, underlying dataframe is preserved) mydf['col2'].unique() #Returns the list of unique values along the indexed column array([444, 555, 666, 111, 222]) The nunique method returns a count of unique values mydf['col2'].nunique() #Returns the total number of unique values along the indexed column 5 The value_counts() method returns the count of each unique value (kind of like a histogram, but each value is the bin) mydf['col2'].value_counts() #Returns the number of occurences of each unique value 666 2 444 2 222 2 555 1 111 1 Name: col2, dtype: int64","title":"Counting and Sum methods"},{"location":"lesson8/#using-functions-in-dataframes-symbolic-apply","text":"The power of Pandas is an ability to apply a function to each element of a dataframe series (or a whole frame) by a technique called symbolic (or synthetic programming) application of the function. This employs principles of pattern matching , abstraction , and algorithm development ; a holy trinity of Computational Thinning. It's somewhat complicated but quite handy, best shown by an example: def times2(x): # A prototype function to scalar multiply an object x by 2 return(x*2) print(mydf) print('Apply the times2 function to col2') mydf['col2'].apply(times2) #Symbolic apply the function to each element of column col2, result is another dataframe col1 col2 col3 0 1 444 orange 1 2 555 apple 2 3 666 grape 3 4 444 mango 4 5 666 jackfruit 5 6 111 watermelon 6 7 222 banana 7 8 222 peach Apply the times2 function to col2 0 888 1 1110 2 1332 3 888 4 1332 5 222 6 444 7 444 Name: col2, dtype: int64","title":"Using functions in dataframes - symbolic apply"},{"location":"lesson8/#sorting","text":"mydf.sort_values('col2', ascending = True) #Sorting based on columns .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 5 6 111 watermelon 6 7 222 banana 7 8 222 peach 0 1 444 orange 3 4 444 mango 1 2 555 apple 2 3 666 grape 4 5 666 jackfruit mydf.sort_values('col3', ascending = True) #Lexiographic sort .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 1 2 555 apple 6 7 222 banana 2 3 666 grape 4 5 666 jackfruit 3 4 444 mango 0 1 444 orange 7 8 222 peach 5 6 111 watermelon","title":"Sorting"},{"location":"lesson8/#aggregating-grouping-values-dataframe-contents","text":"#Creating a dataframe from a dictionary data = { 'key' : ['A', 'B', 'C', 'A', 'B', 'C'], 'data1' : [1, 2, 3, 4, 5, 6], 'data2' : [10, 11, 12, 13, 14, 15], 'data3' : [20, 21, 22, 13, 24, 25] } mydf1 = pandas.DataFrame(data) mydf1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 data3 0 A 1 10 20 1 B 2 11 21 2 C 3 12 22 3 A 4 13 13 4 B 5 14 24 5 C 6 15 25 # Grouping and summing values in all the columns based on the column 'key' mydf1.groupby('key').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 data3 key A 5 23 33 B 7 25 45 C 9 27 47 # Grouping and summing values in the selected columns based on the column 'key' mydf1.groupby('key')[['data1', 'data2']].sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key A 5 23 B 7 25 C 9 27","title":"Aggregating (Grouping Values) dataframe contents"},{"location":"lesson8/#filtering-out-missing-values","text":"Filtering and cleaning are often used to describe the process where data that does not support a narrative is removed ;typically for maintenance of profit applications, if the data are actually missing that is common situation where cleaning is justified. #Creating a dataframe from a dictionary df = pandas.DataFrame({'col1':[1,2,3,4,None,6,7,None], 'col2':[444,555,None,444,666,111,None,222], 'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 NaN grape 3 4.0 444.0 mango 4 NaN 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 NaN banana 7 NaN 222.0 peach Below we drop any row that contains a NaN code. df_dropped = df.dropna() df_dropped .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 3 4.0 444.0 mango 5 6.0 111.0 watermelon Below we replace NaN codes with some value, in this case 0 df_filled1 = df.fillna(0) df_filled1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.0 444.0 orange 1 2.0 555.0 apple 2 3.0 0.0 grape 3 4.0 444.0 mango 4 0.0 666.0 jackfruit 5 6.0 111.0 watermelon 6 7.0 0.0 banana 7 0.0 222.0 peach Below we replace NaN codes with some value, in this case the mean value of of the column in which the missing value code resides. df_filled2 = df.fillna(df.mean()) df_filled2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } col1 col2 col3 0 1.000000 444.0 orange 1 2.000000 555.0 apple 2 3.000000 407.0 grape 3 4.000000 444.0 mango 4 3.833333 666.0 jackfruit 5 6.000000 111.0 watermelon 6 7.000000 407.0 banana 7 3.833333 222.0 peach","title":"Filtering out missing values"},{"location":"lesson8/#reading-a-file-into-a-dataframe","text":"Pandas has methods to read common file types, such as csv , xlsx , and json . Ordinary text files are also quite manageable. On a machine you control you can write script to retrieve files from the internet and process them. readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') #Reading a .csv file print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 Similar to reading and writing .csv files, you can also read and write .xslx files as below (useful to know this) readfileexcel = pandas.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1') #Reading a .xlsx file print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15","title":"Reading a File into a Dataframe"},{"location":"lesson8/#writing-a-dataframe-to-file","text":"#Creating and writing to a .csv file readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile1.csv') readfilecsv = pandas.read_csv('CSV_WritingFile1.csv') print(readfilecsv) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15 #Creating and writing to a .csv file by excluding row labels readfilecsv = pandas.read_csv('CSV_ReadingFile.csv') readfilecsv.to_csv('CSV_WritingFile2.csv', index = False) readfilecsv = pandas.read_csv('CSV_WritingFile2.csv') print(readfilecsv) a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 #Creating and writing to a .xlsx file readfileexcel = pandas.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1') readfileexcel.to_excel('Excel_WritingFile.xlsx', sheet_name='MySheet', index = False) readfileexcel = pandas.read_excel('Excel_WritingFile.xlsx', sheet_name='MySheet') print(readfileexcel) Unnamed: 0 a b c d 0 0 0 1 2 3 1 1 4 5 6 7 2 2 8 9 10 11 3 3 12 13 14 15","title":"Writing a dataframe to file"},{"location":"lesson8/#downloading-files-from-websites-optional","text":"This section shows how to get files from a remote computer. There are several ways to get the files, most importantly you need the FQDN to the file.","title":"Downloading files from websites (optional)"},{"location":"lesson8/#method-1-get-data-from-a-file-on-a-remote-server-unencrypted","text":"This section shows how to obtain data files from public URLs. Prerequesites: You know the FQDN to the file it will be in structure of \"http://server-name/.../filename.ext\" The server is running ordinary (unencrypted) web services, i.e. http://...","title":"Method 1: Get data from a file on a remote server (unencrypted)"},{"location":"lesson8/#web-developer-notes","text":"If you want to distribute files (web developers) the files need to be in the server webroot, but can be deep into the heirarchial structure. Here we will do an example with a file that contains topographic data in XYZ format, without header information. The first few lines of the remote file look like: 74.90959724 93.21251922 0 75.17907367 64.40278759 0 94.9935575 93.07951286 0 95.26234119 64.60091165 0 54.04976655 64.21159095 0 54.52914363 35.06934342 0 75.44993558 34.93079513 0 75.09317373 5.462959114 0 74.87357468 10.43130083 0 74.86249082 15.72938748 0 And importantly it is tab delimited. The module to manipulate url in python is called urllib Google search to learn more, here we are using only a small component without exception trapping. #Step 1: import needed modules to interact with the internet from urllib.request import urlopen # import a method that will connect to a url and read file contents import pandas #import pandas This next code fragment sets a string called remote_url ; it is just a variable, name can be anything that honors python naming rules. Then the urllib function urlopen with read and decode methods is employed, the result is stored in an object named elevationXYZ #Step 2: make the connection to the remote file (actually its implementing \"bash curl -O http://fqdn/path ...\") remote_url = 'http://www.rtfmps.com/share_files/pip-corner-sumps.txt' # elevationXYZ = urlopen(remote_url).read().decode().split() # Gets the file contents as a single vector, comma delimited, file is not retained locally At this point the object exists as a single vector with hundreds of elements. We now need to structure the content. Here using python primatives, and knowing how the data are supposed to look, we prepare variables to recieve the structured results #Step 3 Python primatives to structure the data, or use fancy modules (probably easy in numpy) howmany = len(elevationXYZ) # how long is the vector? nrow = int(howmany/3) xyz = [[0 for j in range(3)] for j in range(nrow)] # null space to receive data define columnX Now that everything is ready, we can extract from the object the values we want into xyz #Step4 Now will build xyz as a matrix with 3 columns index = 0 for irow in range(0,nrow): xyz[irow][0]=float(elevationXYZ[index]) xyz[irow][1]=float(elevationXYZ[index+1]) xyz[irow][2]=float(elevationXYZ[index+2]) index += 3 #increment the index xyz is now a 3-column float array and can now probably be treated as a data frame. Here we use a pandas method to build the dataframe. df = pandas.DataFrame(xyz) Get some info, yep three columns (ordered triples to be precise!) df.info() <class 'pandas.core.frame.DataFrame'> RangeIndex: 774 entries, 0 to 773 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 0 774 non-null float64 1 1 774 non-null float64 2 2 774 non-null float64 dtypes: float64(3) memory usage: 18.3 KB And some summary statistics (meaningless for these data), but now have taken data from the internet and prepared it for analysis. df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 count 774.000000 774.000000 774.000000 mean 52.064621 48.770060 2.364341 std 30.883400 32.886277 1.497413 min -2.113554 -11.360960 0.000000 25% 25.640786 21.809579 2.000000 50% 55.795821 49.059950 2.000000 75% 76.752290 75.015933 4.000000 max 111.726727 115.123931 4.000000 And lets look at the first few rows df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 74.909597 93.212519 0.0 1 75.179074 64.402788 0.0 2 94.993557 93.079513 0.0 3 95.262341 64.600912 0.0 4 54.049767 64.211591 0.0","title":"Web Developer Notes"},{"location":"lesson8/#method-2-get-the-actual-file-from-a-remote-web-server-unencrypted","text":"You know the FQDN to the file it will be in structure of \"http://server-name/.../filename.ext\" The server is running ordinary (unencrypted) web services, i.e. http://... We will need a module to interface with the remote server, in this example lets use something different than urllib . Here we will use requests , so first we load the module import requests # Module to process http/https requests Now we will generate a GET request to the remote http server. I chose to do so using a variable to store the remote URL so I can reuse code in future projects. The GET request (an http/https method) is generated with the requests method get and assigned to an object named rget -- the name is arbitrary. Next we extract the file from the rget object and write it to a local file with the name of the remote file - esentially automating the download process. Then we import the pandas module. remote_url=\"http://54.243.252.9/engr-1330-psuedo-course/MyJupyterNotebooks/42-DataScience-EvaporationAnalysis/all_quads_gross_evaporation.csv\" # set the url rget = requests.get(remote_url, allow_redirects=True) # get the remote resource, follow imbedded links open('all_quads_gross_evaporation.csv','wb').write(rget.content) # extract from the remote the contents, assign to a local file same name import pandas as pd # Module to process dataframes (not absolutely needed but somewhat easier than using primatives, and gives graphing tools) # verify file exists ! pwd ! ls -la /home/compthink/engr-1330-webroot/1-Lessons/Lesson08/OriginalPowerpoint total 1268 drwxrwxr-x 4 compthink compthink 4096 Feb 15 01:30 . drwxrwxr-x 5 compthink compthink 4096 Feb 10 02:50 .. drwxrwxr-x 2 compthink compthink 4096 Feb 15 01:12 .ipynb_checkpoints -rw-rw-r-- 1 compthink compthink 21150 Feb 14 21:07 01-table-dataframe.png -rw-rw-r-- 1 compthink compthink 51 Feb 14 23:00 CSV_ReadingFile.csv -rw-rw-r-- 1 compthink compthink 55 Feb 14 23:12 CSV_WritingFile1.csv -rw-rw-r-- 1 compthink compthink 46 Feb 14 23:12 CSV_WritingFile2.csv -rw-rw-r-- 1 compthink compthink 693687 Feb 15 01:12 ENGR-1330-Lesson8-Dev.html -rw-rw-r-- 1 compthink compthink 164919 Feb 15 01:30 ENGR-1330-Lesson8-Dev.ipynb -rw-rw-r-- 1 compthink compthink 5508 Feb 14 23:01 Excel_ReadingFile.xlsx -rw-rw-r-- 1 compthink compthink 5042 Feb 14 23:12 Excel_WritingFile.xlsx -rw-rw-r-- 1 compthink compthink 363498 Feb 15 01:30 all_quads_gross_evaporation.csv drwxrwxr-x 3 compthink compthink 4096 Feb 15 01:12 src.old Now we can read the file contents and check its structure, before proceeding. evapdf = pd.read_csv(\"all_quads_gross_evaporation.csv\",parse_dates=[\"YYYY-MM\"]) # Read the file as a .CSV assign to a dataframe evapdf evapdf.head() # check structure .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } YYYY-MM 104 105 106 107 108 204 205 206 207 ... 911 912 1008 1009 1010 1011 1108 1109 1110 1210 0 1954-01-01 1.80 1.80 2.02 2.24 2.24 2.34 1.89 1.80 1.99 ... 1.42 1.30 2.50 2.42 1.94 1.29 2.59 2.49 2.22 2.27 1 1954-02-01 4.27 4.27 4.13 3.98 3.90 4.18 4.26 4.27 4.26 ... 2.59 2.51 4.71 4.30 3.84 2.50 5.07 4.62 4.05 4.18 2 1954-03-01 4.98 4.98 4.62 4.25 4.20 5.01 4.98 4.98 4.68 ... 3.21 3.21 6.21 6.06 5.02 3.21 6.32 6.20 5.68 5.70 3 1954-04-01 6.09 5.94 5.94 6.07 5.27 6.31 5.98 5.89 5.72 ... 3.83 3.54 6.45 6.25 4.92 3.54 6.59 6.44 5.88 5.95 4 1954-05-01 5.41 5.09 5.14 4.40 3.61 5.57 4.56 4.47 4.18 ... 3.48 3.97 7.92 8.13 6.31 3.99 7.75 7.98 7.40 7.40 5 rows \u00d7 93 columns Structure looks like a spreadsheet as expected; lets plot the time series for cell '911' evapdf.plot.line(x='YYYY-MM',y='911') # Plot quadrant 911 evaporation time series <AxesSubplot:xlabel='YYYY-MM'>","title":"Method 2: Get the actual file from a remote web server (unencrypted)"},{"location":"lesson8/#method-3-get-the-actual-file-from-an-encrypted-server","text":"This section is saved for future semesters","title":"Method 3: Get the actual file from an encrypted server"},{"location":"lesson8/#references","text":"Overland, B. (2018). Python Without Fear. Addison-Wesley ISBN 978-0-13-468747-6. Grus, Joel (2015). Data Science from Scratch: First Principles with Python O\u2019Reilly Media. Kindle Edition. Precord, C. (2010) wxPython 2.8 Application Development Cookbook Packt Publishing Ltd. Birmingham , B27 6PA, UK ISBN 978-1-849511-78-0. # Preamble script block to identify host, user, and kernel import sys ! hostname ! whoami print(sys.executable) print(sys.version) print(sys.version_info) ip-172-26-4-2 compthink /opt/jupyterhub/bin/python3 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)","title":"References"},{"location":"readings/","text":"Normal Reading List citation","title":"Readings"},{"location":"readings/#normal-reading-list","text":"citation","title":"Normal Reading List"},{"location":"syllabus/","text":"ENGR 1330 Computational Thinking with Data Science Course Description: Introducion to Python programming, its relevant modules and libraries, and computational thinking for solving problems in Data Science. Data science approaches for importing, manipulating, and analyzing data. Modeling and visualizing real-world data sets in various science and engineering disciplines. 3 credit hours comprising of lectures and hands-on lab sessions. This course provides a hands-on learning experience in programming and data science using iPython and JupyterLab. iPython is the interactive python kernel implemented in JupyterLab. Prerequisites: Prior programming background is NOT required. The course is intended for first-year WCOE students (aka engineering foundational) COVID-19 Important Guidelines: If Texas Tech University campus operations are required to change because of health concerns related to the COVID-19 pandemic, it is possible that this course will move to a fully online delivery format. Should that be necessary, students will be advised of technical and/or equipment requirements, including remote proctoring software. Policy on absences resulting from illness: We anticipate that some students may have extended absences. To avoid students feeling compelled to attend in-person class periods when having symptoms or feeling unwell, a standard policy is provided that holds students harmless for illness-related absences (see Section A below). A. Illness-Based Absence Policy (Face-to-Face Classes) If at any time during the semester you are ill, in the interest of your own health and safety as well as the health and safety of your instructors and classmates, you are encouraged not to attend face-to-face class meetings or events. Please review the steps outlined below that you should follow to ensure your absence for illness will be excused. These steps also apply to not participating in synchronous online class meetings if you feel too ill to do so and missing specified assignment due dates in asynchronous online classes because of illness. If you are ill and think the symptoms might be COVID-19-related: Call Student Health Services at 806.743.2848 or your health care provider. During after-hours and on weekends, contact TTU COVID-19 Helpline at TBD. Self-report as soon as possible using the Dean of Students COVID-19 webpage. This website has specific directions about how to upload documentation from a medical provider and what will happen if your illness renders you unable to participate in classes for more than one week. If your illness is determined to be COVID-19-related, all remaining documentation and communication will be handled through the Office of the Dean of Students, including notification of your instructors of the time you may be absent from and may return to classes. If your illness is determined not to be COVID-19-related, please follow steps 2.a-d below. If you are ill and can attribute your symptoms to something other than COVID-19: If your illness renders you unable to attend face-to-face classes, participate in synchronous online classes, or miss specified assignment due dates in asynchronous online classes, you are encouraged to contact either Student Health Services at 806.743.2848 or your health care provider. Note that Student Health Services and your own and other health care providers may arrange virtual visits. During the health provider visit, request a \u201creturn to school\u201d note. E-mail the instructor a picture of that note. Return to class by the next class period after the date indicated on your note. Following the steps outlined above helps to keep your instructors informed about your absences and ensures your absence or missing an assignment due date because of illness will be marked excused. You will still be responsible to complete within a week of returning to class any assignments, quizzes, or exams you miss because of illness. B. Illness-Based Absence Policy (Telepresence/On-Line Classes) Same as above with respect potential to infect others; go to a health care provider if you are ill. Telepresence courses are recorded and will be available on TTU MediaSite and/or YouTube (unlisted). Exercises, Quizzes, and Examinations are all administered by a Learning Management System (Blackboard) and students need to allow enough time to complete and upload their work. Due date adjustments/late submits on case-by-case basis; documentation required as in subsection A above. Course Sections Lesson time, days, and location: Section D04; CRN 64436; 1000-1120 T, TH ; Telepresence Lab Section D66; CRN 64441; 1130-1250 T, TH Section D01; CRN 63306; 1000-1120 T, TH ; Telepresence Lab Section D61; CRN 63744; 1130-1250 T, TH Course Instructor: Instructor: Theodore G. Cleveland, Ph.D., P.E., M. ASCE, F. EWRI Email: theodore.cleveland@ttu.edu (put ENGR 1330 in subject line for email related to this class) Office location: Telepresence ( Zoom ) Office hours: 1000-1100 M, 1600-1700 W or by appointment (meetings will be by Zoom call) Teaching Assistant: Teaching Assistant: Farhang Forghanparast, MSCE Email : Farhang.Forghanparast@ttu.edu Office location: Telepresence ( Zoom ) Office hours: 0900-1000 M; 1700-1800 W Textbook: Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0). Link: https://www.inferentialthinking.com/chapters/intro Course Contents: Computational thinking for problem-solving: Logical problem solving, decomposition, pattern recognition, abstraction, representation, algorithm design, and generalization. Python Programming: Variables, constants, data types, data structures, strings, math operators boolean operators, expressions, program constructs, functions, looping, I/O files, modules, and database. Data science fundamentals: Experimental setup: Importing and formatting data sets, Displaying data, Data pre-processing. Introductory statistical analysis with Python: Elementary statistics, randomness, sampling, probability distributions, Confidence intervals, hypothesis testing, and A/B testing. Basic data analysis, visualization, and machine learning: Data pre-processing, Supervised/unsupervised learning, Performance evaluation metrics. Learning Outcomes: On completion of the course, students will have * Created Python programs employing computational thinking concepts to * Employed Python libraries relevant to data science. * Downloaded data files from selected public sources and analyzed content. * Created scripts to perform fundamental data analytics and basic visualization. ABET Student Outcomes Engineering: An ability to identify, formulate, and solve complex engineering problems by applying principles of engineering, science, and mathematics. An ability to acquire and apply new knowledge as needed, using appropriate learning strategies. Computer Science: Analyze a complex computing problem and to apply principles of computing and other relevant disciplines to identify solutions. Design, implement, and evaluate a computing-based solution to meet a given set of computing requirements in the context of the program\u2019s discipline. Resources/Tools Platforms for Python Programming (for your own computers) Anaconda platform https://www.anaconda.com/ : Anaconda distribution is an open-source Data Science Distribution Development Platform. It includes Python 3 with over 1,500 data science packages making it easy to manage libraries and dependencies. Available in Linux, Windows, and Mac OS X. Jupyter https://jupyter.org/ : JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data. JupyterLab is flexible: Configure and arrange the user interface to support a wide range of workflows in data science, scientific computing, and machine learning. note Anaconda for MacOS includes a JupyterLab instance, so a separate install is not required. Additional Modules for Python Programming Math module https://docs.python.org/3/library/math.html : Gives access to the mathematical functions defined by the C standard e.g. factorial, gcd, exponential, logarithm. Operator module https://docs.python.org/3/library/operator.html : Helps in exporting a set of efficient functions corresponding to the intrinsic operators of Python. For example, the operator add(x,y) is equivalent to the expression x+y. Python Modules for Data Science Scipy module https://www.scipy.org/ : A Python-based ecosystem of open-source software for mathematics, science, and engineering. Some of the core packages are: Numpy: Provides n-dimensional array package Scipy: Fundamental for scientific computing (e.g. linear algorithm, optimization) Matplotlib: Visualizations/2D plotting IPython: Enhanced interactive console <<= this is the kernel used in JupyterLab Pandas: Data structures and data analysis Scikit-learn module https://scikit-learn.org/stable/ : A library for machine learning in Python. It is a simple and efficient tool for predictive data analysis. It is built on NumPy, SciPy, and matplotlib modules. On-Line Options AWS Lightsail Instance (use Windows Server 2000 template; lowest resource provision tier; AWS RDP client, or download and install own RDP client) Then install Anaconda onto the AWS Instance Hardware Requirements Minimal, in fact this syllabus was created using a JupyterLab notebook (as a markdown processor) on a Raspberry Pi 4B, which technically cannot support a JupyterHub, but does. Your current laptop should be fine, or if you only have a chromebook, build an AWS instance. The college of engineering has specific laptop requirements for your other courses that are listed at https://www.depts.ttu.edu/coe/dean/engineeringitservices/buyingtherightcomputer.php Content Server Blackboard is used as the learning management system (LMS) for this class, and it uses web links to a content server at https://3.137.111.182/engr-1330-webroot/ The Blackboard links will generally go directly to a section in the webroot, but feel free to explore by going in the front door! Course Schedule Item Lesson Lab JupyterLab(Python Kernel) and Programming 21Jan2021 Lesson 0 Introduction to Computational Thinking with Data Science: - Computational thinking concepts - Python as a programming environment - Data science and practices - CCMR Approach Computing Environment set up: - Installing Anaconda (Win/MacOS/AWS) \u2013 Jupyter notebooks - Simple Examples 26Jan2021 Lesson 1 Programming Fundamentals: - Data types (int, float, string, bool) - Variables, operators, expressions, basic I/O - String functions and operations Introduction to Python - Data types (e.g. int, float, string, bool) - Expressions 28Jan2021 Lesson 2 Programming Fundamentals: - Data structures: Array, list, tuple, set, dictionary - Conditional statements Introduction to Python - Data structures - Conditional statements 2Feb2021 Lesson 3 Programming Fundamentals: - Loops - Flowcharts Introduction to Python - Loops 4Feb2021 Lesson 4 Programming Fundamentals: - Functions - Variable scope Introduction to Python - Functions - Variable scope 9Feb2021 Lesson 5 Programming Fundamentals: - Class and objects - File handling Introduction to Python - Class and objects - File handling Data Science External Modules 11Feb2021 Lesson 6 Data Representation and Operations: Python library: NumPy - Data representation: Arrays, vectors, matrices - Data operations: Indexing, math functions Exercises on NumPy 16Feb2021 Lesson 7 Data Query and Manipulation: Python Library: Pandas - Data frames: - Create, index, summarize statistics - fill and drop values - read/write to file Exercises on Pandas 18Feb2021 Lesson 8 Data Display: Python Libraries: Matplotlib - Graphing Conventions - Data Display for line charts, bar charts, box plot, scatter plot, and histograms Exercises on data display 23Feb2021 Lesson 9 Data Modeling: - Establishing causality - Randomness - Models as Preciction Machines Exercises on causality and simulation 25Feb2021 Review for Exam-1 (Lessons 0-9) Exam-1 - LMS administered Data Modeling: Statistical Approaches 2Mar2021 Lesson 10 Randomness and Probabilities: - Sampling - Empirical distributions Exercises on probabilities 4Mar2021 Lesson 11 Descriptive Statistics - Location/Center (mean, median,mode) - Dispersion/Spread (variance, standard deviation) - Asymmetry/Skew (Coefficient of Skewness) Descriptive Statistics 9Mar2021 Lesson 12 Distributions: - Normal, LogNormal - Gamma, Weibull - Extreme Value (Gumbell) Exercises on sampling 11Mar2021 Lesson 13 Probability Estimation Modeling - Ranking, order, plotting position - Distribution Fitting ; Method Of Moments; Maximum Likelihood Estimation Exercises 16Mar2021 Lesson 14 Hypothesis testing: - General concept - Assessing data models. Exercises on hypothesis testing 18Mar2021 Lesson 15 Hypothesis testing: -Comparing proportions - Type1 & Type2 errors - Attained significance (p-value) Exercises on hypothesis testing 23Mar2021 Lesson 16 Comparing two samples: A/B Testing Exercises on A/B testing 25Mar2021 Review for Exam-2 (Lessons 10-16) Exam-2 - LMS administered 30Mar2021 17. Confidence intervals Exercises Data Modeling: Regression (Model Fitting) Approaches 1Apr2021 18. Data Modeling: Regression Approach - Linear algebra of equation fitting Exercises 6Apr2021 19. Estimation Modeling by Regression: - Ordinary least squares (OLS) regression - Weighted least squares - Explanitory variables (features) - Response variable(s) exre 8Apr2021 20. Estimation Modeling by Regression: - Residuals - Performance metrics: Accuracy, error - Inference exercises 13Apr2021 21. Estimation Modeling by Regression: - Logistic Regression (a type of classification) Exercises on sample means Data Modeling: Machine Learning Approaches 15Apr2021 22. Data Modeling : The Machine Learning Approach: - Correlation - Training (a model fitting analog) - Confusion matrix, precision, recall, accuracy, F-score. - Making decisions Final projects selection - Project choices - Delivery schedule 20Apr2021 Lesson 23 Evaluation and Making Decisions: - Confusion matrix, precision, recall, accuracy, F-score. - Making decisions KNN with evaluation 22Apr2021 Lesson 24 Classification: - K Nearest Neighbor (KNN) More KNN Demonstration/Examples 27Apr2021 Review for Exam-3 (Lessons 17-24) Exam 3 - LMS administered 29Apr2021 Lesson 25 Classification: - Support Vector Machines (SVM) SVM Demonstration/Examples 4May2021 Lesson 26 Classification: - Artifical Neural Networks (ANN) ANN Demonstration 11May2021 Final Project Report and Link to Video Course Assessment and Grading Criteria: There will be three exams and one comprehensive final project for this course. An AI-supervised online community using the Packback Questions https://www.packback.co platform will be used for online discussion about class topics. The platform is the place to pose questions and answers and share codes and problems. Face-to-face sections do not use packback, and use a different scoring distribution In addition, lab notebooks, quizzes, and homework assignments also contribute to the final grade. Late assignments will not be scored. Grades will be based on the following components; weighting is approximate: Assessment Instrument Weight(%) Exam-1 10 Exam-2 10 Exam-3 15 Lab Notebooks & Homework 30 Quizzes 10 Packback 15 Final project 10 Overall total 100 Letter grades will be assigned using the following proportions: Normalized Score Range Letter Grade \u2265 90 A 80-89 B 70-79 C 55-69 D < 55 F Packback Questions Environment Participation is a requirement for this course, and the Packback Questions platform will be used for online discussion about class topics. Packback Questions is an online community where you can be fearlessly curious and ask open-ended questions to build on top of what we are covering in class and relate topics to real-world applications. Packback Requirements: Your participation on Packback will count toward 15% of your overall course grade. There will be a Weekly Sunday at 10:00PM CST deadline for submissions. In order to receive your points per week, you should submit the following per each deadline period: 1 open-ended Question per week with a minimum Curiosity Score of 30, each worth 33.33% of each assignment grade 2 Responses per week with a minimum Curiosity Score of 30, each worth 66.67% of each assignment grade Half credit will be provided for questions and responses that do not meet the minimum curiosity score. How to Register on Packback: An email invitation will be sent to you from help@packback.co prompting you to finish registration. If you don\u2019t receive an email (be sure to check your spam), you may register by following the instructions below: Create an account by navigating to https://questions.packback.co and clicking \u201cSign up for an Account\u201d Note: If you already have an account on Packback you can log in with your credentials. Then enter our class community\u2019s lookup key into the \u201cLooking to join a community you don't see here?\u201d section in Packback at the bottom of the homepage. Community Lookup Key: 1e3bb85a-ddb2-456a-a8fc-178ead55206d Follow the instructions on your screen to finish your registration. Packback will require a paid subscription (~$25). Refer to www.packback.co/product/pricing for more information. How to Get Help from the Packback Team: If you have any questions or concerns about Packback throughout the semester, please read their FAQ at help.packback.co. If you need more help, contact their customer support team directly at help@packback.co. For a brief introduction to Packback Questions and why we are using it in class, watch this video: vimeo.com/packback/Welcome-to-Packback-Questions Classroom Policy: The following activities are not allowed in the classroom: Texting or talking on the cellphone or other electronic devices, and reading non-course related materials. Telepresence (On-line) Courses Obviously electronic devices are vital; disrupting the conference is prohibited, please mute your microphone unless you have a question - consider typing your question into the chat window as well. Be aware of bandwidth issues and remember most lessons and laboratory sessions are recorded and posted on youtube. Recording, editing, and rendering takes awhile, so expect 24-36 hour delay before video is available. ADA Statement: Any student who, because of a disability, may require special arrangements in order to meet the course requirements should contact the instructor as soon as possible to make necessary arrangements. Students must present appropriate verification from Student Disability Services during the instructor's office hours. Please note that instructors are not allowed to provide classroom accommodation to a student until appropriate verification from Student Disability Services has been provided. For additional information, please contact Student Disability Services office in 335 West Hall or call 806.742.2405. Academic Integrity Statement: Academic integrity is taking responsibility for one\u2019s own class and/or course work, being individually accountable, and demonstrating intellectual honesty and ethical behavior. Academic integrity is a personal choice to abide by the standards of intellectual honesty and responsibility. Because education is a shared effort to achieve learning through the exchange of ideas, students, faculty, and staff have the collective responsibility to build mutual trust and respect. Ethical behavior and independent thought are essential for the highest level of academic achievement, which then must be measured. Academic achievement includes scholarship, teaching, and learning, all of which are shared endeavors. Grades are a device used to quantify the successful accumulation of knowledge through learning. Adhering to the standards of academic integrity ensures grades are earned honestly. Academic integrity is the foundation upon which students, faculty, and staff build their educational and professional careers. [Texas Tech University (\u201cUniversity\u201d) Quality Enhancement Plan, Academic Integrity Task Force, 2010]. Religious Holy Day Statement: \u201cReligious holy day\u201d means a holy day observed by a religion whose places of worship are exempt from property taxation under Texas Tax Code \u00a711.20. A student who intends to observe a religious holy day should make that intention known to the instructor prior to the absence. A student who is absent from classes for the observance of a religious holy day shall be allowed to take an examination or complete an assignment scheduled for that day within a reasonable time after the absence. A student who is excused may not be penalized for the absence; however, the instructor may respond appropriately if the student fails to complete the assignment satisfactorily. Ethical Conduct Policy: Cheating is prohibited, and the representation of the work of another person as your own will be grounds for receiving a failing grade in the course. DISCRIMINATION, HARASSMENT, AND SEXUAL VIOLENCE STATEMENT: Texas Tech University is committed to providing and strengthening an educational, working, and living environment where students, faculty, staff, and visitors are free from gender and/or sex discrimination of any kind. Sexual assault, discrimination, harassment, and other Title IX violations are not tolerated by the University. Report any incidents to the Office for Student Rights & Resolution, (806)-742-SAFE (7233) or file a report online at titleix.ttu.edu/students. Faculty and staff members at TTU are committed to connecting you to resources on campus. Some of these available resources are: TTU Student Counseling Center, 806- 742-3674, https://www.depts.ttu.edu/scc/(Provides confidential support on campus.) TTU 24-hour Crisis Helpline, 806-742-5555, (Assists students who are experiencing a mental health or interpersonal violence crisis. If you call the helpline, you will speak with a mental health counselor.) Voice of Hope Lubbock Rape Crisis Center, 806-763-7273, voiceofhopelubbock.org (24-hour hotline that provides support for survivors of sexual violence.) The Risk, Intervention, Safety and Education (RISE) Office, 806-742-2110, https://www.depts.ttu.edu/rise/ (Provides a range of resources and support options focused on prevention education and student wellness.) Texas Tech Police Department, 806-742- 3931,http://www.depts.ttu.edu/ttpd/ (To report criminal activity that occurs on or near Texas Tech campus.) CIVILITY IN THE CLASSROOM STATEMENT: Texas Tech University is a community of faculty, students, and staff that enjoys an expectation of cooperation, professionalism, and civility during the conduct of all forms of university business, including the conduct of student\u2013student and student\u2013faculty interactions in and out of the classroom. Further, the classroom is a setting in which an exchange of ideas and creative thinking should be encouraged and where intellectual growth and development are fostered. Students who disrupt this classroom mission by rude, sarcastic, threatening, abusive or obscene language and/or behavior will be subject to appropriate sanctions according to university policy. Likewise, faculty members are expected to maintain the highest standards of professionalism in all interactions with all constituents of the university. To ensure that you are fully engaged in class discussions and account team meetings during class time, you are expected to do the following: - Maintain the same level of civility and professionalism that would be expected in a face-to-face classroom setting. - Attend all classes regularly. - Log into the video conference on time and remain logged in for the duration of the class period. - Activate your camera so that you are visible to the instructor and other students in the class. If you have concerns about leaving your camera on (such as childcare obligations, privacy issues, or a particular circumstance during a class period), please talk to the instructor. - Refrain from engaging in non-class related activities during class time that create a distraction for other students in the class and/or limit your ability to engage in the course. Failure to meet these expectations may result in the following consequences: 1. Being counted as absent for the class meeting. 2. Not receiving credit for class participation for that class period. 3. Other consequences as stipulated in the syllabus, Texas Tech Code of Student Conduct, or other university policy. Repeated failure to meet expectations (e.g., attendance, participation in class, etc.), in addition to the above consequences, may result in the one or more of the following consequences: 1. Referral to the appropriate Associate Dean. 2. Academic penalty, ranging from a warning to failure of the course. (www.depts.ttu.edu/ethics/matadorchallenge/ethicalprinciples.php). LGBTQIA SUPPORT STATEMENT: I identify as an ally to the lesbian, gay, bisexual, transgender, queer, intersex, and asexual (LGBTQIA) community, and I am available to listen and support you in an affirming manner. I can assist in connecting you with resources on campus to address problems you may face pertaining to sexual orientation and/or gender identity that could interfere with your success at Texas Tech. Please note that additional resources are available through the Office of LGBTQIA within the Center for Campus Life, Student Union Building Room 201, www.lgbtqia.ttu.edu, 806.742.5433.\u201d Office of LGBTQIA, Student Union Building Room 201, www.lgbtqia.ttu.edu, 806.742.5433 Within the Center for Campus Life, the Office serves the Texas Tech community through facilitation and leadership of programming and advocacy efforts. This work is aimed at strengthening the lesbian, gay, bisexual, transgender, queer, intersex, and asexual (LGBTQIA) community and sustaining an inclusive campus that welcomes people of all sexual orientations, gender identities, and gender expressions.","title":"Syllabus"},{"location":"syllabus/#engr-1330-computational-thinking-with-data-science","text":"","title":"ENGR 1330 Computational Thinking with Data Science"},{"location":"syllabus/#course-description","text":"Introducion to Python programming, its relevant modules and libraries, and computational thinking for solving problems in Data Science. Data science approaches for importing, manipulating, and analyzing data. Modeling and visualizing real-world data sets in various science and engineering disciplines. 3 credit hours comprising of lectures and hands-on lab sessions. This course provides a hands-on learning experience in programming and data science using iPython and JupyterLab. iPython is the interactive python kernel implemented in JupyterLab.","title":"Course Description:"},{"location":"syllabus/#prerequisites","text":"Prior programming background is NOT required. The course is intended for first-year WCOE students (aka engineering foundational)","title":"Prerequisites:"},{"location":"syllabus/#covid-19-important-guidelines","text":"If Texas Tech University campus operations are required to change because of health concerns related to the COVID-19 pandemic, it is possible that this course will move to a fully online delivery format. Should that be necessary, students will be advised of technical and/or equipment requirements, including remote proctoring software. Policy on absences resulting from illness: We anticipate that some students may have extended absences. To avoid students feeling compelled to attend in-person class periods when having symptoms or feeling unwell, a standard policy is provided that holds students harmless for illness-related absences (see Section A below).","title":"COVID-19 Important Guidelines:"},{"location":"syllabus/#a-illness-based-absence-policy-face-to-face-classes","text":"If at any time during the semester you are ill, in the interest of your own health and safety as well as the health and safety of your instructors and classmates, you are encouraged not to attend face-to-face class meetings or events. Please review the steps outlined below that you should follow to ensure your absence for illness will be excused. These steps also apply to not participating in synchronous online class meetings if you feel too ill to do so and missing specified assignment due dates in asynchronous online classes because of illness. If you are ill and think the symptoms might be COVID-19-related: Call Student Health Services at 806.743.2848 or your health care provider. During after-hours and on weekends, contact TTU COVID-19 Helpline at TBD. Self-report as soon as possible using the Dean of Students COVID-19 webpage. This website has specific directions about how to upload documentation from a medical provider and what will happen if your illness renders you unable to participate in classes for more than one week. If your illness is determined to be COVID-19-related, all remaining documentation and communication will be handled through the Office of the Dean of Students, including notification of your instructors of the time you may be absent from and may return to classes. If your illness is determined not to be COVID-19-related, please follow steps 2.a-d below. If you are ill and can attribute your symptoms to something other than COVID-19: If your illness renders you unable to attend face-to-face classes, participate in synchronous online classes, or miss specified assignment due dates in asynchronous online classes, you are encouraged to contact either Student Health Services at 806.743.2848 or your health care provider. Note that Student Health Services and your own and other health care providers may arrange virtual visits. During the health provider visit, request a \u201creturn to school\u201d note. E-mail the instructor a picture of that note. Return to class by the next class period after the date indicated on your note. Following the steps outlined above helps to keep your instructors informed about your absences and ensures your absence or missing an assignment due date because of illness will be marked excused. You will still be responsible to complete within a week of returning to class any assignments, quizzes, or exams you miss because of illness.","title":"A. Illness-Based Absence Policy (Face-to-Face Classes)"},{"location":"syllabus/#b-illness-based-absence-policy-telepresenceon-line-classes","text":"Same as above with respect potential to infect others; go to a health care provider if you are ill. Telepresence courses are recorded and will be available on TTU MediaSite and/or YouTube (unlisted). Exercises, Quizzes, and Examinations are all administered by a Learning Management System (Blackboard) and students need to allow enough time to complete and upload their work. Due date adjustments/late submits on case-by-case basis; documentation required as in subsection A above.","title":"B. Illness-Based Absence Policy (Telepresence/On-Line Classes)"},{"location":"syllabus/#course-sections","text":"Lesson time, days, and location: Section D04; CRN 64436; 1000-1120 T, TH ; Telepresence Lab Section D66; CRN 64441; 1130-1250 T, TH Section D01; CRN 63306; 1000-1120 T, TH ; Telepresence Lab Section D61; CRN 63744; 1130-1250 T, TH","title":"Course Sections"},{"location":"syllabus/#course-instructor","text":"Instructor: Theodore G. Cleveland, Ph.D., P.E., M. ASCE, F. EWRI Email: theodore.cleveland@ttu.edu (put ENGR 1330 in subject line for email related to this class) Office location: Telepresence ( Zoom ) Office hours: 1000-1100 M, 1600-1700 W or by appointment (meetings will be by Zoom call)","title":"Course Instructor:"},{"location":"syllabus/#teaching-assistant","text":"Teaching Assistant: Farhang Forghanparast, MSCE Email : Farhang.Forghanparast@ttu.edu Office location: Telepresence ( Zoom ) Office hours: 0900-1000 M; 1700-1800 W","title":"Teaching Assistant:"},{"location":"syllabus/#textbook","text":"Ani Adhikari and John DeNero, Computational and Inferential Thinking, The Foundations of Data Science, Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0). Link: https://www.inferentialthinking.com/chapters/intro","title":"Textbook:"},{"location":"syllabus/#course-contents","text":"Computational thinking for problem-solving: Logical problem solving, decomposition, pattern recognition, abstraction, representation, algorithm design, and generalization. Python Programming: Variables, constants, data types, data structures, strings, math operators boolean operators, expressions, program constructs, functions, looping, I/O files, modules, and database. Data science fundamentals: Experimental setup: Importing and formatting data sets, Displaying data, Data pre-processing. Introductory statistical analysis with Python: Elementary statistics, randomness, sampling, probability distributions, Confidence intervals, hypothesis testing, and A/B testing. Basic data analysis, visualization, and machine learning: Data pre-processing, Supervised/unsupervised learning, Performance evaluation metrics.","title":"Course Contents:"},{"location":"syllabus/#learning-outcomes","text":"On completion of the course, students will have * Created Python programs employing computational thinking concepts to * Employed Python libraries relevant to data science. * Downloaded data files from selected public sources and analyzed content. * Created scripts to perform fundamental data analytics and basic visualization.","title":"Learning Outcomes:"},{"location":"syllabus/#abet-student-outcomes","text":"Engineering: An ability to identify, formulate, and solve complex engineering problems by applying principles of engineering, science, and mathematics. An ability to acquire and apply new knowledge as needed, using appropriate learning strategies. Computer Science: Analyze a complex computing problem and to apply principles of computing and other relevant disciplines to identify solutions. Design, implement, and evaluate a computing-based solution to meet a given set of computing requirements in the context of the program\u2019s discipline.","title":"ABET Student Outcomes"},{"location":"syllabus/#resourcestools","text":"","title":"Resources/Tools"},{"location":"syllabus/#platforms-for-python-programming-for-your-own-computers","text":"Anaconda platform https://www.anaconda.com/ : Anaconda distribution is an open-source Data Science Distribution Development Platform. It includes Python 3 with over 1,500 data science packages making it easy to manage libraries and dependencies. Available in Linux, Windows, and Mac OS X. Jupyter https://jupyter.org/ : JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data. JupyterLab is flexible: Configure and arrange the user interface to support a wide range of workflows in data science, scientific computing, and machine learning. note Anaconda for MacOS includes a JupyterLab instance, so a separate install is not required.","title":"Platforms for Python Programming (for your own computers)"},{"location":"syllabus/#additional-modules-for-python-programming","text":"Math module https://docs.python.org/3/library/math.html : Gives access to the mathematical functions defined by the C standard e.g. factorial, gcd, exponential, logarithm. Operator module https://docs.python.org/3/library/operator.html : Helps in exporting a set of efficient functions corresponding to the intrinsic operators of Python. For example, the operator add(x,y) is equivalent to the expression x+y.","title":"Additional Modules for Python Programming"},{"location":"syllabus/#python-modules-for-data-science","text":"Scipy module https://www.scipy.org/ : A Python-based ecosystem of open-source software for mathematics, science, and engineering. Some of the core packages are: Numpy: Provides n-dimensional array package Scipy: Fundamental for scientific computing (e.g. linear algorithm, optimization) Matplotlib: Visualizations/2D plotting IPython: Enhanced interactive console <<= this is the kernel used in JupyterLab Pandas: Data structures and data analysis Scikit-learn module https://scikit-learn.org/stable/ : A library for machine learning in Python. It is a simple and efficient tool for predictive data analysis. It is built on NumPy, SciPy, and matplotlib modules.","title":"Python Modules for Data Science"},{"location":"syllabus/#on-line-options","text":"AWS Lightsail Instance (use Windows Server 2000 template; lowest resource provision tier; AWS RDP client, or download and install own RDP client) Then install Anaconda onto the AWS Instance","title":"On-Line Options"},{"location":"syllabus/#hardware-requirements","text":"Minimal, in fact this syllabus was created using a JupyterLab notebook (as a markdown processor) on a Raspberry Pi 4B, which technically cannot support a JupyterHub, but does. Your current laptop should be fine, or if you only have a chromebook, build an AWS instance. The college of engineering has specific laptop requirements for your other courses that are listed at https://www.depts.ttu.edu/coe/dean/engineeringitservices/buyingtherightcomputer.php","title":"Hardware Requirements"},{"location":"syllabus/#content-server","text":"Blackboard is used as the learning management system (LMS) for this class, and it uses web links to a content server at https://3.137.111.182/engr-1330-webroot/ The Blackboard links will generally go directly to a section in the webroot, but feel free to explore by going in the front door!","title":"Content Server"},{"location":"syllabus/#course-schedule","text":"Item Lesson Lab JupyterLab(Python Kernel) and Programming 21Jan2021 Lesson 0 Introduction to Computational Thinking with Data Science: - Computational thinking concepts - Python as a programming environment - Data science and practices - CCMR Approach Computing Environment set up: - Installing Anaconda (Win/MacOS/AWS) \u2013 Jupyter notebooks - Simple Examples 26Jan2021 Lesson 1 Programming Fundamentals: - Data types (int, float, string, bool) - Variables, operators, expressions, basic I/O - String functions and operations Introduction to Python - Data types (e.g. int, float, string, bool) - Expressions 28Jan2021 Lesson 2 Programming Fundamentals: - Data structures: Array, list, tuple, set, dictionary - Conditional statements Introduction to Python - Data structures - Conditional statements 2Feb2021 Lesson 3 Programming Fundamentals: - Loops - Flowcharts Introduction to Python - Loops 4Feb2021 Lesson 4 Programming Fundamentals: - Functions - Variable scope Introduction to Python - Functions - Variable scope 9Feb2021 Lesson 5 Programming Fundamentals: - Class and objects - File handling Introduction to Python - Class and objects - File handling Data Science External Modules 11Feb2021 Lesson 6 Data Representation and Operations: Python library: NumPy - Data representation: Arrays, vectors, matrices - Data operations: Indexing, math functions Exercises on NumPy 16Feb2021 Lesson 7 Data Query and Manipulation: Python Library: Pandas - Data frames: - Create, index, summarize statistics - fill and drop values - read/write to file Exercises on Pandas 18Feb2021 Lesson 8 Data Display: Python Libraries: Matplotlib - Graphing Conventions - Data Display for line charts, bar charts, box plot, scatter plot, and histograms Exercises on data display 23Feb2021 Lesson 9 Data Modeling: - Establishing causality - Randomness - Models as Preciction Machines Exercises on causality and simulation 25Feb2021 Review for Exam-1 (Lessons 0-9) Exam-1 - LMS administered Data Modeling: Statistical Approaches 2Mar2021 Lesson 10 Randomness and Probabilities: - Sampling - Empirical distributions Exercises on probabilities 4Mar2021 Lesson 11 Descriptive Statistics - Location/Center (mean, median,mode) - Dispersion/Spread (variance, standard deviation) - Asymmetry/Skew (Coefficient of Skewness) Descriptive Statistics 9Mar2021 Lesson 12 Distributions: - Normal, LogNormal - Gamma, Weibull - Extreme Value (Gumbell) Exercises on sampling 11Mar2021 Lesson 13 Probability Estimation Modeling - Ranking, order, plotting position - Distribution Fitting ; Method Of Moments; Maximum Likelihood Estimation Exercises 16Mar2021 Lesson 14 Hypothesis testing: - General concept - Assessing data models. Exercises on hypothesis testing 18Mar2021 Lesson 15 Hypothesis testing: -Comparing proportions - Type1 & Type2 errors - Attained significance (p-value) Exercises on hypothesis testing 23Mar2021 Lesson 16 Comparing two samples: A/B Testing Exercises on A/B testing 25Mar2021 Review for Exam-2 (Lessons 10-16) Exam-2 - LMS administered 30Mar2021 17. Confidence intervals Exercises Data Modeling: Regression (Model Fitting) Approaches 1Apr2021 18. Data Modeling: Regression Approach - Linear algebra of equation fitting Exercises 6Apr2021 19. Estimation Modeling by Regression: - Ordinary least squares (OLS) regression - Weighted least squares - Explanitory variables (features) - Response variable(s) exre 8Apr2021 20. Estimation Modeling by Regression: - Residuals - Performance metrics: Accuracy, error - Inference exercises 13Apr2021 21. Estimation Modeling by Regression: - Logistic Regression (a type of classification) Exercises on sample means Data Modeling: Machine Learning Approaches 15Apr2021 22. Data Modeling : The Machine Learning Approach: - Correlation - Training (a model fitting analog) - Confusion matrix, precision, recall, accuracy, F-score. - Making decisions Final projects selection - Project choices - Delivery schedule 20Apr2021 Lesson 23 Evaluation and Making Decisions: - Confusion matrix, precision, recall, accuracy, F-score. - Making decisions KNN with evaluation 22Apr2021 Lesson 24 Classification: - K Nearest Neighbor (KNN) More KNN Demonstration/Examples 27Apr2021 Review for Exam-3 (Lessons 17-24) Exam 3 - LMS administered 29Apr2021 Lesson 25 Classification: - Support Vector Machines (SVM) SVM Demonstration/Examples 4May2021 Lesson 26 Classification: - Artifical Neural Networks (ANN) ANN Demonstration 11May2021 Final Project Report and Link to Video","title":"Course Schedule"},{"location":"syllabus/#course-assessment-and-grading-criteria","text":"There will be three exams and one comprehensive final project for this course. An AI-supervised online community using the Packback Questions https://www.packback.co platform will be used for online discussion about class topics. The platform is the place to pose questions and answers and share codes and problems. Face-to-face sections do not use packback, and use a different scoring distribution In addition, lab notebooks, quizzes, and homework assignments also contribute to the final grade. Late assignments will not be scored. Grades will be based on the following components; weighting is approximate: Assessment Instrument Weight(%) Exam-1 10 Exam-2 10 Exam-3 15 Lab Notebooks & Homework 30 Quizzes 10 Packback 15 Final project 10 Overall total 100 Letter grades will be assigned using the following proportions: Normalized Score Range Letter Grade \u2265 90 A 80-89 B 70-79 C 55-69 D < 55 F","title":"Course Assessment and Grading Criteria:"},{"location":"syllabus/#packback-questions-environment","text":"Participation is a requirement for this course, and the Packback Questions platform will be used for online discussion about class topics. Packback Questions is an online community where you can be fearlessly curious and ask open-ended questions to build on top of what we are covering in class and relate topics to real-world applications.","title":"Packback Questions Environment"},{"location":"syllabus/#packback-requirements","text":"Your participation on Packback will count toward 15% of your overall course grade. There will be a Weekly Sunday at 10:00PM CST deadline for submissions. In order to receive your points per week, you should submit the following per each deadline period: 1 open-ended Question per week with a minimum Curiosity Score of 30, each worth 33.33% of each assignment grade 2 Responses per week with a minimum Curiosity Score of 30, each worth 66.67% of each assignment grade Half credit will be provided for questions and responses that do not meet the minimum curiosity score.","title":"Packback Requirements:"},{"location":"syllabus/#how-to-register-on-packback","text":"An email invitation will be sent to you from help@packback.co prompting you to finish registration. If you don\u2019t receive an email (be sure to check your spam), you may register by following the instructions below: Create an account by navigating to https://questions.packback.co and clicking \u201cSign up for an Account\u201d Note: If you already have an account on Packback you can log in with your credentials. Then enter our class community\u2019s lookup key into the \u201cLooking to join a community you don't see here?\u201d section in Packback at the bottom of the homepage. Community Lookup Key: 1e3bb85a-ddb2-456a-a8fc-178ead55206d Follow the instructions on your screen to finish your registration. Packback will require a paid subscription (~$25). Refer to www.packback.co/product/pricing for more information. How to Get Help from the Packback Team: If you have any questions or concerns about Packback throughout the semester, please read their FAQ at help.packback.co. If you need more help, contact their customer support team directly at help@packback.co. For a brief introduction to Packback Questions and why we are using it in class, watch this video: vimeo.com/packback/Welcome-to-Packback-Questions","title":"How to Register on Packback:"},{"location":"syllabus/#classroom-policy","text":"The following activities are not allowed in the classroom: Texting or talking on the cellphone or other electronic devices, and reading non-course related materials.","title":"Classroom Policy:"},{"location":"syllabus/#telepresence-on-line-courses","text":"Obviously electronic devices are vital; disrupting the conference is prohibited, please mute your microphone unless you have a question - consider typing your question into the chat window as well. Be aware of bandwidth issues and remember most lessons and laboratory sessions are recorded and posted on youtube. Recording, editing, and rendering takes awhile, so expect 24-36 hour delay before video is available.","title":"Telepresence (On-line) Courses"},{"location":"syllabus/#ada-statement","text":"Any student who, because of a disability, may require special arrangements in order to meet the course requirements should contact the instructor as soon as possible to make necessary arrangements. Students must present appropriate verification from Student Disability Services during the instructor's office hours. Please note that instructors are not allowed to provide classroom accommodation to a student until appropriate verification from Student Disability Services has been provided. For additional information, please contact Student Disability Services office in 335 West Hall or call 806.742.2405.","title":"ADA Statement:"},{"location":"syllabus/#academic-integrity-statement","text":"Academic integrity is taking responsibility for one\u2019s own class and/or course work, being individually accountable, and demonstrating intellectual honesty and ethical behavior. Academic integrity is a personal choice to abide by the standards of intellectual honesty and responsibility. Because education is a shared effort to achieve learning through the exchange of ideas, students, faculty, and staff have the collective responsibility to build mutual trust and respect. Ethical behavior and independent thought are essential for the highest level of academic achievement, which then must be measured. Academic achievement includes scholarship, teaching, and learning, all of which are shared endeavors. Grades are a device used to quantify the successful accumulation of knowledge through learning. Adhering to the standards of academic integrity ensures grades are earned honestly. Academic integrity is the foundation upon which students, faculty, and staff build their educational and professional careers. [Texas Tech University (\u201cUniversity\u201d) Quality Enhancement Plan, Academic Integrity Task Force, 2010].","title":"Academic Integrity Statement:"},{"location":"syllabus/#religious-holy-day-statement","text":"\u201cReligious holy day\u201d means a holy day observed by a religion whose places of worship are exempt from property taxation under Texas Tax Code \u00a711.20. A student who intends to observe a religious holy day should make that intention known to the instructor prior to the absence. A student who is absent from classes for the observance of a religious holy day shall be allowed to take an examination or complete an assignment scheduled for that day within a reasonable time after the absence. A student who is excused may not be penalized for the absence; however, the instructor may respond appropriately if the student fails to complete the assignment satisfactorily.","title":"Religious Holy Day Statement:"},{"location":"syllabus/#ethical-conduct-policy","text":"Cheating is prohibited, and the representation of the work of another person as your own will be grounds for receiving a failing grade in the course. DISCRIMINATION, HARASSMENT, AND SEXUAL VIOLENCE STATEMENT: Texas Tech University is committed to providing and strengthening an educational, working, and living environment where students, faculty, staff, and visitors are free from gender and/or sex discrimination of any kind. Sexual assault, discrimination, harassment, and other Title IX violations are not tolerated by the University. Report any incidents to the Office for Student Rights & Resolution, (806)-742-SAFE (7233) or file a report online at titleix.ttu.edu/students. Faculty and staff members at TTU are committed to connecting you to resources on campus. Some of these available resources are: TTU Student Counseling Center, 806- 742-3674, https://www.depts.ttu.edu/scc/(Provides confidential support on campus.) TTU 24-hour Crisis Helpline, 806-742-5555, (Assists students who are experiencing a mental health or interpersonal violence crisis. If you call the helpline, you will speak with a mental health counselor.) Voice of Hope Lubbock Rape Crisis Center, 806-763-7273, voiceofhopelubbock.org (24-hour hotline that provides support for survivors of sexual violence.) The Risk, Intervention, Safety and Education (RISE) Office, 806-742-2110, https://www.depts.ttu.edu/rise/ (Provides a range of resources and support options focused on prevention education and student wellness.) Texas Tech Police Department, 806-742- 3931,http://www.depts.ttu.edu/ttpd/ (To report criminal activity that occurs on or near Texas Tech campus.) CIVILITY IN THE CLASSROOM STATEMENT: Texas Tech University is a community of faculty, students, and staff that enjoys an expectation of cooperation, professionalism, and civility during the conduct of all forms of university business, including the conduct of student\u2013student and student\u2013faculty interactions in and out of the classroom. Further, the classroom is a setting in which an exchange of ideas and creative thinking should be encouraged and where intellectual growth and development are fostered. Students who disrupt this classroom mission by rude, sarcastic, threatening, abusive or obscene language and/or behavior will be subject to appropriate sanctions according to university policy. Likewise, faculty members are expected to maintain the highest standards of professionalism in all interactions with all constituents of the university. To ensure that you are fully engaged in class discussions and account team meetings during class time, you are expected to do the following: - Maintain the same level of civility and professionalism that would be expected in a face-to-face classroom setting. - Attend all classes regularly. - Log into the video conference on time and remain logged in for the duration of the class period. - Activate your camera so that you are visible to the instructor and other students in the class. If you have concerns about leaving your camera on (such as childcare obligations, privacy issues, or a particular circumstance during a class period), please talk to the instructor. - Refrain from engaging in non-class related activities during class time that create a distraction for other students in the class and/or limit your ability to engage in the course. Failure to meet these expectations may result in the following consequences: 1. Being counted as absent for the class meeting. 2. Not receiving credit for class participation for that class period. 3. Other consequences as stipulated in the syllabus, Texas Tech Code of Student Conduct, or other university policy. Repeated failure to meet expectations (e.g., attendance, participation in class, etc.), in addition to the above consequences, may result in the one or more of the following consequences: 1. Referral to the appropriate Associate Dean. 2. Academic penalty, ranging from a warning to failure of the course. (www.depts.ttu.edu/ethics/matadorchallenge/ethicalprinciples.php). LGBTQIA SUPPORT STATEMENT: I identify as an ally to the lesbian, gay, bisexual, transgender, queer, intersex, and asexual (LGBTQIA) community, and I am available to listen and support you in an affirming manner. I can assist in connecting you with resources on campus to address problems you may face pertaining to sexual orientation and/or gender identity that could interfere with your success at Texas Tech. Please note that additional resources are available through the Office of LGBTQIA within the Center for Campus Life, Student Union Building Room 201, www.lgbtqia.ttu.edu, 806.742.5433.\u201d Office of LGBTQIA, Student Union Building Room 201, www.lgbtqia.ttu.edu, 806.742.5433 Within the Center for Campus Life, the Office serves the Texas Tech community through facilitation and leadership of programming and advocacy efforts. This work is aimed at strengthening the lesbian, gay, bisexual, transgender, queer, intersex, and asexual (LGBTQIA) community and sustaining an inclusive campus that welcomes people of all sexual orientations, gender identities, and gender expressions.","title":"Ethical Conduct Policy:"},{"location":"untitled-Copy1/","text":"Placeholder file","title":"Placeholder file"},{"location":"untitled-Copy1/#placeholder-file","text":"","title":"Placeholder file"},{"location":"untitled/","text":"Placeholder file","title":"Solution"},{"location":"untitled/#placeholder-file","text":"","title":"Placeholder file"},{"location":"workshop1/","text":"Workshop 1 -- Title A short description, such as installing HEC-HMS Onto your local computer (Windows) Onto a cloud provider (AWS Lightsail) Workshop Objectives ABET Criteria Actual tutorial","title":"Workshop 1.1"},{"location":"workshop1/#workshop-1-title","text":"A short description, such as installing HEC-HMS Onto your local computer (Windows) Onto a cloud provider (AWS Lightsail)","title":"Workshop 1 -- Title"},{"location":"workshop1/#workshop-objectives","text":"","title":"Workshop Objectives"},{"location":"workshop1/#abet-criteria","text":"","title":"ABET Criteria"},{"location":"workshop1/#actual-tutorial","text":"","title":"Actual tutorial"}]}